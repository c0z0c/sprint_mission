---
layout: default
title: "이미지와 컴퓨터비전 학습자료"
description: "이미지와 컴퓨터비전 학습자료"
date: 2025-08-14
cache-control: no-cache
expires: 0
pragma: no-cache
---

# 이미지와 컴퓨터비전 학습자료

## 목차
1. [컴퓨터 비전 개요](#컴퓨터-비전-개요)
2. [디지털 이미지의 구조](#디지털-이미지의-구조)
3. [전통적인 컴퓨터 비전 방법](#전통적인-컴퓨터-비전-방법)
4. [딥러닝과 CNN](#딥러닝과-cnn)
5. [CNN 구성 요소](#cnn-구성-요소)
6. [이미지 전처리 방법과 종류](#이미지-전처리-방법과-종류)
7. [이미지 증강(Data Augmentation)](#이미지-증강data-augmentation)
8. [정규화의 장단점과 실제 적용](#정규화의-장단점과-실제-적용)
9. [주요 컴퓨터 비전 태스크](#주요-컴퓨터-비전-태스크)
10. [유명한 CNN 아키텍처](#유명한-cnn-아키텍처)
11. [실용 응용 분야](#실용-응용-분야)
12. [용어 정리](#용어-정리)
13. [부록: 상세 구현 코드](#부록-상세-구현-코드)

---

## 컴퓨터 비전 개요

### 컴퓨터 비전이란?

**컴퓨터 비전**(Computer Vision)은 컴퓨터가 사람처럼 이미지나 비디오를 "보고" 이해할 수 있게 하는 AI 분야입니다.

#### 인간 시각 vs 컴퓨터 시각

| 구분 | 인간의 시각 처리 | 컴퓨터의 시각 처리 |
|------|----------------|------------------|
| **처리 과정** | 눈 → 시신경 → 뇌의 시각피질 | 센서 → 디지털 신호 → 알고리즘 |
| **인식 속도** | 즉시 객체 인식, 깊이 감지 | 계산을 통한 분석 필요 |
| **이해 방식** | 맥락적 이해 | 픽셀 단위 수치 데이터 |
| **학습 방법** | 경험과 직관 | 패턴 매칭과 통계적 학습 |

### 컴퓨터 비전의 목표

1. **인식(Recognition)**: "이것은 무엇인가?"
2. **분할(Segmentation)**: "어디에 무엇이 있는가?"
3. **추적(Tracking)**: "어떻게 움직이는가?"
4. **재구성(Reconstruction)**: "3D 형태는 어떤가?"

---

## 디지털 이미지의 구조

### 픽셀의 개념

디지털 이미지는 **픽셀(Pixel, Picture Element)**이라는 작은 점들의 격자로 구성됩니다.

#### 흑백 이미지 구조 예시

```
5x5 픽셀 흑백 이미지 (0=검정, 255=흰색)

[  0  50 100 150 255]
[ 25  75 125 175 200]
[ 50 100 150 200 225]
[ 75 125 175 225 250]
[100 150 200 250 255]
```

#### 컬러 이미지 구조 (RGB)

```
각 픽셀이 3개의 값을 가짐:
픽셀 (0,0) = [R: 255, G: 0, B: 0]    # 빨간색
픽셀 (0,1) = [R: 0, G: 255, B: 0]    # 녹색  
픽셀 (0,2) = [R: 0, G: 0, B: 255]    # 파란색
```

### 이미지 해상도와 차원

- **해상도**: 이미지의 픽셀 개수 (예: 1920x1080)
- **차원**: 채널 수
  - 흑백: 1차원 (Height × Width × 1)
  - 컬러: 3차원 (Height × Width × 3)
  - RGBA: 4차원 (Height × Width × 4, Alpha는 투명도)

---

## 전통적인 컴퓨터 비전 방법

딥러닝 이전에는 수동으로 특징을 정의해야 했습니다.

### 1. 에지 디텍션(Edge Detection)

**목적**: 이미지에서 경계선 찾기

#### Sobel 필터 예제

```
수직 에지 검출:          수평 에지 검출:
[-1  0  1]              [-1 -2 -1]
[-2  0  2]              [ 0  0  0]
[-1  0  1]              [ 1  2  1]
```

### 2. 컨볼루션 연산 기본

```
이미지:    필터:    결과:
[1 2 3]   [1 0]    [1×1+2×0 = 1]
[4 5 6] * [0 1] =  [4×1+5×0 = 4]
[7 8 9]            [7×1+8×0 = 7]
```

### 전통적 방법의 한계

1. **수동 특징 설계**: 사람이 직접 어떤 특징을 찾을지 정의
2. **도메인 특화**: 한 문제에 최적화된 방법이 다른 문제에는 부적합
3. **복잡한 패턴 인식 한계**: 고차원적 패턴 인식 어려움
4. **확장성 부족**: 새로운 객체나 상황에 대한 일반화 어려움

---

## 딥러닝과 CNN

### 딥러닝의 혁신

**패러다임 변화:**
- **전통적 방법**: 수동 특징 설계 → 분류기
- **딥러닝**: 데이터로부터 자동으로 특징 학습 → 종단간(End-to-End) 학습

### 컨볼루셔널 신경망(CNN) 소개

**CNN**(Convolutional Neural Network, 컨볼루셔널[kən.və.ˈluː.ʃən.əl])은 이미지의 공간적 특성을 활용한 신경망입니다.

#### CNN의 핵심 아이디어

1. **지역 연결성(Local Connectivity)**: 인근 픽셀들만 연결
2. **파라미터 공유(Parameter Sharing)**: 같은 필터를 전체 이미지에 적용  
3. **평행이동 불변성(Translation Invariance)**: 객체의 위치가 바뀌어도 인식 가능

---

## CNN 구성 요소

### 1. 컨볼루션 레이어(Convolution Layer)

#### 기본 컨볼루션 연산

```
입력 (4x4):              필터 (3x3):
[1  2  3  4 ]           [1  0  1]
[5  6  7  8 ]           [0  1  0]  
[9  10 11 12]           [1  0  1]
[13 14 15 16]

결과 (2x2):
[37  43]  # 1×1+2×0+3×1+5×0+6×1+7×0+9×1+10×0+11×1 = 37
[63  69]
```

#### 주요 하이퍼파라미터

**스트라이드(Stride)**: 필터가 이동하는 간격
```
스트라이드 1: 1픽셀씩 이동
스트라이드 2: 2픽셀씩 이동 (크기 절반으로 축소)
```

**패딩(Padding)**: 가장자리에 값 추가
```
원본 (3x3) → 제로 패딩 → (5x5)
[1 2 3]      [0 0 0 0 0]
[4 5 6]  →   [0 1 2 3 0]
[7 8 9]      [0 4 5 6 0]
             [0 7 8 9 0]
             [0 0 0 0 0]
```

### 2. 활성화 함수 - ReLU

```python
ReLU(x) = max(0, x)

입력: [-2, -1, 0, 1, 2]
출력: [ 0,  0, 0, 1, 2]
```

### 3. 풀링 레이어(Pooling Layer)

#### 맥스 풀링 예제

```
입력 (4x4):              2x2 맥스 풀링:    출력 (2x2):
[1  3  2  4]            각 2x2 영역의     [7  8]
[5  7  6  8]      →     최댓값 선택  →    [15 16] 
[9  11 10 12]
[13 15 14 16]
```

---

## 이미지 전처리 방법과 종류

### 전처리의 목적

1. **데이터 표준화**: 모델이 일관성 있게 학습
2. **성능 향상**: 노이즈 제거, 대비 개선
3. **계산 효율성**: 이미지 크기 조정으로 연산량 감소
4. **일반화 성능**: 다양한 조건에 robust한 모델 구축

### 1. 기본 전처리 방법

#### 크기 조정(Resizing)

```python
# 간단한 크기 조정 예시
import cv2
resized = cv2.resize(image, (224, 224))
```

**보간 방법 비교:**

| 방법 | 특징 | 용도 |
|------|------|------|
| INTER_LINEAR | 선형 보간, 빠름 | 일반적 용도 |
| INTER_CUBIC | 3차 보간, 부드러움 | 품질 중시 |
| INTER_AREA | 축소에 최적화 | 다운샘플링 |

#### 색공간 변환

```python
# 주요 색공간 변환
gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # 그레이스케일
hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)    # HSV
lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)    # LAB
```

**색공간별 특징:**
- **RGB**: 기본 색공간, 하드웨어 친화적
- **HSV**: 색상 분리 용이, 색상 기반 필터링에 유용
- **LAB**: 인간 시각과 유사, 색상 보정에 효과적

### 2. 히스토그램 처리

#### 히스토그램 평활화

```python
# 그레이스케일 히스토그램 평활화
equalized = cv2.equalizeHist(gray_image)

# CLAHE (적응적 히스토그램 평활화)
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
clahe_result = clahe.apply(gray_image)
```

**언제 사용하나:**
- 대비가 낮은 이미지
- 의료 영상 분석
- 저조도 환경 이미지

### 3. 노이즈 제거

```python
# 가우시안 블러 - 일반적 노이즈 제거
gaussian = cv2.GaussianBlur(image, (5, 5), 0)

# 미디언 필터 - Salt-and-pepper 노이즈
median = cv2.medianBlur(image, 5)

# 양방향 필터 - 엣지 보존하며 노이즈 제거
bilateral = cv2.bilateralFilter(image, 9, 75, 75)
```

---

## 이미지 증강(Data Augmentation)

### 증강의 목적

1. **데이터 부족 해결**: 제한된 데이터셋 확장
2. **과적합 방지**: 다양한 변형으로 일반화 성능 향상
3. **불변성 학습**: 변환에 robust한 모델 구축
4. **데이터 불균형 해결**: 클래스별 데이터 균형화

### 1. 기하학적 변환

#### 회전(Rotation)

```python
# 무작위 회전 (-30도 ~ +30도)
angle = random.uniform(-30, 30)
rotated = cv2.warpAffine(image, rotation_matrix, (w, h))
```

**권장 각도:**
- 일반 객체: ±15도
- 자연 이미지: ±30도  
- 텍스트/숫자: ±10도 (가독성 고려)

#### 평행이동(Translation)

```python
# 이미지 크기의 10% 범위 내 이동
shift_x = int(width * 0.1 * random.uniform(-1, 1))
shift_y = int(height * 0.1 * random.uniform(-1, 1))
```

#### 확대/축소(Scaling)

```python
# 0.8배 ~ 1.2배 크기 변화
scale = random.uniform(0.8, 1.2)
scaled = cv2.resize(image, None, fx=scale, fy=scale)
```

### 2. 색상 및 밝기 변환

#### 밝기 조정

```python
# 밝기 ±50 범위 조정
brightness = random.randint(-50, 50)
bright_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * brightness)
```

#### 대비 조정

```python
# 0.7배 ~ 1.3배 대비 변화
contrast = random.uniform(0.7, 1.3)
contrasted = np.clip((image - 128) * contrast + 128, 0, 255)
```

### 3. 고급 증강 기법

#### 믹스업(Mixup)

두 이미지를 선형 결합하여 새로운 훈련 샘플 생성

```
mixed_image = λ × image1 + (1-λ) × image2
mixed_label = λ × label1 + (1-λ) × label2
```

#### CutMix

한 이미지의 일부를 다른 이미지로 교체

```
이미지1의 사각형 영역을 이미지2로 대체
라벨도 영역 비율에 따라 조합
```

### 4. 증강 전략과 고려사항

#### 태스크별 증강 전략

| 태스크 | 권장 증강 | 주의사항 |
|--------|-----------|----------|
| **이미지 분류** | 회전, 이동, 색상 변화 | 과도한 변형 주의 |
| **객체 탐지** | 수평 뒤집기, 크기 조정 | 바운딩 박스 함께 변환 |
| **세그멘테이션** | 탄성 변형, 회전 | 마스크와 이미지 동일 변환 |
| **의료 영상** | 회전, 탄성 변형 | 해부학적 구조 보존 |

#### 데이터 의존적 고려사항

```python
# 도메인별 증강 예시

# 자연 이미지
natural_augmentations = [
    'horizontal_flip',      # 좌우 반전 OK
    'rotation',            # 회전 OK  
    'color_jitter',        # 색상 변화 OK
    'gaussian_noise'       # 노이즈 추가 OK
]

# 의료 영상
medical_augmentations = [
    'rotation',            # 제한적 회전
    'elastic_deformation', # 조직 변형 시뮬레이션
    'brightness_adjust',   # 촬영 조건 차이
    # 'horizontal_flip'    # 해부학적 이유로 제외
]

# 텍스트/문서
text_augmentations = [
    'slight_rotation',     # 미세한 회전만
    'perspective_change',  # 시점 변화
    'contrast_adjust',     # 대비 조정
    # 'color_change'       # 텍스트 색상은 보존
]
```

---

## 정규화의 장단점과 실제 적용

### 정규화 방법들

#### 1. 기본 정규화 방법

```python
# Min-Max 정규화 (0-1 범위)
normalized = (image - image.min()) / (image.max() - image.min())

# 단순 스케일링 (0-1 범위)
simple_norm = image.astype(np.float32) / 255.0

# Z-score 정규화 (평균 0, 표준편차 1)
z_norm = (image - image.mean()) / image.std()

# ImageNet 정규화 (사전훈련 모델용)
imagenet_norm = (image/255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
```

### 정규화의 장점

1. **훈련 안정성 향상**
   - 그라디언트 크기 조절
   - 수치적 안정성 확보

2. **수렴 속도 향상**
   - 적절한 학습률 사용 가능
   - 더 빠른 최적화

3. **사전훈련 모델 호환**
   - Transfer Learning 시 필수
   - 모델 간 일관성 유지

### 정규화의 단점과 이미지 복원에서의 문제

#### 1. 정보 손실 문제

```python
# 절대적 밝기 정보 손실 예시
bright_image = np.array([[200, 220, 240]])  # 밝은 이미지
dark_image = np.array([[20, 22, 24]])       # 어두운 이미지

# Min-Max 정규화 후 둘 다 [0, 0.5, 1.0]이 됨
# → 원본의 절대적 밝기 차이 소실
```

#### 2. 이미지 복원에서 성능 저하 원인

**복원 태스크의 특수성:**

| 일반 분류 | 이미지 복원 |
|-----------|-------------|
| 상대적 패턴 중요 | 절대적 값 중요 |
| 정규화로 안정성 ↑ | 정규화로 정보 손실 |
| 분류 경계 학습 | 픽셀 값 정확도 중요 |

#### 3. 복원 태스크에서의 대안

**1) 적응적 정규화**

```python
# 지역적 정규화 - 패치별로 다른 정규화
def adaptive_normalization(image, patch_size=64):
    h, w = image.shape[:2]
    normalized = np.zeros_like(image, dtype=np.float32)
    
    for i in range(0, h, patch_size):
        for j in range(0, w, patch_size):
            patch = image[i:i+patch_size, j:j+patch_size]
            # 패치별 개별 정규화
            norm_patch = (patch - patch.mean()) / (patch.std() + 1e-8)
            normalized[i:i+patch_size, j:j+patch_size] = norm_patch
    
    return normalized
```

**2) 범위 보존 정규화**

```python
# 원본 범위 정보 보존
def range_preserving_norm(image):
    # 정규화와 함께 범위 정보 저장
    min_val, max_val = image.min(), image.max()
    normalized = (image - min_val) / (max_val - min_val)
    return normalized, min_val, max_val

def denormalize(normalized, min_val, max_val):
    # 복원 시 원래 범위로 되돌림
    return normalized * (max_val - min_val) + min_val
```

**3) 복원 전용 전처리**

```python
# 이미지 복원에 적합한 전처리
def restoration_preprocessing(image):
    # 1. 노이즈 제거 (과도하지 않게)
    denoised = cv2.bilateralFilter(image, 5, 25, 25)
    
    # 2. 정규화 대신 단순 타입 변환
    processed = denoised.astype(np.float32)
    
    # 3. 0-1 범위로 스케일링 (정보 보존)
    if processed.max() > 1.0:
        processed = processed / 255.0
    
    return processed
```

### 복원 성능 저하 해결 방안

#### 1. 손실 함수 개선

```python
# 정규화된 공간에서의 손실보다 원본 공간 손실 사용
def perceptual_loss(restored, target):
    # VGG 특징을 이용한 지각적 손실
    # 정규화 영향 최소화
    pass

def combined_loss(restored, target):
    # L1 + Perceptual + GAN Loss 조합
    # 픽셀 단위 정확도와 지각적 품질 모두 고려
    pass
```

#### 2. 네트워크 아키텍처 조정

```python
# 복원용 네트워크 설계 시 고려사항
class RestorationNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        # 1. Skip connection으로 저수준 정보 보존
        # 2. 다중 스케일 특징 활용
        # 3. 정규화 레이어 신중히 사용
        pass
```

#### 3. 훈련 전략 수정

```python
# 점진적 훈련 방법
def progressive_training():
    # 1단계: 정규화 없이 기본 복원 학습
    # 2단계: 약한 정규화 적용
    # 3단계: 최종 fine-tuning
    pass
```

---

## 주요 컴퓨터 비전 태스크

### 1. 이미지 분류(Image Classification)

**목표**: 이미지 전체를 하나의 클래스로 분류

```python
# 출력 예시
입력: 고양이 사진
출력: {"고양이": 0.95, "개": 0.03, "새": 0.01, "기타": 0.01}
```

### 2. 객체 탐지(Object Detection)

**목표**: 이미지에서 여러 객체의 위치와 클래스를 동시에 찾기

```python
# 바운딩 박스 형식: [x, y, width, height, class, confidence]
출력 = [
    [100, 50, 200, 150, "사람", 0.92],
    [300, 80, 100, 120, "자동차", 0.87],
    [450, 200, 80, 60, "신호등", 0.79]
]
```

### 3. 시맨틱 세그멘테이션(Semantic Segmentation)

**목표**: 픽셀 단위로 클래스 분류

```
원본 이미지:           세그멘테이션 결과:
[하늘 하늘 나무 나무]  [클래스1 클래스1 클래스2 클래스2]
[하늘 하늘 나무 나무]  [클래스1 클래스1 클래스2 클래스2]
[길  길  차  차 ]    [클래스3 클래스3 클래스4 클래스4]
```

### 4. 인스턴스 세그멘테이션(Instance Segmentation)

**시맨틱 vs 인스턴스 비교:**

```
시맨틱: [사람 사람 배경]  →  인스턴스: [사람1 사람2 배경]
        같은 클래스 통합      →           개별 객체 구분
```

---

## 유명한 CNN 아키텍처

### 1. LeNet-5 (1998년)

```
입력(32×32×1) → Conv1 → Pool1 → Conv2 → Pool2 → FC → 출력(10)
```

**특징:**
- 최초의 성공적인 CNN
- 손글씨 숫자 인식용
- 시그모이드 활성화 함수

### 2. AlexNet (2012년)

**혁신 요소:**
1. **ReLU 활성화 함수** 도입
2. **드롭아웃**으로 과적합 방지  
3. **GPU 병렬 처리** 활용
4. **데이터 어그멘테이션** 적용

### 3. VGG (2014년)

**핵심**: 작은 3×3 필터를 깊게 쌓기

```
왜 3×3 필터?
- 7×7 필터 1개 = 49개 파라미터
- 3×3 필터 3개 = 27개 파라미터 (같은 수용영역, 더 적은 파라미터)
```

### 4. ResNet (2015년)

**문제**: 깊은 네트워크의 그라디언트 소실

**해결**: 잔차 연결(Residual Connection)

```
전통적: H(x) = F(x)
ResNet: H(x) = F(x) + x  ← 스킵 연결 추가
```

### 5. EfficientNet (2019년)

**복합 스케일링**: 깊이 + 너비 + 해상도 동시 조정

```
깊이: d = α^φ
너비: w = β^φ  
해상도: r = γ^φ
제약: α × β² × γ² ≈ 2
```

---

## 실용 응용 분야

### 1. 자율주행

**핵심 기술:**
- 차선 인식 (세그멘테이션)
- 신호등 분류 (객체 탐지)
- 보행자 추적 (다중 객체 추적)

### 2. 의료 영상

**응용 분야:**
- X-ray 판독 보조
- 피부암 진단
- 망막 병변 탐지

### 3. 제조업

**품질 관리:**
- 표면 결함 탐지
- 부품 조립 확인
- 치수 측정 자동화

### 4. 보안 및 감시

**기능:**
- 얼굴 인식 출입 통제
- 이상 행동 탐지
- 차량 번호판 인식

### 5. 소매업

**활용:**
- 무인 계산대
- 재고 관리
- 고객 행동 분석

---

## 용어 정리

### A-C

**CNN (Convolutional Neural Network)**
: 이미지 처리에 특화된 신경망, 컨볼루션 연산을 통해 특징을 추출

**컨볼루션(Convolution)**
: 필터를 이미지에 슬라이딩하며 특징을 추출하는 연산

**CLAHE (Contrast Limited Adaptive Histogram Equalization)**
: 지역적 대비 향상 기법, 과도한 대비 증가 방지

### D-F

**드롭아웃(Dropout)**
: 과적합을 방지하기 위해 일부 뉴런을 임의로 비활성화하는 기법

**데이터 어그멘테이션(Data Augmentation)**
: 기존 데이터를 변형하여 훈련 데이터를 늘리는 기법

**피처 맵(Feature Map)**
: 컨볼루션 레이어에서 출력되는 특징이 추출된 이미지

### G-P

**HSV**
: Hue(색조), Saturation(채도), Value(명도) 색공간

**ImageNet**
: 대규모 이미지 분류 데이터셋, 사전훈련 모델의 기준

**커널/필터(Kernel/Filter)**
: 컨볼루션 연산에 사용되는 작은 크기의 가중치 행렬

**풀링(Pooling)**
: 이미지 크기를 줄이면서 중요한 정보를