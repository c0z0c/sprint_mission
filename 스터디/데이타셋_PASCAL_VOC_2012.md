---
layout: default
title: "PASCAL VOC 2012 ë°ì´í„°ì…‹"
description: "PASCAL VOC 2012 ë°ì´í„°ì…‹"
date: 2025-08-25
cache-control: no-cache
expires: 0
pragma: no-cache
author: "ê¹€ëª…í™˜"
---

# PASCAL VOC 2012 ë°ì´í„°ì…‹ ë° torchvision.datasets.VOCSegmentation ê°€ì´ë“œ

## ëª©ì°¨
1. [PASCAL VOC 2012 ë°ì´í„°ì…‹ ê°œìš”](#1-pascal-voc-2012-ë°ì´í„°ì…‹-ê°œìš”)<br/>
   1.1. [ë°ì´í„°ì…‹ ì†Œê°œ](#11-ë°ì´í„°ì…‹-ì†Œê°œ)<br/>
   1.1.1. [í•µì‹¬ íŠ¹ì§•](#111-í•µì‹¬-íŠ¹ì§•)<br/>
   1.2. [í´ë˜ìŠ¤ êµ¬ì¡°](#12-í´ë˜ìŠ¤-êµ¬ì¡°)<br/>
   1.3. [ë°ì´í„° ë¶„í• ](#13-ë°ì´í„°-ë¶„í• )<br/>
2. [ë°ì´í„°ì…‹ êµ¬ì¡° ë° íŠ¹ì§•](#2-ë°ì´í„°ì…‹-êµ¬ì¡°-ë°-íŠ¹ì§•)<br/>
   2.1. [ë°ì´í„° í†µê³„](#21-ë°ì´í„°-í†µê³„)<br/>
   2.2. [ì–´ë…¸í…Œì´ì…˜ êµ¬ì¡°](#22-ì–´ë…¸í…Œì´ì…˜-êµ¬ì¡°)<br/>
   2.2.1. [XML ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ êµ¬ì¡°](#221-xml-ì–´ë…¸í…Œì´ì…˜-íŒŒì¼-êµ¬ì¡°)<br/>
   2.2.2. [ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬](#222-ì„¸ê·¸ë©˜í…Œì´ì…˜-ë§ˆìŠ¤í¬)<br/>
   2.3. [íŠ¹ë³„ í´ë˜ìŠ¤: Neutral Class](#23-íŠ¹ë³„-í´ë˜ìŠ¤-neutral-class)<br/>
3. [torchvision.datasets.VOCSegmentation](#3-torchvisiondatasetsvocSegmentation)<br/>
   3.1. [í´ë˜ìŠ¤ ì •ì˜ ë° ë§¤ê°œë³€ìˆ˜](#31-í´ë˜ìŠ¤-ì •ì˜-ë°-ë§¤ê°œë³€ìˆ˜)<br/>
   3.2. [ê¸°ë³¸ ì‚¬ìš©ë²•](#32-ê¸°ë³¸-ì‚¬ìš©ë²•)<br/>
   3.2.1. [ê³µì‹ ë‹¤ìš´ë¡œë“œ ë°©ë²•](#321-ê³µì‹-ë‹¤ìš´ë¡œë“œ-ë°©ë²•)<br/>
   3.2.2. [Kaggle Hubë¥¼ í†µí•œ ì•ˆì •ì  ë‹¤ìš´ë¡œë“œ](#322-kaggle-hubë¥¼-í†µí•œ-ì•ˆì •ì -ë‹¤ìš´ë¡œë“œ)<br/>
   3.2.3. [ë””ë ‰í„°ë¦¬ êµ¬ì¡° í™•ì¸](#323-ë””ë ‰í„°ë¦¬-êµ¬ì¡°-í™•ì¸)<br/>
   3.2.4. [ImageSets í´ë” êµ¬ì¡° ë° ë‚´ìš©](#324-imagesets-í´ë”-êµ¬ì¡°-ë°-ë‚´ìš©)<br/>
   3.3. [ê³ ê¸‰ ì‚¬ìš©ë²•](#33-ê³ ê¸‰-ì‚¬ìš©ë²•)<br/>
   3.3.1. [ë°ì´í„° ë³€í™˜ ì ìš©](#331-ë°ì´í„°-ë³€í™˜-ì ìš©)<br/>
   3.3.2. [DataLoaderì™€ í•¨ê»˜ ì‚¬ìš©](#332-dataloaderì™€-í•¨ê»˜-ì‚¬ìš©)<br/>
4. [ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ](#4-ì‹¤ì œ-êµ¬í˜„-ì˜ˆì œ)<br/>
   4.1. [ê¸°ë³¸ ë°ì´í„° ë¡œë”©](#41-ê¸°ë³¸-ë°ì´í„°-ë¡œë”©)<br/>
   4.2. [ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í•™ìŠµìš© íŒŒì´í”„ë¼ì¸](#42-ì„¸ê·¸ë©˜í…Œì´ì…˜-ëª¨ë¸-í•™ìŠµìš©-íŒŒì´í”„ë¼ì¸)<br/>
   4.3. [VOC ì»¬ëŸ¬ë§µ ë° ì‹œê°í™”](#43-voc-ì»¬ëŸ¬ë§µ-ë°-ì‹œê°í™”)<br/>
   4.4. [XML ì–´ë…¸í…Œì´ì…˜ íŒŒì‹±](#44-xml-ì–´ë…¸í…Œì´ì…˜-íŒŒì‹±)<br/>
5. [ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì…ë³„ ì°¨ì´ì ](#5-ì„¸ê·¸ë©˜í…Œì´ì…˜-íƒ€ì…ë³„-ì°¨ì´ì )<br/>
   5.1. [SegmentationClass vs SegmentationObject](#51-segmentationclass-vs-segmentationobject)<br/>
   5.2. [ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ](#52-ì‹¤ì œ-ì‚¬ìš©-ì˜ˆì œ)<br/>
6. [ë²¤ì¹˜ë§ˆí‚¹ ë° í‰ê°€](#6-ë²¤ì¹˜ë§ˆí‚¹-ë°-í‰ê°€)<br/>
   6.1. [í‘œì¤€ í‰ê°€ ë©”íŠ¸ë¦­](#61-í‘œì¤€-í‰ê°€-ë©”íŠ¸ë¦­)<br/>
   6.2. [í˜„ì¬ State-of-the-Art](#62-í˜„ì¬-state-of-the-art)<br/>

---

## 1. PASCAL VOC 2012 ë°ì´í„°ì…‹ ê°œìš”

### 1.1. ë°ì´í„°ì…‹ ì†Œê°œ

PASCAL Visual Object Classes Challenge 2012 (VOC2012)ëŠ” ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë²¤ì¹˜ë§ˆí¬(ë²¤ì¹˜ë§ˆí¬) ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ê°ì²´ ê²€ì¶œ(Object Detection), ì˜ë¯¸ë¡ ì  ì„¸ê·¸ë©˜í…Œì´ì…˜(Semantic Segmentation, ì‹œë§¨í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜), ë¶„ë¥˜(Classification, í´ë˜ì‹œí”¼ì¼€ì´ì…˜) ì‘ì—…ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

```mermaid
graph TD
    A["PASCAL VOC 2012"] --> B["Object Detection"]
    A --> C["Semantic Segmentation"]  
    A --> D["Action Classification"]
    A --> E["Instance Segmentation"]
    
    B --> F["Annotations/*.xml"]
    C --> G["SegmentationClass/*.png"]
    E --> H["SegmentationObject/*.png"]
    D --> I["ImageSets/Action/*.txt"]
    
    F --> J["Bounding Boxes"]
    F --> K["Class Labels"]
    G --> L["Pixel-wise Labels"]
    H --> M["Instance IDs"]
```

#### 1.1.1. í•µì‹¬ íŠ¹ì§•

- **ì´ ì´ë¯¸ì§€ ìˆ˜**: 17,125ê°œ (í›ˆë ¨/ê²€ì¦ìš©)
- **í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜**: 5,138ê°œ
- **ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ë¯¸ì§€**: 9,993ê°œ (VOC2011ì˜ 7,062ê°œì—ì„œ ì¦ê°€)
- **ë¼ë²¨ë§ëœ ê°ì²´**: 27,450ê°œ ROI(Region of Interest, ì•Œì˜¤ì•„ì´) íƒœê·¸ëœ ê°ì²´
- **ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬**: 2,913ê°œ (Class ë° Object ê°ê°)

### 1.2. í´ë˜ìŠ¤ êµ¬ì¡°

VOC 2012 ë°ì´í„°ì…‹ì€ ì´ **21ê°œì˜ í´ë˜ìŠ¤**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤ (ë°°ê²½ í¬í•¨):

```
í´ë˜ìŠ¤ ëª©ë¡ (20ê°œ ê°ì²´ + 1ê°œ ë°°ê²½):
- ì‚¬ëŒ: person
- ë™ë¬¼: bird, cat, cow, dog, horse, sheep
- íƒˆê²ƒ: aeroplane, bicycle, boat, bus, car, motorbike, train
- ì‹¤ë‚´ ë¬¼í’ˆ: bottle, chair, diningtable, pottedplant, sofa, tvmonitor
- íŠ¹ìˆ˜: background (ë°°ê²½)
```

### 1.3. ë°ì´í„° ë¶„í• 

ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë¶„í• ë©ë‹ˆë‹¤:

- **Train**: í›ˆë ¨ìš© ë°ì´í„°
- **Val**: ê²€ì¦ìš© ë°ì´í„°  
- **Trainval**: í›ˆë ¨ + ê²€ì¦ ë°ì´í„° ê²°í•©
- **Test**: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (ì–´ë…¸í…Œì´ì…˜ì€ ê³µê°œë˜ì§€ ì•ŠìŒ)

## 2. ë°ì´í„°ì…‹ êµ¬ì¡° ë° íŠ¹ì§•

### 2.1. ë°ì´í„° í†µê³„

```
ì„¸ê·¸ë©˜í…Œì´ì…˜ íŒŒíŠ¸ ê¸°ì¤€:
- ì´ ì´ë¯¸ì§€: 7,282ê°œ
- ë¼ë²¨ë§ëœ ê°ì²´: 19,694ê°œ
- í´ë˜ìŠ¤ë³„ ë¶„í¬: 21ê°œ í´ë˜ìŠ¤ì— ê· ë“±í•˜ê²Œ ë¶„í¬
- ì–´ë…¸í…Œì´ì…˜ ì—†ëŠ” ì´ë¯¸ì§€: 1,456ê°œ (ì „ì²´ì˜ 20%)
```

### 2.2. ì–´ë…¸í…Œì´ì…˜ êµ¬ì¡°

#### 2.2.1. XML ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ êµ¬ì¡°

VOC ë°ì´í„°ì…‹ì˜ ì–´ë…¸í…Œì´ì…˜ì€ XML í˜•íƒœë¡œ ì €ì¥ë˜ë©°, ê° ì´ë¯¸ì§€ë‹¹ í•˜ë‚˜ì˜ XML íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. ë‹¤ìŒì€ ê¸°ë³¸ êµ¬ì¡°ì™€ ì£¼ìš” ë…¸ë“œ(Node, ë…¸ë“œ)ë“¤ì…ë‹ˆë‹¤:

```xml
<annotation>
    <folder>VOC2012</folder>                    <!-- í´ë”ëª… -->
    <filename>2007_000001.jpg</filename>        <!-- ì´ë¯¸ì§€ íŒŒì¼ëª… -->
    <source>                                    <!-- ë°ì´í„° ì¶œì²˜ ì •ë³´ -->
        <database>The VOC2007 Database</database>
        <annotation>PASCAL VOC2007</annotation>
    </source>
    <size>                                      <!-- ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ -->
        <width>353</width>                      <!-- ë„ˆë¹„ (í”½ì…€) -->
        <height>500</height>                    <!-- ë†’ì´ (í”½ì…€) -->
        <depth>3</depth>                        <!-- ì±„ë„ ìˆ˜ (RGB=3) -->
    </size>
    <segmented>0</segmented>                    <!-- ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—¬ë¶€ (0/1) -->
    
    <object>                                    <!-- ê°ì²´ ì •ë³´ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥) -->
        <name>dog</name>                        <!-- í´ë˜ìŠ¤ ì´ë¦„ -->
        <pose>Left</pose>                       <!-- ê°ì²´ ë°©í–¥ -->
        <truncated>1</truncated>                <!-- ì˜ë¦¼ ì—¬ë¶€ (0/1) -->
        <difficult>0</difficult>                <!-- ê²€ì¶œ ë‚œì´ë„ (0/1) -->
        <bndbox>                                <!-- ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ -->
            <xmin>48</xmin>                     <!-- ì¢Œìƒë‹¨ x ì¢Œí‘œ -->
            <ymin>240</ymin>                    <!-- ì¢Œìƒë‹¨ y ì¢Œí‘œ -->
            <xmax>195</xmax>                    <!-- ìš°í•˜ë‹¨ x ì¢Œí‘œ -->
            <ymax>371</ymax>                    <!-- ìš°í•˜ë‹¨ y ì¢Œí‘œ -->
        </bndbox>
    </object>
    
    <!-- ì¶”ê°€ ê°ì²´ë“¤... -->
</annotation>
```

**ì£¼ìš” ë…¸ë“œ ì„¤ëª…**:
- `<annotation>`: ë£¨íŠ¸ ìš”ì†Œ
- `<filename>`: í•´ë‹¹ ì´ë¯¸ì§€ íŒŒì¼ëª…
- `<size>`: ì´ë¯¸ì§€ í•´ìƒë„ ì •ë³´ (width, height, depth)
- `<object>`: ê°œë³„ ê°ì²´ ì •ë³´ (ì´ë¯¸ì§€ ë‚´ ì—¬ëŸ¬ ê°ì²´ ì¡´ì¬ ì‹œ ë°˜ë³µ)
- `<name>`: VOC 20ê°œ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ (person, car, dog ë“±)
- `<bndbox>`: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (xmin, ymin, xmax, ymax)
- `<truncated>`: ê°ì²´ê°€ ì´ë¯¸ì§€ ê²½ê³„ì—ì„œ ì˜ë ¸ëŠ”ì§€ ì—¬ë¶€
- `<difficult>`: ê²€ì¶œí•˜ê¸° ì–´ë ¤ìš´ ê°ì²´ì¸ì§€ í‘œì‹œ (ì‘ê±°ë‚˜ ê°€ë ¤ì§„ ê°ì²´)

#### 2.2.2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬

VOC 2012ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ëŠ” **í”½ì…€ ìˆ˜ì¤€ì˜ ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜(Instance Segmentation, ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜)** ì–´ë…¸í…Œì´ì…˜(Annotation, ì–´ë…¸í…Œì´ì…˜)ì„ ì œê³µí•©ë‹ˆë‹¤:

- ê° í”½ì…€ì€ í•´ë‹¹í•˜ëŠ” ê°ì²´ í´ë˜ìŠ¤ IDë¡œ ë¼ë²¨ë§
- í”½ì…€ê°’ 0: ë°°ê²½(background)
- í”½ì…€ê°’ 1-20: ê° ê°ì²´ í´ë˜ìŠ¤
- í”½ì…€ê°’ 255: ê²½ê³„(boundary) í”½ì…€ ë˜ëŠ” "ì¤‘ë¦½" í´ë˜ìŠ¤

### 2.3. íŠ¹ë³„ í´ë˜ìŠ¤: Neutral Class(ë‰´íŠ¸ëŸ´ í´ë˜ìŠ¤)

VOC 2012ì˜ ë…íŠ¹í•œ íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” **Neutral Class(ë‰´íŠ¸ëŸ´ í´ë˜ìŠ¤)**ì…ë‹ˆë‹¤:

- ê°ì²´ì˜ ê²½ê³„(ë‚´ë¶€ ë° ì™¸ë¶€ í”½ì…€)ë¥¼ íŠ¹ë³„í•œ ì¤‘ë¦½ í´ë˜ìŠ¤ë¡œ í‘œì‹œ
- ëª¨ë“  ê°ì²´ì˜ ê²½ê³„ê°€ í•˜ë‚˜ì˜ í†µí•©ëœ ë§ˆìŠ¤í¬ë¡œ ì œê³µ
- ê°ì²´ë³„ë¡œ ê°œë³„ ì¤‘ë¦½ ë§ˆìŠ¤í¬ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ

## 3. torchvision.datasets.VOCSegmentation

### 3.1. í´ë˜ìŠ¤ ì •ì˜ ë° ë§¤ê°œë³€ìˆ˜

```python
class torchvision.datasets.VOCSegmentation(
    root: Union[str, Path],
    year: str = '2012',
    image_set: str = 'train',
    download: bool = False,
    transform: Optional[Callable] = None,
    target_transform: Optional[Callable] = None,
    transforms: Optional[Callable] = None
)
```

**ë§¤ê°œë³€ìˆ˜ ì„¤ëª…**:

- `root`: ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë£¨íŠ¸ ë””ë ‰í„°ë¦¬(ë””ë ‰í„°ë¦¬) ê²½ë¡œ
- `year`: ì‚¬ìš©í•  VOC ë°ì´í„°ì…‹ ì—°ë„ ('2007' ë˜ëŠ” '2012')
- `image_set`: ì´ë¯¸ì§€ ì…‹ ì„ íƒ ('train', 'trainval', 'val', VOC2007ì˜ ê²½ìš° 'test'ë„ ê°€ëŠ¥)
- `download`: ì¸í„°ë„·ì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€
- `transform`: ì…ë ¥ ì´ë¯¸ì§€ì— ì ìš©í•  ë³€í™˜(Transform, íŠ¸ëœìŠ¤í¼) í•¨ìˆ˜
- `target_transform`: íƒ€ê²Ÿ(ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬)ì— ì ìš©í•  ë³€í™˜ í•¨ìˆ˜
- `transforms`: ì…ë ¥ê³¼ íƒ€ê²Ÿ ëª¨ë‘ì— ì ìš©í•  ë³€í™˜ í•¨ìˆ˜

### 3.2. ê¸°ë³¸ ì‚¬ìš©ë²•

#### 3.2.1. ê³µì‹ ë‹¤ìš´ë¡œë“œ ë°©ë²•

```python
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë”© (ê³µì‹ ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œ)
dataset = datasets.VOCSegmentation(
    root='./data',
    year='2012',
    image_set='trainval',
    download=True  # ì£¼ì˜: ê³µì‹ ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ
)

# ìƒ˜í”Œ ë°ì´í„° í™•ì¸
image, target = dataset[0]
print(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
print(f"íƒ€ê²Ÿ í¬ê¸°: {target.size}")
print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
```

#### 3.2.2. Kaggle Hubë¥¼ í†µí•œ ì•ˆì •ì  ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)

ê³µì‹ ë‹¤ìš´ë¡œë“œê°€ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš°, Kaggle Hubë¥¼ í†µí•´ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  PyTorchê°€ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤:

```python
import os
import shutil
import kagglehub
import torchvision.datasets as datasets

def setup_voc_dataset():
    """Kaggle Hubë¥¼ í†µí•´ VOC ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° êµ¬ì¡° ì„¤ì •"""
    
    # Kaggle Hubì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    path = kagglehub.dataset_download("likhon148/visual-object-classes-voc-12")
    
    voc2012_path = os.path.join(path, "VOC2012")
    vocdevkit_path = os.path.join(path, "VOCdevkit")
    
    # PyTorchê°€ ìš”êµ¬í•˜ëŠ” ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±
    # ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°: root/VOCdevkit/VOC2012/
    if os.path.exists(voc2012_path) and not os.path.exists(vocdevkit_path):
        os.makedirs(vocdevkit_path, exist_ok=True)
        
        try:
            # VOC2012 í´ë”ë¥¼ VOCdevkit ë‚´ë¶€ë¡œ ì´ë™
            shutil.move(voc2012_path, vocdevkit_path)
            print("ë°ì´í„°ì…‹ êµ¬ì¡° ì¬êµ¬ì„± ì™„ë£Œ")
        except Exception as e:
            print(f"shutil.move ì˜¤ë¥˜: {e}")
            # ëŒ€ì•ˆ: os.rename ì‚¬ìš©
            try:
                target_path = os.path.join(vocdevkit_path, "VOC2012")
                os.rename(voc2012_path, target_path)
                print("os.renameì„ í†µí•œ êµ¬ì¡° ì¬êµ¬ì„± ì™„ë£Œ")
            except Exception as e2:
                print(f"os.rename ì˜¤ë¥˜: {e2}")
                raise Exception("ë°ì´í„°ì…‹ êµ¬ì¡° ì¬êµ¬ì„± ì‹¤íŒ¨")
    
    return path

def load_voc_dataset(image_set='train'):
    """VOC ë°ì´í„°ì…‹ ë¡œë”©"""
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
    dataset_path = setup_voc_dataset()
    
    # PyTorch ë°ì´í„°ì…‹ ë¡œë”©
    voc_dataset = datasets.VOCSegmentation(
        root=dataset_path,  # VOCdevkitê°€ ìˆëŠ” ìƒìœ„ í´ë”
        year='2012',
        image_set=image_set,
        download=False  # ì´ë¯¸ ë‹¤ìš´ë¡œë“œí–ˆìœ¼ë¯€ë¡œ False
    )
    
    print(f"ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ: {len(voc_dataset)}ê°œ ìƒ˜í”Œ")
    return voc_dataset

# ì‚¬ìš© ì˜ˆì œ
try:
    dataset = load_voc_dataset('trainval')
    
    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
    image, target = dataset[0]
    print(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
    print(f"íƒ€ê²Ÿ í¬ê¸°: {target.size}")
    print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
    
except Exception as e:
    print(f"ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
```

#### 3.2.3. ë””ë ‰í„°ë¦¬ êµ¬ì¡° í™•ì¸

ì˜¬ë°”ë¥¸ ë””ë ‰í„°ë¦¬ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

```
dataset_path/
â””â”€â”€ VOCdevkit/
    â””â”€â”€ VOC2012/
        â”œâ”€â”€ Annotations/          # XML í˜•íƒœì˜ ì–´ë…¸í…Œì´ì…˜(ì–´ë…¸í…Œì´ì…˜) íŒŒì¼ [17,125ê°œ]
        â”œâ”€â”€ ImageSets/           # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  ì •ë³´
        â”‚   â”œâ”€â”€ Action/          # ì•¡ì…˜ ë¶„ë¥˜ìš© íŒŒì¼ë“¤ [33ê°œ]
        â”‚   â”œâ”€â”€ Layout/          # ì‚¬ëŒ ë ˆì´ì•„ì›ƒìš© íŒŒì¼ë“¤
        â”‚   â”œâ”€â”€ Main/            # ì£¼ìš” ë¶„í•  ì •ë³´ íŒŒì¼ë“¤ [63ê°œ]
        â”‚   â””â”€â”€ Segmentation/    # ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© ë¶„í•  ì •ë³´
        â”œâ”€â”€ JPEGImages/          # ì›ë³¸ JPEG ì´ë¯¸ì§€ë“¤ [17,125ê°œ]
        â”œâ”€â”€ SegmentationClass/   # í´ë˜ìŠ¤ë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ [2,913ê°œ]
        â””â”€â”€ SegmentationObject/  # ê°ì²´ë³„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ [2,913ê°œ]
```

#### 3.2.4. ImageSets í´ë” êµ¬ì¡° ë° ë‚´ìš©

**Main í´ë” (63ê°œ íŒŒì¼)**:
Main í´ë”ì—ëŠ” ê°ì²´ ê²€ì¶œ ë° ë¶„ë¥˜ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ë¶„í•  ì •ë³´ê°€ ë‹´ê²¨ìˆìŠµë‹ˆë‹¤.

```
ImageSets/Main/
â”œâ”€â”€ train.txt              # í›ˆë ¨ìš© ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
â”œâ”€â”€ val.txt                # ê²€ì¦ìš© ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸  
â”œâ”€â”€ trainval.txt           # í›ˆë ¨+ê²€ì¦ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
â”œâ”€â”€ aeroplane_train.txt    # ë¹„í–‰ê¸° í´ë˜ìŠ¤ë³„ í›ˆë ¨ ë°ì´í„°
â”œâ”€â”€ aeroplane_val.txt      # ë¹„í–‰ê¸° í´ë˜ìŠ¤ë³„ ê²€ì¦ ë°ì´í„°
â”œâ”€â”€ aeroplane_trainval.txt # ë¹„í–‰ê¸° í´ë˜ìŠ¤ë³„ ì „ì²´ ë°ì´í„°
â”œâ”€â”€ [í´ë˜ìŠ¤ëª…]_train.txt   # ê° 20ê°œ í´ë˜ìŠ¤ë³„ í›ˆë ¨ ë°ì´í„°
â”œâ”€â”€ [í´ë˜ìŠ¤ëª…]_val.txt     # ê° 20ê°œ í´ë˜ìŠ¤ë³„ ê²€ì¦ ë°ì´í„°
â””â”€â”€ [í´ë˜ìŠ¤ëª…]_trainval.txt # ê° 20ê°œ í´ë˜ìŠ¤ë³„ ì „ì²´ ë°ì´í„°
```

íŒŒì¼ ë‚´ìš© ì˜ˆì‹œ:
```
# train.txt (ì´ë¯¸ì§€ IDë§Œ ì €ì¥)
2007_000027
2007_000032
2007_000042
...

# aeroplane_trainval.txt (ì´ë¯¸ì§€ ID + í•´ë‹¹ í´ë˜ìŠ¤ ì¡´ì¬ ì—¬ë¶€)
2007_000027 -1    # -1: ë¹„í–‰ê¸°ê°€ ì—†ìŒ
2007_000032  1    #  1: ë¹„í–‰ê¸°ê°€ ìˆìŒ
2007_000042 -1    # -1: ë¹„í–‰ê¸°ê°€ ì—†ìŒ
...
```

**Action í´ë” (33ê°œ íŒŒì¼)**:
ì‚¬ëŒì˜ í–‰ë™ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„° ë¶„í•  ì •ë³´ì…ë‹ˆë‹¤.

**VOC 2012 ì•¡ì…˜ ë¶„ë¥˜ 10ê°œ ì¹´í…Œê³ ë¦¬**:
- jumping (ì í”„í•˜ê¸°)
- phoning (ì „í™”í•˜ê¸°)  
- playinginstrument (ì•…ê¸° ì—°ì£¼í•˜ê¸°)
- reading (ë…ì„œí•˜ê¸°)
- ridingbike (ìì „ê±°/ì˜¤í† ë°”ì´ íƒ€ê¸°)
- ridinghorse (ë§ íƒ€ê¸°)
- running (ë‹¬ë¦¬ê¸°)
- takingphoto (ì‚¬ì§„ ì´¬ì˜í•˜ê¸°)
- usingcomputer (ì»´í“¨í„° ì‚¬ìš©í•˜ê¸°)
- walking (ê±·ê¸°)

ì•¡ì…˜ íŒŒì¼ ë‚´ìš© ì˜ˆì‹œ:
```
# phoning_train.txt (ì´ë¯¸ì§€ ID + ê°ì²´ ì¸ë±ìŠ¤ + ì•¡ì…˜ ì—¬ë¶€)
2010_006215 1  1   # ì´ë¯¸ì§€ 2010_006215ì˜ 1ë²ˆì§¸ ì‚¬ëŒì´ ì „í™” ì¤‘
2010_006217 1 -1   # ì´ë¯¸ì§€ 2010_006217ì˜ 1ë²ˆì§¸ ì‚¬ëŒì´ ì „í™”í•˜ì§€ ì•ŠìŒ
2010_006217 2 -1   # ì´ë¯¸ì§€ 2010_006217ì˜ 2ë²ˆì§¸ ì‚¬ëŒì´ ì „í™”í•˜ì§€ ì•ŠìŒ
...
```

### 3.3. ê³ ê¸‰ ì‚¬ìš©ë²•

#### 3.3.1. ë°ì´í„° ë³€í™˜ ì ìš©

```python
from torchvision import transforms
from PIL import Image
import numpy as np

# ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜
image_transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# íƒ€ê²Ÿ ë³€í™˜ ì •ì˜ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ìš©)
target_transform = transforms.Compose([
    transforms.Resize((512, 512), interpolation=Image.NEAREST),
    transforms.ToTensor()
])

# ë³€í™˜ì´ ì ìš©ëœ ë°ì´í„°ì…‹
dataset = datasets.VOCSegmentation(
    root='./data',
    year='2012',
    image_set='trainval',
    download=True,
    transform=image_transform,
    target_transform=target_transform
)
```

#### 3.3.2. DataLoaderì™€ í•¨ê»˜ ì‚¬ìš©

```python
from torch.utils.data import DataLoader

# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ DataLoader(ë°ì´í„°ë¡œë”) ì„¤ì •
dataloader = DataLoader(
    dataset,
    batch_size=8,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)

# ë°°ì¹˜ ë°ì´í„° ë¡œë”© ì˜ˆì œ
for batch_idx, (images, targets) in enumerate(dataloader):
    print(f"ë°°ì¹˜ {batch_idx}: ì´ë¯¸ì§€ shape {images.shape}, íƒ€ê²Ÿ shape {targets.shape}")
    if batch_idx == 0:  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í™•ì¸
        break
```

## 4. ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ

### 4.1. ê¸°ë³¸ ë°ì´í„° ë¡œë”© (Kaggle Hub ì‚¬ìš©)

```python
import matplotlib.pyplot as plt
import numpy as np
import os
import shutil
import kagglehub
from torchvision import datasets

def setup_and_load_voc():
    """VOC ë°ì´í„°ì…‹ ì„¤ì • ë° ë¡œë”©"""
    
    # Kaggle Hubì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    path = kagglehub.dataset_download("likhon148/visual-object-classes-voc-12")
    
    voc2012_path = os.path.join(path, "VOC2012")
    vocdevkit_path = os.path.join(path, "VOCdevkit")
    
    # ë””ë ‰í„°ë¦¬ êµ¬ì¡° ì¬êµ¬ì„±
    if os.path.exists(voc2012_path) and not os.path.exists(vocdevkit_path):
        os.makedirs(vocdevkit_path, exist_ok=True)
        try:
            shutil.move(voc2012_path, vocdevkit_path)
        except Exception as e:
            print(f"shutil.move ì˜¤ë¥˜: {e}")
            try:
                os.rename(voc2012_path, os.path.join(vocdevkit_path, "VOC2012"))
            except Exception as e2:
                print(f"os.rename ì˜¤ë¥˜: {e2}")
    
    # ë°ì´í„°ì…‹ ë¡œë”©
    dataset = datasets.VOCSegmentation(
        root=path,
        year='2012',
        image_set='train',
        download=False
    )
    
    return dataset

def visualize_voc_sample(dataset, sample_idx=100):
    """VOC ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™”"""
    
    image, mask = dataset[sample_idx]
    
    plt.figure(figsize=(15, 5))
    
    # ì›ë³¸ ì´ë¯¸ì§€
    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title('Original Image')
    plt.axis('off')
    
    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬
    plt.subplot(1, 3, 2)
    mask_array = np.array(mask)
    plt.imshow(mask_array, cmap='tab20')
    plt.title('Segmentation Mask')
    plt.axis('off')
    
    # ë§ˆìŠ¤í¬ í†µê³„
    unique_values = np.unique(mask_array)
    print(f"ë§ˆìŠ¤í¬ ë‚´ í´ë˜ìŠ¤ ID: {unique_values}")
    print(f"ë°°ê²½(0) í”½ì…€ ìˆ˜: {np.sum(mask_array == 0)}")
    print(f"ê²½ê³„(255) í”½ì…€ ìˆ˜: {np.sum(mask_array == 255)}")
    
    # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
    plt.subplot(1, 3, 3)
    plt.imshow(image)
    plt.imshow(mask_array, alpha=0.5, cmap='tab20')
    plt.title('Overlay')
    plt.axis('off')
    
    plt.tight_layout()
    plt.show()

# ì‚¬ìš© ì˜ˆì œ
try:
    dataset = setup_and_load_voc()
    print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}")
    
    # ìƒ˜í”Œ ì‹œê°í™”
    visualize_voc_sample(dataset, 50)
    
except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
```

### 4.2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í•™ìŠµìš© íŒŒì´í”„ë¼ì¸

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms

class SegmentationDataset:
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ë˜í¼"""
    
    def __init__(self, root, year='2012', image_set='trainval', img_size=512):
        self.img_size = img_size
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        self.image_transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬
        self.mask_transform = transforms.Compose([
            transforms.Resize((img_size, img_size), interpolation=Image.NEAREST),
            self.mask_to_tensor
        ])
        
        # VOC ë°ì´í„°ì…‹ ë¡œë”©
        self.dataset = datasets.VOCSegmentation(
            root=root,
            year=year,
            image_set=image_set,
            download=False,
            transform=self.image_transform,
            target_transform=self.mask_transform
        )
    
    def mask_to_tensor(self, mask):
        """ë§ˆìŠ¤í¬ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ê³  í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ì¡°ì •"""
        mask = np.array(mask)
        mask[mask == 255] = 0  # ê²½ê³„ í”½ì…€ì„ ë°°ê²½ìœ¼ë¡œ ì²˜ë¦¬
        return torch.LongTensor(mask)
    
    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, idx):
        return self.dataset[idx]

def create_dataloaders(root='./data', batch_size=8, num_workers=4):
    """í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ë¡œë” ìƒì„±"""
    
    # í›ˆë ¨ìš© ë°ì´í„°ì…‹
    train_dataset = SegmentationDataset(
        root=root,
        year='2012',
        image_set='train'
    )
    
    # ê²€ì¦ìš© ë°ì´í„°ì…‹
    val_dataset = SegmentationDataset(
        root=root,
        year='2012',
        image_set='val'
    )
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, val_loader

# ì‚¬ìš© ì˜ˆì œ
train_loader, val_loader = create_dataloaders()
print(f"í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
print(f"ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")
```

### 4.3. VOC ì»¬ëŸ¬ë§µ ë° ì‹œê°í™”

```python
import numpy as np
import matplotlib.pyplot as plt

def create_voc_colormap():
    """VOC í‘œì¤€ ì»¬ëŸ¬ë§µ ìƒì„± (256ìƒ‰)"""
    def bit_get(val, idx):
        return (val >> idx) & 1
    
    colormap = np.zeros((256, 3), dtype=np.uint8)
    for i in range(256):
        r = g = b = 0
        c = i
        for j in range(8):
            r |= bit_get(c, 0) << (7 - j)
            g |= bit_get(c, 1) << (7 - j)
            b |= bit_get(c, 2) << (7 - j)
            c >>= 3
        colormap[i] = [r, g, b]
    return colormap

# VOC ê³µì‹ ì»¬ëŸ¬ë§µ (ì²˜ìŒ 21ê°œ í´ë˜ìŠ¤)
VOC_COLORMAP = [
    (0, 0, 0),         # 0: background
    (128, 0, 0),       # 1: aeroplane
    (0, 128, 0),       # 2: bicycle
    (128, 128, 0),     # 3: bird
    (0, 0, 128),       # 4: boat
    (128, 0, 128),     # 5: bottle
    (0, 128, 128),     # 6: bus
    (128, 128, 128),   # 7: car
    (64, 0, 0),        # 8: cat
    (192, 0, 0),       # 9: chair
    (64, 128, 0),      # 10: cow
    (192, 128, 0),     # 11: diningtable
    (64, 0, 128),      # 12: dog
    (192, 0, 128),     # 13: horse
    (64, 128, 128),    # 14: motorbike
    (192, 128, 128),   # 15: person
    (0, 64, 0),        # 16: pottedplant
    (128, 64, 0),      # 17: sheep
    (0, 192, 0),       # 18: sofa
    (128, 192, 0),     # 19: train
    (0, 64, 128),      # 20: tvmonitor
]

VOC_CLASSES = [
    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',
    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

def visualize_with_voc_colormap(image, mask, title="VOC Segmentation"):
    """VOC ê³µì‹ ì»¬ëŸ¬ë§µì„ ì‚¬ìš©í•œ ì‹œê°í™”"""
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # ì›ë³¸ ì´ë¯¸ì§€
    axes[0].imshow(image)
    axes[0].set_title('Original Image')
    axes[0].axis('off')
    
    # ë§ˆìŠ¤í¬ (ê³µì‹ ì»¬ëŸ¬ë§µ)
    mask_colored = np.zeros((*mask.shape, 3), dtype=np.uint8)
    for class_id in range(len(VOC_COLORMAP)):
        mask_colored[mask == class_id] = VOC_COLORMAP[class_id]
    
    axes[1].imshow(mask_colored)
    axes[1].set_title('Segmentation Mask (VOC Colors)')
    axes[1].axis('off')
    
    # ì˜¤ë²„ë ˆì´
    axes[2].imshow(image)
    axes[2].imshow(mask_colored, alpha=0.5)
    axes[2].set_title('Overlay')
    axes[2].axis('off')
    
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()
    
    # í´ë˜ìŠ¤ í†µê³„ ì¶œë ¥
    unique_classes = np.unique(mask)
    print("ê°ì§€ëœ í´ë˜ìŠ¤:")
    for class_id in unique_classes:
        if class_id < len(VOC_CLASSES):
            class_name = VOC_CLASSES[class_id]
            pixel_count = np.sum(mask == class_id)
            print(f"  {class_id}: {class_name} ({pixel_count} pixels)")

def apply_colormap_to_mask(mask):
    """ë§ˆìŠ¤í¬ì— VOC ì»¬ëŸ¬ë§µ ì ìš©"""
    mask = np.array(mask)
    colored_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)
    
    for i, color in enumerate(VOC_COLORMAP[:21]):  # 21ê°œ í´ë˜ìŠ¤ë§Œ ì‚¬ìš©
        colored_mask[mask == i] = color
    
    return colored_mask
```

### 4.4. XML ì–´ë…¸í…Œì´ì…˜ íŒŒì‹±

```python
import xml.etree.ElementTree as ET
from PIL import Image
import os

def parse_voc_xml(xml_file_path):
    """VOC XML ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ íŒŒì‹±"""
    
    tree = ET.parse(xml_file_path)
    root = tree.getroot()
    
    # ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
    filename = root.find('filename').text
    size_info = root.find('size')
    width = int(size_info.find('width').text)
    height = int(size_info.find('height').text)
    depth = int(size_info.find('depth').text)
    
    # ê°ì²´ ì •ë³´ ì¶”ì¶œ
    objects = []
    for obj in root.findall('object'):
        name = obj.find('n').text
        pose = obj.find('pose').text
        truncated = int(obj.find('truncated').text)
        difficult = int(obj.find('difficult').text)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´
        bbox = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        
        objects.append({
            'name': name,
            'pose': pose,
            'truncated': truncated,
            'difficult': difficult,
            'bbox': [xmin, ymin, xmax, ymax]
        })
    
    return {
        'filename': filename,
        'size': {'width': width, 'height': height, 'depth': depth},
        'objects': objects
    }

def load_voc_annotations(annotations_dir):
    """VOC ì–´ë…¸í…Œì´ì…˜ ë””ë ‰í„°ë¦¬ì—ì„œ ëª¨ë“  XML íŒŒì¼ ë¡œë”©"""
    
    annotations = {}
    xml_files = [f for f in os.listdir(annotations_dir) if f.endswith('.xml')]
    
    for xml_file in xml_files:
        xml_path = os.path.join(annotations_dir, xml_file)
        image_id = xml_file.replace('.xml', '')
        annotations[image_id] = parse_voc_xml(xml_path)
    
    return annotations

def visualize_xml_annotation(image_path, xml_path):
    """XML ì–´ë…¸í…Œì´ì…˜ì„ ì‹œê°í™”"""
    
    # ì´ë¯¸ì§€ ë¡œë”©
    image = Image.open(image_path)
    
    # XML íŒŒì‹±
    annotation = parse_voc_xml(xml_path)
    
    # ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    plt.imshow(image)
    
    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    ax = plt.gca()
    for obj in annotation['objects']:
        bbox = obj['bbox']
        rect = plt.Rectangle(
            (bbox[0], bbox[1]), 
            bbox[2] - bbox[0], 
            bbox[3] - bbox[1],
            fill=False, 
            color='red', 
            linewidth=2
        )
        ax.add_patch(rect)
        
        # í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
        plt.text(
            bbox[0], bbox[1] - 5,
            f"{obj['name']}",
            bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7),
            fontsize=10
        )
    
    plt.title(f"Annotation: {annotation['filename']}")
    plt.axis('off')
    plt.tight_layout()
    plt.show()
    
    # ê°ì²´ ì •ë³´ ì¶œë ¥
    print(f"ì´ë¯¸ì§€ í¬ê¸°: {annotation['size']}")
    print(f"ê°ì²´ ìˆ˜: {len(annotation['objects'])}")
    for i, obj in enumerate(annotation['objects']):
        print(f"ê°ì²´ {i+1}: {obj['name']} - {obj['bbox']}")

# ì‚¬ìš© ì˜ˆì œ
def demo_xml_parsing(voc_root):
    """XML íŒŒì‹± ë°ëª¨"""
    
    annotations_dir = os.path.join(voc_root, "VOCdevkit/VOC2012/Annotations")
    images_dir = os.path.join(voc_root, "VOCdevkit/VOC2012/JPEGImages")
    
    # ì²« ë²ˆì§¸ XML íŒŒì¼ ì„ íƒ
    xml_files = [f for f in os.listdir(annotations_dir) if f.endswith('.xml')][:5]
    
    for xml_file in xml_files:
        image_id = xml_file.replace('.xml', '')
        xml_path = os.path.join(annotations_dir, xml_file)
        image_path = os.path.join(images_dir, f"{image_id}.jpg")
        
        if os.path.exists(image_path):
            print(f"\n=== {image_id} ===")
            visualize_xml_annotation(image_path, xml_path)
            break
```

## 5. ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì…ë³„ ì°¨ì´ì 

### 5.1. SegmentationClass vs SegmentationObject

VOC ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°œë… ì¤‘ í•˜ë‚˜ëŠ” ë‘ ê°€ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì…ì˜ ì°¨ì´ì…ë‹ˆë‹¤:

#### **SegmentationClass (Semantic Segmentation, ì‹œë§¨í‹± ì„¸ê·¸ë©˜í…Œì´ì…˜)**
- **ëª©ì **: í´ë˜ìŠ¤ë³„ ì˜ë¯¸ë¡ ì  ì„¸ê·¸ë©˜í…Œì´ì…˜
- **íŠ¹ì§•**: ê°™ì€ í´ë˜ìŠ¤ì˜ ëª¨ë“  ê°ì²´ë¥¼ ê°™ì€ ìƒ‰ìƒ/IDë¡œ í‘œí˜„

```python
# SegmentationClass ì˜ˆì‹œ
# ì´ë¯¸ì§€ì— ìë™ì°¨ 3ëŒ€ê°€ ìˆë‹¤ë©´
í”½ì…€ê°’ 0 = ë°°ê²½ (background)
í”½ì…€ê°’ 7 = ëª¨ë“  ìë™ì°¨ (car class) - ëª‡ ëŒ€ë“  ìƒê´€ì—†ì´
í”½ì…€ê°’ 15 = ëª¨ë“  ì‚¬ëŒ (person class) - ëª‡ ëª…ì´ë“  ìƒê´€ì—†ì´
í”½ì…€ê°’ 255 = ê²½ê³„/ë¬´ì‹œí•  í”½ì…€ (void)
```

#### **SegmentationObject (Instance Segmentation, ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜)**
- **ëª©ì **: ê°ì²´ë³„ ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜  
- **íŠ¹ì§•**: ê°™ì€ í´ë˜ìŠ¤ë¼ë„ ê°œë³„ ê°ì²´ë¥¼ ë‹¤ë¥¸ ìƒ‰ìƒ/IDë¡œ êµ¬ë¶„

```python
# SegmentationObject ì˜ˆì‹œ  
# ì´ë¯¸ì§€ì— ìë™ì°¨ 3ëŒ€ê°€ ìˆë‹¤ë©´
í”½ì…€ê°’ 0 = ë°°ê²½ (background)
í”½ì…€ê°’ 1 = ì²« ë²ˆì§¸ ê°ì²´ (í´ë˜ìŠ¤ ë¬´ê´€)
í”½ì…€ê°’ 2 = ë‘ ë²ˆì§¸ ê°ì²´ (í´ë˜ìŠ¤ ë¬´ê´€)
í”½ì…€ê°’ 3 = ì„¸ ë²ˆì§¸ ê°ì²´ (í´ë˜ìŠ¤ ë¬´ê´€)
...
í”½ì…€ê°’ 255 = ê²½ê³„/ë¬´ì‹œí•  í”½ì…€ (void)
```

### 5.2. ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ

```python
def compare_segmentation_types(voc_root, image_id="2007_000032"):
    """SegmentationClassì™€ SegmentationObject ë¹„êµ"""
    
    # ê²½ë¡œ ì„¤ì •
    image_path = os.path.join(voc_root, f"VOCdevkit/VOC2012/JPEGImages/{image_id}.jpg")
    class_path = os.path.join(voc_root, f"VOCdevkit/VOC2012/SegmentationClass/{image_id}.png")
    object_path = os.path.join(voc_root, f"VOCdevkit/VOC2012/SegmentationObject/{image_id}.png")
    
    # ì´ë¯¸ì§€ ë¡œë”©
    image = Image.open(image_path)
    class_mask = np.array(Image.open(class_path))
    object_mask = np.array(Image.open(object_path))
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # ì›ë³¸ ì´ë¯¸ì§€
    axes[0, 0].imshow(image)
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')
    
    # SegmentationClass
    axes[0, 1].imshow(apply_colormap_to_mask(class_mask))
    axes[0, 1].set_title('SegmentationClass\n(Semantic Segmentation)')
    axes[0, 1].axis('off')
    
    # SegmentationObject  
    axes[1, 0].imshow(object_mask, cmap='tab20')
    axes[1, 0].set_title('SegmentationObject\n(Instance Segmentation)')
    axes[1, 0].axis('off')
    
    # í†µê³„ ë¹„êµ
    axes[1, 1].axis('off')
    
    # í´ë˜ìŠ¤ í†µê³„
    class_unique = np.unique(class_mask)
    object_unique = np.unique(object_mask)
    
    stats_text = f"""
    SegmentationClass í†µê³„:
    - ê³ ìœ ê°’ ê°œìˆ˜: {len(class_unique)}
    - ê°’ ë²”ìœ„: {class_unique.min()} ~ {class_unique.max()}
    - ê°ì§€ëœ í´ë˜ìŠ¤: {class_unique}
    
    SegmentationObject í†µê³„:
    - ê³ ìœ ê°’ ê°œìˆ˜: {len(object_unique)}  
    - ê°’ ë²”ìœ„: {object_unique.min()} ~ {object_unique.max()}
    - ê°ì²´ ê°œìˆ˜: {len(object_unique[object_unique > 0])}
    """
    
    axes[1, 1].text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center')
    axes[1, 1].set_title('Statistics Comparison')
    
    plt.tight_layout()
    plt.show()
    
    return class_mask, object_mask

# ì‚¬ìš©ë²• ë¹„êµ í‘œ
def print_usage_comparison():
    """ì‚¬ìš© ëª©ì ë³„ ë¹„êµ í…Œì´ë¸” ì¶œë ¥"""
    
    comparison_data = {
        "íŠ¹ì„±": ["ëª©ì ", "í”½ì…€ê°’ ì˜ë¯¸", "ê°™ì€ í´ë˜ìŠ¤ ê°ì²´", "ì£¼ìš” ìš©ë„", "ëŒ€í‘œ ëª¨ë¸"],
        "SegmentationClass": [
            "Semantic Segmentation",
            "í´ë˜ìŠ¤ ID (0-20, 255)",
            "ëª¨ë‘ ê°™ì€ ê°’",
            "FCN, DeepLab í•™ìŠµ",
            "FCN, U-Net, DeepLabv3+"
        ],
        "SegmentationObject": [
            "Instance Segmentation", 
            "ê°ì²´ ì¸ìŠ¤í„´ìŠ¤ ID (1,2,3...)",
            "ê°ê° ë‹¤ë¥¸ ê°’",
            "Mask R-CNN í•™ìŠµ",
            "Mask R-CNN, YOLACT"
        ]
    }
    
    print("=" * 80)
    print("VOC ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì… ë¹„êµ")
    print("=" * 80)
    
    for i, characteristic in enumerate(comparison_data["íŠ¹ì„±"]):
        print(f"{characteristic:15} | {comparison_data['SegmentationClass'][i]:25} | {comparison_data['SegmentationObject'][i]}")
        
    print("=" * 80)

# ì‹¤ì œ ëª¨ë¸ í•™ìŠµ ì‹œ ì „ì²˜ë¦¬ ì˜ˆì œ
def preprocess_for_training(mask_path, segmentation_type="class"):
    """í•™ìŠµìš© ë§ˆìŠ¤í¬ ì „ì²˜ë¦¬"""
    
    mask = np.array(Image.open(mask_path))
    
    if segmentation_type == "class":
        # Semantic segmentationìš© ì „ì²˜ë¦¬
        mask[mask == 255] = 0  # ê²½ê³„ í”½ì…€ì„ ë°°ê²½ìœ¼ë¡œ ì²˜ë¦¬
        # ë˜ëŠ”: mask[mask == 255] = -1  # ignore_indexë¡œ ì„¤ì •
        processed_mask = torch.LongTensor(mask)
        
    elif segmentation_type == "object":
        # Instance segmentationìš© ì „ì²˜ë¦¬
        # ê° ê°ì²´ë¥¼ ê°œë³„ ë§ˆìŠ¤í¬ë¡œ ë¶„ë¦¬
        unique_objects = np.unique(mask)
        unique_objects = unique_objects[unique_objects > 0]  # ë°°ê²½ ì œì™¸
        
        instance_masks = []
        for obj_id in unique_objects:
            instance_mask = (mask == obj_id).astype(np.uint8)
            instance_masks.append(torch.tensor(instance_mask))
        
        processed_mask = torch.stack(instance_masks) if instance_masks else torch.empty(0, *mask.shape)
    
    return processed_mask
```

## 6. ë²¤ì¹˜ë§ˆí‚¹ ë° í‰ê°€

### 6.1. í‘œì¤€ í‰ê°€ ë©”íŠ¸ë¦­

VOC 2012 ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒœìŠ¤í¬(Task, íƒœìŠ¤í¬)ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë©”íŠ¸ë¦­(Metric, ë©”íŠ¸ë¦­)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

#### **ì£¼ìš” ë©”íŠ¸ë¦­ë“¤**

- **Mean Intersection over Union (mIoU, ì— ì•„ì´ì˜¤ìœ )**: í‰ê·  êµì§‘í•© ëŒ€ë¹„ í•©ì§‘í•© ë¹„ìœ¨
- **Pixel Accuracy**: í”½ì…€ ë‹¨ìœ„ ì •í™•ë„
- **Mean Accuracy**: í´ë˜ìŠ¤ë³„ í‰ê·  ì •í™•ë„
- **Frequency Weighted IoU**: ë¹ˆë„ ê°€ì¤‘ IoU

$\text{IoU} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive} + \text{False Negative}}$

$\text{mIoU} = \frac{1}{N} \sum_{i=1}^{N} \text{IoU}_i$

$\text{Pixel Accuracy} = \frac{\sum_{i=1}^{N} n_{ii}}{\sum_{i=1}^{N} \sum_{j=1}^{N} n_{ij}}$

```python
def calculate_iou_metrics(pred_mask, true_mask, num_classes=21):
    """IoU ë©”íŠ¸ë¦­ ê³„ì‚°"""
    
    # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
    mask = (true_mask >= 0) & (true_mask < num_classes)
    hist = np.bincount(
        num_classes * true_mask[mask].astype(int) + pred_mask[mask],
        minlength=num_classes ** 2
    ).reshape(num_classes, num_classes)
    
    # IoU ê³„ì‚°
    ious = []
    for i in range(num_classes):
        tp = hist[i, i]  # True Positive
        fp = hist[:, i].sum() - tp  # False Positive  
        fn = hist[i, :].sum() - tp  # False Negative
        
        if tp + fp + fn == 0:
            iou = float('nan')
        else:
            iou = tp / (tp + fp + fn)
        ious.append(iou)
    
    # ìœ íš¨í•œ IoU ê°’ë“¤ë¡œ mIoU ê³„ì‚°
    valid_ious = [iou for iou in ious if not np.isnan(iou)]
    mean_iou = np.mean(valid_ious) if valid_ious else 0.0
    
    # Pixel Accuracy
    pixel_acc = np.diag(hist).sum() / hist.sum()
    
    # Mean Accuracy
    acc_per_class = np.diag(hist) / hist.sum(axis=1)
    acc_per_class = acc_per_class[~np.isnan(acc_per_class)]
    mean_acc = np.mean(acc_per_class)
    
    return {
        'mIoU': mean_iou,
        'Pixel_Accuracy': pixel_acc,
        'Mean_Accuracy': mean_acc,
        'IoU_per_class': ious
    }

def evaluate_model_performance(model, dataloader, device, num_classes=21):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for images, targets in dataloader:
            images = images.to(device)
            targets = targets.to(device)
            
            outputs = model(images)
            preds = torch.argmax(outputs, dim=1)
            
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
    
    # ì „ì²´ ê²°ê³¼ì— ëŒ€í•´ ë©”íŠ¸ë¦­ ê³„ì‚°
    all_preds = np.concatenate(all_preds)
    all_targets = np.concatenate(all_targets)
    
    metrics = calculate_iou_metrics(all_preds, all_targets, num_classes)
    return metrics
```

### 6.2. í˜„ì¬ State-of-the-Art

2025ë…„ í˜„ì¬ PASCAL VOC 2012 í…ŒìŠ¤íŠ¸ì…‹ì—ì„œì˜ ìµœê³  ì„±ëŠ¥:

#### **ì£¼ìš” ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ**

| Model | Year | mIoU (%) | íŠ¹ì§• |
|-------|------|----------|------|
| **DeepLabv3+ (Xception-65-JFT)** | 2018 | **89.0** | í˜„ì¬ ìµœê³  ì„±ëŠ¥ |
| DeepLabv3 (ResNet-101) | 2017 | 85.7 | Atrous convolution |
| PSPNet (ResNet-101) | 2017 | 85.4 | Pyramid pooling |
| FCN (VGG-16) | 2015 | 67.2 | ì´ˆê¸° end-to-end ëª¨ë¸ |
| U-Net | 2015 | 72.0 | Skip connection |
| SegNet | 2017 | 60.1 | Encoder-decoder |

#### **ìµœì‹  íŠ¸ë Œë“œ ë° ê¸°ë²•ë“¤**

```python
# ìµœì‹  ëª¨ë¸ë“¤ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ê¸°ë²•ë“¤
SOTA_TECHNIQUES = {
    "Attention Mechanisms": [
        "Self-Attention (Non-local Networks)",
        "Channel Attention (SE-Net)",
        "Spatial Attention (CBAM)"
    ],
    "Multi-Scale Processing": [
        "Atrous Spatial Pyramid Pooling (ASPP)",
        "Feature Pyramid Network (FPN)", 
        "Pyramid Scene Parsing (PSP)"
    ],
    "Advanced Training": [
        "Mixed Precision Training",
        "Knowledge Distillation",
        "Self-Training with Pseudo Labels",
        "Test Time Augmentation (TTA)"
    ],
    "Data Augmentation": [
        "CutMix", "MixUp", "AugMax",
        "Copy-Paste for Segmentation"
    ]
}

def print_sota_summary():
    """SOTA ëª¨ë¸ ë° ê¸°ë²• ìš”ì•½"""
    
    print("ğŸ† PASCAL VOC 2012 Semantic Segmentation SOTA")
    print("=" * 60)
    print("Best Model: DeepLabv3+ (Xception-65-JFT)")
    print("Best mIoU: 89.0%")
    print("Key Innovation: Encoder-Decoder + Atrous Convolution")
    print()
    
    for category, techniques in SOTA_TECHNIQUES.items():
        print(f"ğŸ“‹ {category}:")
        for tech in techniques:
            print(f"   â€¢ {tech}")
        print()
```

---

## ìš©ì–´ ëª©ë¡

| ìš©ì–´ | ì˜ë¬¸ | ì„¤ëª… |
|------|------|------|
| ì˜ë¯¸ë¡ ì  ì„¸ê·¸ë©˜í…Œì´ì…˜ | Semantic Segmentation | ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì„ ì˜ë¯¸ë¡ ì  í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—… |
| ì¸ìŠ¤í„´ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜ | Instance Segmentation | ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œë„ ê°œë³„ ê°ì²´ë¥¼ êµ¬ë¶„í•˜ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ |
| ê´€ì‹¬ ì˜ì—­ | Region of Interest (ROI) | ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ê°ì²´ê°€ ìœ„ì¹˜í•œ ì˜ì—­ |
| ì–´ë…¸í…Œì´ì…˜ | Annotation | ë°ì´í„°ì— ëŒ€í•œ ë¼ë²¨ë§ ë˜ëŠ” ì£¼ì„ ì •ë³´ |
| ì‹¤ì¸¡ê°’ | Ground Truth | ì •ë‹µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì‹¤ì œ ë¼ë²¨ ë°ì´í„° |
| êµì§‘í•© ëŒ€ë¹„ í•©ì§‘í•© | Intersection over Union (IoU) | ì˜ˆì¸¡ ì˜ì—­ê³¼ ì‹¤ì œ ì˜ì—­ì˜ ê²¹ì¹˜ëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ |
| í‰ê·  ì •ë°€ë„ | Mean Average Precision (mAP) | ê°ì²´ ê²€ì¶œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” í‘œì¤€ ì§€í‘œ |
| ë³€í™˜ | Transform | ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€í™˜ í•¨ìˆ˜ |
| ë°ì´í„°ë¡œë” | DataLoader | ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ëŠ” PyTorch ìœ í‹¸ë¦¬í‹°(ìœ í‹¸ë¦¬í‹°) |
| ë²¤ì¹˜ë§ˆí¬ | Benchmark | ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•œ í‘œì¤€ ë°ì´í„°ì…‹ |
| ìºê¸€ í—ˆë¸Œ | Kaggle Hub | Kaggleì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ |
| ë””ë ‰í„°ë¦¬ êµ¬ì¡° | Directory Structure | íŒŒì¼ê³¼ í´ë”ì˜ ê³„ì¸µì  ì¡°ì§ êµ¬ì¡° |
| ì•ˆì •ì  ë‹¤ìš´ë¡œë“œ | Robust Download | ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì— ê°•ê±´í•œ ë‹¤ìš´ë¡œë“œ ë°©ì‹ |
| ì•„íŠ¸ëŸ¬ìŠ¤ ì»¨ë³¼ë£¨ì…˜ | Atrous Convolution | í™•ì¥ëœ í•©ì„±ê³±ìœ¼ë¡œ ìˆ˜ìš©ì¥ì„ ë„“íˆëŠ” ê¸°ë²•