{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLpmc82djeIE"
   },
   "source": [
    "- 작성자: 김명환 (Kim Myunghwan)\n",
    "- 작성일: 2025년 7월 9일\n",
    "- 목적: matplotlib.pyplot에서 한글 폰트가 깨지지 않도록 설정한 템플릿\n",
    "- github: https://github.com/c0z0c/jupyter_hangul\n",
    "- 환경: Jupyter Notebook 및 Google Colab 겸용\n",
    "- 자유롭게 편집해서 사용하세요\n",
    "\n",
    "**한글 폰트 설정 셀**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1752576334995,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "WE6336hF11C5",
    "outputId": "4568d40b-c790-4a97-80cc-b16d8a572e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 helper 모듈을 로드했습니다.\n",
      "🚀 Jupyter/Colab 한글 환경 설정 중... (helper v2.3.0)\n",
      "✅ matplotlib 한글 폰트 설정 완료\n",
      "✅ 한글 폰트 및 pandas 확장 기능 설정 완료\n",
      "🎉 사용 가능: 한글 폰트, CSV 읽기, DataFrame.head_att(), 캐시 기능\n"
     ]
    }
   ],
   "source": [
    "# coalb 에서는 두번 실행 해야 합니다.\n",
    "# 첫 번째 실행 - 폰트 설치 후 자동 재시작\n",
    "# 두번째 실행 - 폰트 설치 완료\n",
    "# https://github.com/c0z0c/jupyter_hangul\n",
    "# 코딩 중간에 한글 깨진다 싶으면 helper.setup() 다시 호출 해줘도 됩니다.\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/master/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import helper_c0z0c_dev as helper\n",
    "print(\"📁 helper 모듈을 로드했습니다.\")\n",
    "helper.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >기본< 라이브리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels 라이브러리 로드 완료\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# --- 다중공선성 진단용 (선택적) ---\n",
    "try:\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print(\"statsmodels 라이브러리 로드 완료\")\n",
    "except Exception:\n",
    "    print(\"statsmodels 라이브러리가 설치되어 있지 않습니다. 설치: !pip install statsmodels\")\n",
    "\n",
    "# --- 표준 라이브러리 및 유틸리티 ---\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import pytz  # 시간대 처리\n",
    "\n",
    "# --- 이미지 처리 ---\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import cv2  # 필요시 설치: !pip install opencv-python\n",
    "\n",
    "# --- 데이터/시각화 ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- PyTorch 관련 ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# --- 선택 패키지(주석) ---\n",
    "# !pip install pytorch-msssim\n",
    "\n",
    "# --- 시드 고정 ---\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# --- 디바이스 및 전역 설정 ---\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "global __kst\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global __device\n",
    "print('Device:', __device)\n",
    "\n",
    "__model_class_list = []\n",
    "global __model_class_list\n",
    "\n",
    "DEBUG_ON = False\n",
    "global DEBUG_ON\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >기본< 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_makedirs(path):\n",
    "    if os.path.exists(path) and not os.path.isdir(path):\n",
    "        os.remove(path)  # 파일이면 삭제\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "def tensor_to_jsonable(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.item() if obj.numel() == 1 else obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: tensor_to_jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [tensor_to_jsonable(v) for v in obj]\n",
    "    return obj   \n",
    "\n",
    "def save_model_dict(model, path, pth_name, kwargs=None):\n",
    "    \"\"\"\n",
    "    모델 state_dict와 추가 정보를 지정한 디렉토리(path)에 name.pth 파일로 저장\n",
    "    - model: 저장할 모델 객체\n",
    "    - path: 저장할 디렉토리 경로 (예: './save')\n",
    "    - name: 저장할 파일 이름 (확장자 없이, 예: 'model1')\n",
    "    - kwargs: dict 또는 JSON 문자열(딕셔너리로 변환 가능한 객체)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    # 디렉토리 생성\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # 모델 구조 정보 추출\n",
    "    model_info = {\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'init_args': {},  # 생성자 인자(가능하면)\n",
    "        'str': str(model),\n",
    "        'repr': repr(model),\n",
    "        'modules': [m.__class__.__name__ for m in model.modules()],\n",
    "    }\n",
    "    # 생성자 인자 자동 추출(가능한 경우)\n",
    "    if hasattr(model, '__dict__'):\n",
    "        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n",
    "            if hasattr(model, key):\n",
    "                model_info['init_args'][key] = getattr(model, key)\n",
    "\n",
    "    # kwargs 처리\n",
    "    extra_info = {}\n",
    "    if kwargs is not None:\n",
    "        if isinstance(kwargs, str):\n",
    "            extra_info = json.loads(kwargs)\n",
    "        elif isinstance(kwargs, dict):\n",
    "            extra_info = kwargs\n",
    "        else:\n",
    "            raise ValueError(\"kwargs는 dict 또는 JSON 문자열이어야 합니다.\")\n",
    "\n",
    "    # model_info에 kwargs 내용 추가\n",
    "    model_info.update(extra_info)\n",
    "\n",
    "    # 저장할 dict 구성\n",
    "    save_dict = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'model_info': model_info,\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    torch.save(save_dict, save_path)\n",
    "    return save_path\n",
    "\n",
    "def load_model_dict(path, pth_name, model_class=None):\n",
    "    \"\"\"\n",
    "    save_model_dict로 저장한 모델을 로드하는 함수\n",
    "    - path: 저장된 디렉토리 경로 (예: './save')\n",
    "    - pth_name: 저장된 파일 이름 (확장자 없이, 예: 'model1')\n",
    "    - model_class: 모델 클래스 (None이면 모델 인스턴스는 반환하지 않음)\n",
    "    반환값: (model, class_name, model_info)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import os\n",
    "\n",
    "    pth_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    checkpoint = torch.load(pth_path, map_location=__device)\n",
    "    class_name = checkpoint.get('class_name', None)\n",
    "    model_info = checkpoint.get('model_info', {})\n",
    "\n",
    "    model = None\n",
    "    if model_class is not None:\n",
    "        try:\n",
    "            model = model_class().to(__device)\n",
    "            model.load_state_dict(checkpoint['model_state'])\n",
    "        except Exception as e:\n",
    "            print(f\"모델 state_dict 로드 실패: {e}\")\n",
    "            model = None\n",
    "\n",
    "    return model, class_name, model_info\n",
    "\n",
    "def print_model_recovery_guide_from_info(model_info):\n",
    "    \"\"\"\n",
    "    model_info(dict)를 받아서 복구용 클래스 정의 가이드를 출력합니다.\n",
    "    \"\"\"\n",
    "    class_name = model_info.get('class_name', 'UnknownModel')\n",
    "    init_args = model_info.get('init_args', {})\n",
    "    model_str = model_info.get('str', '')\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"[모델 복구 가이드] class_name: {class_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"\\n[1] 복사 붙여넣기용 클래스 정의:\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "    print(\"# 아래 코드를 그대로 복사해서 붙여넣으세요\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "\n",
    "    print(f\"\\nclass {class_name}(nn.Module):\")\n",
    "    print(f\"    def __init__(self, \", end=\"\")\n",
    "    if init_args:\n",
    "        args_list = [f\"{k}={repr(v)}\" for k, v in init_args.items()]\n",
    "        print(\", \".join(args_list) + \"):\")\n",
    "    else:\n",
    "        print(\"in_ch=1, base_ch=64):  # ← 실제 값으로 수정 필요\")\n",
    "    print(\"        super().__init__()\")\n",
    "\n",
    "    if model_str:\n",
    "        print(\"        # 아래는 저장된 구조를 기반으로 한 추정 코드입니다\")\n",
    "        print(\"        # 필요시 수정하세요\")\n",
    "        import re\n",
    "        # Conv2d\n",
    "        conv_matches = re.findall(r'Conv2d\\((\\d+), (\\d+), kernel_size=\\((\\d+), (\\d+)\\)', model_str)\n",
    "        if conv_matches:\n",
    "            print(\"        # Convolution layers:\")\n",
    "            for i, (in_ch, out_ch, k1, k2) in enumerate(conv_matches[:5]):\n",
    "                print(f\"        self.conv{i+1} = nn.Conv2d({in_ch}, {out_ch}, {k1})\")\n",
    "        # Linear\n",
    "        linear_matches = re.findall(r'Linear\\(in_features=(\\d+), out_features=(\\d+)', model_str)\n",
    "        if linear_matches:\n",
    "            print(\"        # Linear layers:\")\n",
    "            for i, (in_feat, out_feat) in enumerate(linear_matches[:3]):\n",
    "                print(f\"        self.fc{i+1} = nn.Linear({in_feat}, {out_feat})\")\n",
    "        # BatchNorm\n",
    "        bn_matches = re.findall(r'BatchNorm2d\\((\\d+)', model_str)\n",
    "        if bn_matches:\n",
    "            print(\"        # BatchNorm layers:\")\n",
    "            for i, (num_feat,) in enumerate(bn_matches[:3]):\n",
    "                print(f\"        self.bn{i+1} = nn.BatchNorm2d({num_feat})\")\n",
    "\n",
    "    print(\"\\n    def forward(self, x):\")\n",
    "    print(\"        # TODO: forward 로직 구현\")\n",
    "    print(\"        # 아래 구조를 참고하여 구현하세요:\")\n",
    "    if model_str:\n",
    "        if \"Conv2d\" in model_str and \"ReLU\" in model_str:\n",
    "            print(\"        # x = F.relu(self.conv1(x))\")\n",
    "            print(\"        # x = F.relu(self.conv2(x))\")\n",
    "        if \"Linear\" in model_str:\n",
    "            print(\"        # x = x.view(x.size(0), -1)  # flatten\")\n",
    "            print(\"        # x = self.fc1(x)\")\n",
    "        if \"Sigmoid\" in model_str:\n",
    "            print(\"        # x = torch.sigmoid(x)\")\n",
    "        elif \"Softmax\" in model_str:\n",
    "            print(\"        # x = F.softmax(x, dim=1)\")\n",
    "    print(\"        return x\")\n",
    "\n",
    "    print(\"\\n# 모델 클래스를 __model_class_list에 등록\")\n",
    "    print(f\"__model_class_list.append({class_name})\")\n",
    "\n",
    "    print(\"\\n# \" + \"=\"*70)\n",
    "    print(\"# 여기까지 복사 붙여넣기\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "    print(\"\\n[2] 사용자 설정 가이드:\")\n",
    "    print(\"# \" + \"-\"*70)\n",
    "    print(\"# 아래 값들을 실제 환경에 맞게 수정하세요\")\n",
    "    print(\"# \" + \"-\"*70)\n",
    "    print(\"\\n# 모델 인스턴스 생성\")\n",
    "    if init_args:\n",
    "        args_str = ', '.join([f\"{k}={repr(v)}\" for k, v in init_args.items()])\n",
    "        print(f\"model = {class_name}({args_str}).to(__device)\")\n",
    "    else:\n",
    "        print(f\"model = {class_name}(\")\n",
    "        print(\"    in_ch=1,     # ← 입력 채널 수 (1=그레이스케일, 3=RGB)\")\n",
    "        print(\"    base_ch=64   # ← 기본 채널 수 (메모리에 따라 32, 64, 128 등)\")\n",
    "        print(\").to(__device)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"복구 가이드 완료! 위 코드를 복사해서 새로운 셀에 붙여넣고 실행하세요.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >기본< 모델링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 함수\n",
    "def train_fn(model, train_loader, criterion, optimizer, device, epoch=None, epochs=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    res = {}\n",
    "    desc = f\"Train [{epoch+1}/{epochs}]\" if epoch is not None and epochs is not None else \"Train\"\n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 1\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 3\n",
    "\n",
    "    pbar = tqdm(train_loader, leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "    \n",
    "    # tqdm_kwargs = {\n",
    "    #     'disable': False,  # 항상 표시\n",
    "    #     'mininterval': 0.5,\n",
    "    #     'leave': True,\n",
    "    #     'desc': desc,\n",
    "    #     'position': 1\n",
    "    # }\n",
    "    # pbar = tqdm(train_loader, **tqdm_kwargs)\n",
    "        \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        # criterion이 기본(reduction='mean')이라 가정하여 샘플 기준 누적\n",
    "        running_loss += loss.item() * batch_size\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    res['loss'] = epoch_loss\n",
    "    res['acc'] = epoch_acc\n",
    "    return res\n",
    "\n",
    "# 검증 함수\n",
    "def evaluate_fn(model, val_loader, criterion, device, epoch, epochs):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    res = {}\n",
    "    desc = f\"Val   [{epoch+1}/{epochs}]\"\n",
    "\n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 1\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 3\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "        \n",
    "        # tqdm_kwargs = {\n",
    "        #     'disable': False,  # 항상 표시\n",
    "        #     'mininterval': 0.5,\n",
    "        #     'leave': True,\n",
    "        #     'desc': desc,\n",
    "        #     'position': 1\n",
    "        # }\n",
    "        # pbar = tqdm(val_loader, **tqdm_kwargs)        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_size\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    res['loss'] = epoch_loss\n",
    "    res['acc'] = epoch_acc\n",
    "    return res\n",
    "\n",
    "# 모델링 함수 (훈련 + 검증)\n",
    "def modeling_fn(model, epochs, train_loader, val_loader, criterion, optimizer, scheduler, device):\n",
    "    history = []\n",
    "    best_val_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    start_time = time.time()\n",
    "    epoch_start_time = None\n",
    "\n",
    "    estimated_completion_str = None\n",
    "    \n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 2\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 6\n",
    "\n",
    "    epoch = 0\n",
    "    desc = f\"Epoch [{epoch+1}/{epochs}]\"\n",
    "    pbar = tqdm(range(epochs), leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        print()\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        pbar.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        \n",
    "        train_res = train_fn(model, train_loader, criterion, optimizer, device, epoch=epoch, epochs=epochs)\n",
    "        val_res = evaluate_fn(model, val_loader, criterion, device, epoch=epoch, epochs=epochs)\n",
    "        if estimated_completion_str is not None:\n",
    "            pbar.set_postfix_str(\"종료 \" + estimated_completion_str)\n",
    "            \n",
    "        # 스케줄러 업데이트\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        res = {\n",
    "            \"epoch\": epoch,\n",
    "            \"epochs\": epochs,\n",
    "            \"train\": train_res,\n",
    "            \"val\": val_res,\n",
    "        }\n",
    "\n",
    "        history.append(res)\n",
    "\n",
    "        # 최고 성능 모델 저장\n",
    "        if val_res['acc'] > best_val_acc:\n",
    "            best_val_acc = val_res['acc']\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # 에포크 완료 시간 계산\n",
    "        epoch_elapsed = time.time() - epoch_start_time\n",
    "\n",
    "        # 첫 번째 에포크 완료 후 예상 완료 시간 계산\n",
    "        if epoch == 0 and epochs > 1:\n",
    "            remaining_epochs = epochs - 1\n",
    "            estimated_total_time = epoch_elapsed * epochs\n",
    "            estimated_completion = datetime.now(__kst) + timedelta(seconds=epoch_elapsed * remaining_epochs)\n",
    "            estimated_completion_str = estimated_completion.strftime('%Y-%m-%d %H:%M:%S KST')\n",
    "            pbar.set_postfix_str(\"종료 \" + estimated_completion_str)\n",
    "            # print(f\"첫 에포크 완료 - 예상 완료 시간: {estimated_completion_str}\")\n",
    "            \n",
    "        \n",
    "        # print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "        #       f\"Train Loss: {train_res['loss']:.4f}, \"\n",
    "        #       f\"Train Acc: {train_res['acc']:.4f} | \"\n",
    "        #       f\"Val Loss: {val_res['loss']:.4f}, \"\n",
    "        #       f\"Val Acc: {val_res['acc']:.4f} \"\n",
    "        #       f\"({epoch_elapsed:.1f}s)\")\n",
    "\n",
    "    # 전체 학습 완료 시간\n",
    "    total_elapsed = time.time() - start_time\n",
    "    completion_time = datetime.now(__kst)\n",
    "\n",
    "    # 최고 성능 모델 가중치 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    # print(f'\\n최고 검증 정확도: {best_val_acc:.4f}')\n",
    "    # print(f'전체 학습 시간: {total_elapsed:.1f}초 ({total_elapsed/60:.1f}분)')\n",
    "    # print(f'학습 완료 시간: {completion_time.strftime(\"%Y-%m-%d %H:%M:%S KST\")}')\n",
    "\n",
    "    return model, history, completion_time, total_elapsed\n",
    "\n",
    "# 테스트 함수\n",
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"모델 테스트\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, leave=True, desc=\"Testing\", position=0)\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # 클래스별 정확도 계산\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    # print(f'전체 테스트 정확도: {accuracy:.2f}%')\n",
    "\n",
    "    # # 클래스별 정확도 출력\n",
    "    # print('\\n클래스별 정확도:')\n",
    "    # for i in range(10):\n",
    "    #     if class_total[i] > 0:\n",
    "    #         print(f'{classes[i]:>8}: {100 * class_correct[i] / class_total[i]:.1f}%')\n",
    "\n",
    "    return accuracy, class_total, classes, class_correct\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
