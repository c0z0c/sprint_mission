{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLpmc82djeIE"
   },
   "source": [
    "- ìž‘ì„±ìž: ê¹€ëª…í™˜ (Kim Myunghwan)\n",
    "- ìž‘ì„±ì¼: 2025ë…„ 7ì›” 9ì¼\n",
    "- ëª©ì : matplotlib.pyplotì—ì„œ í•œê¸€ í°íŠ¸ê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •í•œ í…œí”Œë¦¿\n",
    "- github: https://github.com/c0z0c/jupyter_hangul\n",
    "- í™˜ê²½: Jupyter Notebook ë° Google Colab ê²¸ìš©\n",
    "- ìžìœ ë¡­ê²Œ íŽ¸ì§‘í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "\n",
    "**í•œê¸€ í°íŠ¸ ì„¤ì • ì…€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1752576334995,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "WE6336hF11C5",
    "outputId": "4568d40b-c790-4a97-80cc-b16d8a572e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ helper ëª¨ë“ˆì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\n",
      "ðŸš€ Jupyter/Colab í•œê¸€ í™˜ê²½ ì„¤ì • ì¤‘... (helper v2.3.0)\n",
      "âœ… matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "âœ… í•œê¸€ í°íŠ¸ ë° pandas í™•ìž¥ ê¸°ëŠ¥ ì„¤ì • ì™„ë£Œ\n",
      "ðŸŽ‰ ì‚¬ìš© ê°€ëŠ¥: í•œê¸€ í°íŠ¸, CSV ì½ê¸°, DataFrame.head_att(), ìºì‹œ ê¸°ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "# coalb ì—ì„œëŠ” ë‘ë²ˆ ì‹¤í–‰ í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ - í°íŠ¸ ì„¤ì¹˜ í›„ ìžë™ ìž¬ì‹œìž‘\n",
    "# ë‘ë²ˆì§¸ ì‹¤í–‰ - í°íŠ¸ ì„¤ì¹˜ ì™„ë£Œ\n",
    "# https://github.com/c0z0c/jupyter_hangul\n",
    "# ì½”ë”© ì¤‘ê°„ì— í•œê¸€ ê¹¨ì§„ë‹¤ ì‹¶ìœ¼ë©´ helper.setup() ë‹¤ì‹œ í˜¸ì¶œ í•´ì¤˜ë„ ë©ë‹ˆë‹¤.\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/master/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import helper_c0z0c_dev as helper\n",
    "print(\"ðŸ“ helper ëª¨ë“ˆì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "helper.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >ê¸°ë³¸< ë¼ì´ë¸Œë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# --- ë‹¤ì¤‘ê³µì„ ì„± ì§„ë‹¨ìš© (ì„ íƒì ) ---\n",
    "try:\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print(\"statsmodels ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "except Exception:\n",
    "    print(\"statsmodels ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìžˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì¹˜: !pip install statsmodels\")\n",
    "\n",
    "# --- í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ìœ í‹¸ë¦¬í‹° ---\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import pytz  # ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "# --- ì´ë¯¸ì§€ ì²˜ë¦¬ ---\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import cv2  # í•„ìš”ì‹œ ì„¤ì¹˜: !pip install opencv-python\n",
    "\n",
    "# --- ë°ì´í„°/ì‹œê°í™” ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from IPython.display import display, Markdown\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- PyTorch ê´€ë ¨ ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# --- ì„ íƒ íŒ¨í‚¤ì§€(ì£¼ì„) ---\n",
    "# !pip install pytorch-msssim\n",
    "\n",
    "# --- ì‹œë“œ ê³ ì • ---\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# --- ë””ë°”ì´ìŠ¤ ë° ì „ì—­ ì„¤ì • ---\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "global __kst\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global __device\n",
    "print('Device:', __device)\n",
    "\n",
    "__model_class_list = []\n",
    "global __model_class_list\n",
    "\n",
    "DEBUG_ON = False\n",
    "global DEBUG_ON\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >ê¸°ë³¸< ëª¨ë¸ ì €ìž¥ ë° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_makedirs(path):\n",
    "    if os.path.exists(path) and not os.path.isdir(path):\n",
    "        os.remove(path)  # íŒŒì¼ì´ë©´ ì‚­ì œ\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "def tensor_to_jsonable(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.item() if obj.numel() == 1 else obj.tolist()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: tensor_to_jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [tensor_to_jsonable(v) for v in obj]\n",
    "    return obj   \n",
    "\n",
    "def save_model_dict(model, path, pth_name, kwargs=None):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ state_dictì™€ ì¶”ê°€ ì •ë³´ë¥¼ ì§€ì •í•œ ë””ë ‰í† ë¦¬(path)ì— name.pth íŒŒì¼ë¡œ ì €ìž¥\n",
    "    - model: ì €ìž¥í•  ëª¨ë¸ ê°ì²´\n",
    "    - path: ì €ìž¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: './save')\n",
    "    - name: ì €ìž¥í•  íŒŒì¼ ì´ë¦„ (í™•ìž¥ìž ì—†ì´, ì˜ˆ: 'model1')\n",
    "    - kwargs: dict ë˜ëŠ” JSON ë¬¸ìžì—´(ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ê°ì²´)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n",
    "    model_info = {\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'init_args': {},  # ìƒì„±ìž ì¸ìž(ê°€ëŠ¥í•˜ë©´)\n",
    "        'str': str(model),\n",
    "        'repr': repr(model),\n",
    "        'modules': [m.__class__.__name__ for m in model.modules()],\n",
    "    }\n",
    "    # ìƒì„±ìž ì¸ìž ìžë™ ì¶”ì¶œ(ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "    if hasattr(model, '__dict__'):\n",
    "        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n",
    "            if hasattr(model, key):\n",
    "                model_info['init_args'][key] = getattr(model, key)\n",
    "\n",
    "    # kwargs ì²˜ë¦¬\n",
    "    extra_info = {}\n",
    "    if kwargs is not None:\n",
    "        if isinstance(kwargs, str):\n",
    "            extra_info = json.loads(kwargs)\n",
    "        elif isinstance(kwargs, dict):\n",
    "            extra_info = kwargs\n",
    "        else:\n",
    "            raise ValueError(\"kwargsëŠ” dict ë˜ëŠ” JSON ë¬¸ìžì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # model_infoì— kwargs ë‚´ìš© ì¶”ê°€\n",
    "    model_info.update(extra_info)\n",
    "\n",
    "    # ì €ìž¥í•  dict êµ¬ì„±\n",
    "    save_dict = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'class_name': model.__class__.__name__,\n",
    "        'model_info': model_info,\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    torch.save(save_dict, save_path)\n",
    "    return save_path\n",
    "\n",
    "def load_model_dict(path, pth_name, model_class=None):\n",
    "    \"\"\"\n",
    "    save_model_dictë¡œ ì €ìž¥í•œ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "    - path: ì €ìž¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: './save')\n",
    "    - pth_name: ì €ìž¥ëœ íŒŒì¼ ì´ë¦„ (í™•ìž¥ìž ì—†ì´, ì˜ˆ: 'model1')\n",
    "    - model_class: ëª¨ë¸ í´ëž˜ìŠ¤ (Noneì´ë©´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ëŠ” ë°˜í™˜í•˜ì§€ ì•ŠìŒ)\n",
    "    ë°˜í™˜ê°’: (model, class_name, model_info)\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import os\n",
    "\n",
    "    pth_path = os.path.join(path, f\"{pth_name}.pth\")\n",
    "    checkpoint = torch.load(pth_path, map_location=__device)\n",
    "    class_name = checkpoint.get('class_name', None)\n",
    "    model_info = checkpoint.get('model_info', {})\n",
    "\n",
    "    model = None\n",
    "    if model_class is not None:\n",
    "        try:\n",
    "            model = model_class().to(__device)\n",
    "            model.load_state_dict(checkpoint['model_state'])\n",
    "        except Exception as e:\n",
    "            print(f\"ëª¨ë¸ state_dict ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            model = None\n",
    "\n",
    "    return model, class_name, model_info\n",
    "\n",
    "def print_model_recovery_guide_from_info(model_info):\n",
    "    \"\"\"\n",
    "    model_info(dict)ë¥¼ ë°›ì•„ì„œ ë³µêµ¬ìš© í´ëž˜ìŠ¤ ì •ì˜ ê°€ì´ë“œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    class_name = model_info.get('class_name', 'UnknownModel')\n",
    "    init_args = model_info.get('init_args', {})\n",
    "    model_str = model_info.get('str', '')\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"[ëª¨ë¸ ë³µêµ¬ ê°€ì´ë“œ] class_name: {class_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"\\n[1] ë³µì‚¬ ë¶™ì—¬ë„£ê¸°ìš© í´ëž˜ìŠ¤ ì •ì˜:\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "    print(\"# ì•„ëž˜ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "\n",
    "    print(f\"\\nclass {class_name}(nn.Module):\")\n",
    "    print(f\"    def __init__(self, \", end=\"\")\n",
    "    if init_args:\n",
    "        args_list = [f\"{k}={repr(v)}\" for k, v in init_args.items()]\n",
    "        print(\", \".join(args_list) + \"):\")\n",
    "    else:\n",
    "        print(\"in_ch=1, base_ch=64):  # â† ì‹¤ì œ ê°’ìœ¼ë¡œ ìˆ˜ì • í•„ìš”\")\n",
    "    print(\"        super().__init__()\")\n",
    "\n",
    "    if model_str:\n",
    "        print(\"        # ì•„ëž˜ëŠ” ì €ìž¥ëœ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¶”ì • ì½”ë“œìž…ë‹ˆë‹¤\")\n",
    "        print(\"        # í•„ìš”ì‹œ ìˆ˜ì •í•˜ì„¸ìš”\")\n",
    "        import re\n",
    "        # Conv2d\n",
    "        conv_matches = re.findall(r'Conv2d\\((\\d+), (\\d+), kernel_size=\\((\\d+), (\\d+)\\)', model_str)\n",
    "        if conv_matches:\n",
    "            print(\"        # Convolution layers:\")\n",
    "            for i, (in_ch, out_ch, k1, k2) in enumerate(conv_matches[:5]):\n",
    "                print(f\"        self.conv{i+1} = nn.Conv2d({in_ch}, {out_ch}, {k1})\")\n",
    "        # Linear\n",
    "        linear_matches = re.findall(r'Linear\\(in_features=(\\d+), out_features=(\\d+)', model_str)\n",
    "        if linear_matches:\n",
    "            print(\"        # Linear layers:\")\n",
    "            for i, (in_feat, out_feat) in enumerate(linear_matches[:3]):\n",
    "                print(f\"        self.fc{i+1} = nn.Linear({in_feat}, {out_feat})\")\n",
    "        # BatchNorm\n",
    "        bn_matches = re.findall(r'BatchNorm2d\\((\\d+)', model_str)\n",
    "        if bn_matches:\n",
    "            print(\"        # BatchNorm layers:\")\n",
    "            for i, (num_feat,) in enumerate(bn_matches[:3]):\n",
    "                print(f\"        self.bn{i+1} = nn.BatchNorm2d({num_feat})\")\n",
    "\n",
    "    print(\"\\n    def forward(self, x):\")\n",
    "    print(\"        # TODO: forward ë¡œì§ êµ¬í˜„\")\n",
    "    print(\"        # ì•„ëž˜ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬í˜„í•˜ì„¸ìš”:\")\n",
    "    if model_str:\n",
    "        if \"Conv2d\" in model_str and \"ReLU\" in model_str:\n",
    "            print(\"        # x = F.relu(self.conv1(x))\")\n",
    "            print(\"        # x = F.relu(self.conv2(x))\")\n",
    "        if \"Linear\" in model_str:\n",
    "            print(\"        # x = x.view(x.size(0), -1)  # flatten\")\n",
    "            print(\"        # x = self.fc1(x)\")\n",
    "        if \"Sigmoid\" in model_str:\n",
    "            print(\"        # x = torch.sigmoid(x)\")\n",
    "        elif \"Softmax\" in model_str:\n",
    "            print(\"        # x = F.softmax(x, dim=1)\")\n",
    "    print(\"        return x\")\n",
    "\n",
    "    print(\"\\n# ëª¨ë¸ í´ëž˜ìŠ¤ë¥¼ __model_class_listì— ë“±ë¡\")\n",
    "    print(f\"__model_class_list.append({class_name})\")\n",
    "\n",
    "    print(\"\\n# \" + \"=\"*70)\n",
    "    print(\"# ì—¬ê¸°ê¹Œì§€ ë³µì‚¬ ë¶™ì—¬ë„£ê¸°\")\n",
    "    print(\"# \" + \"=\"*70)\n",
    "    print(\"\\n[2] ì‚¬ìš©ìž ì„¤ì • ê°€ì´ë“œ:\")\n",
    "    print(\"# \" + \"-\"*70)\n",
    "    print(\"# ì•„ëž˜ ê°’ë“¤ì„ ì‹¤ì œ í™˜ê²½ì— ë§žê²Œ ìˆ˜ì •í•˜ì„¸ìš”\")\n",
    "    print(\"# \" + \"-\"*70)\n",
    "    print(\"\\n# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\")\n",
    "    if init_args:\n",
    "        args_str = ', '.join([f\"{k}={repr(v)}\" for k, v in init_args.items()])\n",
    "        print(f\"model = {class_name}({args_str}).to(__device)\")\n",
    "    else:\n",
    "        print(f\"model = {class_name}(\")\n",
    "        print(\"    in_ch=1,     # â† ìž…ë ¥ ì±„ë„ ìˆ˜ (1=ê·¸ë ˆì´ìŠ¤ì¼€ì¼, 3=RGB)\")\n",
    "        print(\"    base_ch=64   # â† ê¸°ë³¸ ì±„ë„ ìˆ˜ (ë©”ëª¨ë¦¬ì— ë”°ë¼ 32, 64, 128 ë“±)\")\n",
    "        print(\").to(__device)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"ë³µêµ¬ ê°€ì´ë“œ ì™„ë£Œ! ìœ„ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ìƒˆë¡œìš´ ì…€ì— ë¶™ì—¬ë„£ê³  ì‹¤í–‰í•˜ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# >ê¸°ë³¸< ëª¨ë¸ë§ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ í•¨ìˆ˜\n",
    "def train_fn(model, train_loader, criterion, optimizer, device, epoch=None, epochs=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    res = {}\n",
    "    desc = f\"Train [{epoch+1}/{epochs}]\" if epoch is not None and epochs is not None else \"Train\"\n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 1\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 3\n",
    "\n",
    "    pbar = tqdm(train_loader, leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "    \n",
    "    # tqdm_kwargs = {\n",
    "    #     'disable': False,  # í•­ìƒ í‘œì‹œ\n",
    "    #     'mininterval': 0.5,\n",
    "    #     'leave': True,\n",
    "    #     'desc': desc,\n",
    "    #     'position': 1\n",
    "    # }\n",
    "    # pbar = tqdm(train_loader, **tqdm_kwargs)\n",
    "        \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        # criterionì´ ê¸°ë³¸(reduction='mean')ì´ë¼ ê°€ì •í•˜ì—¬ ìƒ˜í”Œ ê¸°ì¤€ ëˆ„ì \n",
    "        running_loss += loss.item() * batch_size\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    res['loss'] = epoch_loss\n",
    "    res['acc'] = epoch_acc\n",
    "    return res\n",
    "\n",
    "# ê²€ì¦ í•¨ìˆ˜\n",
    "def evaluate_fn(model, val_loader, criterion, device, epoch, epochs):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    res = {}\n",
    "    desc = f\"Val   [{epoch+1}/{epochs}]\"\n",
    "\n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 1\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 3\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "        \n",
    "        # tqdm_kwargs = {\n",
    "        #     'disable': False,  # í•­ìƒ í‘œì‹œ\n",
    "        #     'mininterval': 0.5,\n",
    "        #     'leave': True,\n",
    "        #     'desc': desc,\n",
    "        #     'position': 1\n",
    "        # }\n",
    "        # pbar = tqdm(val_loader, **tqdm_kwargs)        \n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_size\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total if total > 0 else 0.0\n",
    "    epoch_acc = correct / total if total > 0 else 0.0\n",
    "    res['loss'] = epoch_loss\n",
    "    res['acc'] = epoch_acc\n",
    "    return res\n",
    "\n",
    "# ëª¨ë¸ë§ í•¨ìˆ˜ (í›ˆë ¨ + ê²€ì¦)\n",
    "def modeling_fn(model, epochs, train_loader, val_loader, criterion, optimizer, scheduler, device):\n",
    "    history = []\n",
    "    best_val_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    start_time = time.time()\n",
    "    epoch_start_time = None\n",
    "\n",
    "    estimated_completion_str = None\n",
    "    \n",
    "    tqdm_kwargs = {} \n",
    "    if DEBUG_ON:\n",
    "        tqdm_kwargs['disable'] = False\n",
    "        tqdm_kwargs['mininterval'] = 2\n",
    "    else:\n",
    "        tqdm_kwargs['disable'] = True\n",
    "        tqdm_kwargs['mininterval'] = 6\n",
    "\n",
    "    epoch = 0\n",
    "    desc = f\"Epoch [{epoch+1}/{epochs}]\"\n",
    "    pbar = tqdm(range(epochs), leave=True, desc=desc, position=0, **tqdm_kwargs)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        print()\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        pbar.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        \n",
    "        train_res = train_fn(model, train_loader, criterion, optimizer, device, epoch=epoch, epochs=epochs)\n",
    "        val_res = evaluate_fn(model, val_loader, criterion, device, epoch=epoch, epochs=epochs)\n",
    "        if estimated_completion_str is not None:\n",
    "            pbar.set_postfix_str(\"ì¢…ë£Œ \" + estimated_completion_str)\n",
    "            \n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        res = {\n",
    "            \"epoch\": epoch,\n",
    "            \"epochs\": epochs,\n",
    "            \"train\": train_res,\n",
    "            \"val\": val_res,\n",
    "        }\n",
    "\n",
    "        history.append(res)\n",
    "\n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ìž¥\n",
    "        if val_res['acc'] > best_val_acc:\n",
    "            best_val_acc = val_res['acc']\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # ì—í¬í¬ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
    "        epoch_elapsed = time.time() - epoch_start_time\n",
    "\n",
    "        # ì²« ë²ˆì§¸ ì—í¬í¬ ì™„ë£Œ í›„ ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
    "        if epoch == 0 and epochs > 1:\n",
    "            remaining_epochs = epochs - 1\n",
    "            estimated_total_time = epoch_elapsed * epochs\n",
    "            estimated_completion = datetime.now(__kst) + timedelta(seconds=epoch_elapsed * remaining_epochs)\n",
    "            estimated_completion_str = estimated_completion.strftime('%Y-%m-%d %H:%M:%S KST')\n",
    "            pbar.set_postfix_str(\"ì¢…ë£Œ \" + estimated_completion_str)\n",
    "            # print(f\"ì²« ì—í¬í¬ ì™„ë£Œ - ì˜ˆìƒ ì™„ë£Œ ì‹œê°„: {estimated_completion_str}\")\n",
    "            \n",
    "        \n",
    "        # print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "        #       f\"Train Loss: {train_res['loss']:.4f}, \"\n",
    "        #       f\"Train Acc: {train_res['acc']:.4f} | \"\n",
    "        #       f\"Val Loss: {val_res['loss']:.4f}, \"\n",
    "        #       f\"Val Acc: {val_res['acc']:.4f} \"\n",
    "        #       f\"({epoch_elapsed:.1f}s)\")\n",
    "\n",
    "    # ì „ì²´ í•™ìŠµ ì™„ë£Œ ì‹œê°„\n",
    "    total_elapsed = time.time() - start_time\n",
    "    completion_time = datetime.now(__kst)\n",
    "\n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    # print(f'\\nìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}')\n",
    "    # print(f'ì „ì²´ í•™ìŠµ ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)')\n",
    "    # print(f'í•™ìŠµ ì™„ë£Œ ì‹œê°„: {completion_time.strftime(\"%Y-%m-%d %H:%M:%S KST\")}')\n",
    "\n",
    "    return model, history, completion_time, total_elapsed\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"ëª¨ë¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, leave=True, desc=\"Testing\", position=0)\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # í´ëž˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    # print(f'ì „ì²´ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.2f}%')\n",
    "\n",
    "    # # í´ëž˜ìŠ¤ë³„ ì •í™•ë„ ì¶œë ¥\n",
    "    # print('\\ní´ëž˜ìŠ¤ë³„ ì •í™•ë„:')\n",
    "    # for i in range(10):\n",
    "    #     if class_total[i] > 0:\n",
    "    #         print(f'{classes[i]:>8}: {100 * class_correct[i] / class_total[i]:.1f}%')\n",
    "\n",
    "    return accuracy, class_total, classes, class_correct\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
