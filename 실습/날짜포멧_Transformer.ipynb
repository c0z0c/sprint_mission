{"cells":[{"cell_type":"markdown","metadata":{"id":"tQv15fF-MfKH"},"source":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"0mkjoNR-gvgd","executionInfo":{"status":"ok","timestamp":1759286886772,"user_tz":-540,"elapsed":3,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# %load_ext autoreload\n","# %autoreload 2"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"-B9an7HNgvgf","executionInfo":{"status":"ok","timestamp":1759286886778,"user_tz":-540,"elapsed":5,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# !pip install -q \"numpy<2\"\n","# !pip install -q albumentations\n","# !pip install -q ultralytics"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5167,"status":"ok","timestamp":1759286891946,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"4QvcZx75gvgf","outputId":"83c64d3a-8659-4995-bee5-9273694ecdfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["🌐 https://c0z0c.github.io/jupyter_hangul\n","ℹ️ NumPy 2.0.2 (v2.x+): 호환성 모드 적용됨\n","Mounted at /content/drive\n","✅ 설정 완료: 한글 폰트, plt 전역 등록, pandas 확장, 캐시 기능\n","pd commit 저장 경로 = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_utils' from '/content/helper_utils.py'>"]},"metadata":{},"execution_count":21}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_utils.py\", \"helper_utils.py\")\n","import importlib\n","import helper_utils as hu\n","importlib.reload(hu)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1759286891963,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"TXoYK8FtMfKM","outputId":"f23fec04-0478-436f-fe9a-485a4d50a545"},"outputs":[{"output_type":"stream","name":"stdout","text":["라이브러리 로드 완료 사용장치:cuda\n"]}],"source":["# 기본 라이브러리\n","\n","# --- Scikit-learn: 데이터 전처리, 모델, 평가 ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- 기타 라이브러리 ---\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: 딥러닝 관련 ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from collections import OrderedDict\n","\n","# --- 기타 ---\n","import re\n","import os\n","import sys\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU 설정\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # 재현 가능한 결과를 위해\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"라이브러리 로드 완료 사용장치:{__device}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ckKTgI3ggvgg","executionInfo":{"status":"ok","timestamp":1759286891967,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_dataset(n_examples):\n","    \"\"\"모든 가능한 월 이름을 포함한 포괄적인 데이터셋 생성\"\"\"\n","    dataset = []\n","\n","    # 모든 월 이름과 축약형을 명시적으로 포함\n","    full_months = ['January', 'February', 'March', 'April', 'May', 'June',\n","                   'July', 'August', 'September', 'October', 'November', 'December']\n","\n","    short_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n","                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n","\n","    for i in range(n_examples):\n","        year = random.randint(1990, 2030)\n","        month = (i % 12) + 1\n","        day = random.randint(1, 28)\n","\n","        current_date = datetime(year, month, day)\n","\n","        # 포맷 선택을 더 균등하게\n","        format_choice = i % 4\n","\n","        if format_choice == 0:  # 전체 월 이름\n","            input_str = f\"{full_months[month-1]} {day:02d}, {year}\"\n","        elif format_choice == 1:  # 축약 월 이름\n","            input_str = f\"{day:02d} {short_months[month-1]} {year}\"\n","        elif format_choice == 2:  # 숫자 슬래시\n","            input_str = f\"{year}/{month:02d}/{day:02d}\"\n","        else:  # 숫자 하이픈\n","            input_str = f\"{month:02d}-{day:02d}-{year}\"\n","\n","        output_str = current_date.strftime('%Y-%m-%d')\n","        dataset.append((input_str, output_str))\n","\n","    random.shuffle(dataset)\n","    return dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1759286892000,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"73xj1QXSgvgh","outputId":"44c5bf41-9ccd-428f-e853-cc9c33014928"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('04-20-2024', '2024-04-20'),\n"," ('08-14-2002', '2002-08-14'),\n"," ('January 19, 2018', '2018-01-19'),\n"," ('2011/07/22', '2011-07-22'),\n"," ('10 Oct 2000', '2000-10-10'),\n"," ('27 Feb 1992', '1992-02-27'),\n"," ('04-23-2012', '2012-04-23'),\n"," ('2007/11/08', '2007-11-08'),\n"," ('15 Jun 2017', '2017-06-15'),\n"," ('20 Feb 1993', '1993-02-20')]"]},"metadata":{},"execution_count":24}],"source":["raw_data = create_dataset(5000)\n","raw_data[:10]"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"kDzZXJGvgvgh","executionInfo":{"status":"ok","timestamp":1759286892006,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# 문자 단위 토큰화를 위한 새로운 Lang 클래스\n","class CharLang:\n","    def __init__(self, name):\n","        self.name = name\n","\n","        # PAD, SOS, EOS 명시적으로 추가 (PAD=0)\n","        self.char2index = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n","        self.index2char = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n","        self.n_chars = 3\n","\n","    def add_sentence(self, sentence):\n","        for char in sentence:\n","            if char not in self.char2index:\n","                self.char2index[char] = self.n_chars\n","                self.index2char[self.n_chars] = char\n","                self.n_chars += 1\n","\n","# 문자 단위 언어 클래스 생성\n","date_input_lang = CharLang(\"date_input\")\n","date_output_lang = CharLang(\"date_output\")\n","\n","# 문자 단위로 vocabulary 구축\n","for pair in raw_data:\n","    date_input_lang.add_sentence(pair[0])\n","    date_output_lang.add_sentence(pair[1])\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"0zMQhaYsgvgh","executionInfo":{"status":"ok","timestamp":1759286892018,"user_tz":-540,"elapsed":9,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import numpy as np\n","\n","# 데이터 및 CharLang 클래스는 이미 정의되어 사용 가능하다고 가정\n","# date_input_lang, date_output_lang 인스턴스 사용"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kQZMV6cogvgi","executionInfo":{"status":"ok","timestamp":1759286892025,"user_tz":-540,"elapsed":4,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, emb_dim, n_heads, pf_dim, dropout):\n","        super().__init__()\n","        self.attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        self.ff = nn.Sequential(\n","            nn.Linear(emb_dim, pf_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(pf_dim, emb_dim)\n","        )\n","        self.norm1 = nn.LayerNorm(emb_dim)\n","        self.norm2 = nn.LayerNorm(emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Multi-Head Attention\n","        _src = self.norm1(src)\n","        attn_output, _ = self.attn(_src, _src, _src, attn_mask=src_mask)\n","        src = src + self.dropout(attn_output) # Add & Norm 1\n","\n","        # Feed Forward\n","        _src = self.norm2(src)\n","        ff_output = self.ff(_src)\n","        src = src + self.dropout(ff_output) # Add & Norm 2\n","\n","        return src\n","\n","class TransformerDecoderLayer(nn.Module):\n","    def __init__(self, emb_dim, n_heads, pf_dim, dropout):\n","        super().__init__()\n","        # 1. Masked Multi-Head Attention (Self-Attention)\n","        self.self_attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        # 2. Encoder-Decoder Attention (Cross-Attention)\n","        self.enc_attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        # 3. Feed Forward\n","        self.ff = nn.Sequential(\n","            nn.Linear(emb_dim, pf_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(pf_dim, emb_dim)\n","        )\n","\n","        self.norm1 = nn.LayerNorm(emb_dim)\n","        self.norm2 = nn.LayerNorm(emb_dim)\n","        self.norm3 = nn.LayerNorm(emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        # 1. Masked Multi-Head Attention (Self-Attention)\n","        _trg = self.norm1(trg)\n","        self_attn_output, _ = self.self_attn(_trg, _trg, _trg, attn_mask=trg_mask)\n","        trg = trg + self.dropout(self_attn_output) # Add & Norm 1\n","\n","        # 2. Encoder-Decoder Attention (Cross-Attention)\n","        _trg = self.norm2(trg)\n","        enc_attn_output, _ = self.enc_attn(_trg, enc_src, enc_src, attn_mask=src_mask)\n","        trg = trg + self.dropout(enc_attn_output) # Add & Norm 2\n","\n","        # 3. Feed Forward\n","        _trg = self.norm3(trg)\n","        ff_output = self.ff(_trg)\n","        trg = trg + self.dropout(ff_output) # Add & Norm 3\n","\n","        return trg"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"G5HKgEM-gvgi","executionInfo":{"status":"ok","timestamp":1759286892057,"user_tz":-540,"elapsed":28,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self, input_dim, output_dim, emb_dim, n_heads, pf_dim, n_layers, dropout, max_len):\n","        super().__init__()\n","\n","        # 1. nn.Sequential 대신 nn.ModuleList 사용 (마스크 인수를 전달하기 위함)\n","        self.encoder = nn.ModuleList([TransformerEncoderLayer(emb_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)])\n","        self.decoder = nn.ModuleList([TransformerDecoderLayer(emb_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)])\n","\n","        self.input_emb = nn.Embedding(input_dim, emb_dim)\n","        self.output_emb = nn.Embedding(output_dim, emb_dim)\n","\n","        # 위치 인코딩\n","        self.pos_emb = nn.Embedding(max_len, emb_dim)\n","\n","        self.fc_out = nn.Linear(emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # device 저장\n","\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        # src: [배치 크기, src_len], trg: [배치 크기, trg_len]\n","        batch_size = src.shape[0]\n","\n","        # 1. 입력 임베딩 및 위치 인코딩\n","\n","        # 인코더 입력 처리\n","        src_len = src.shape[1]\n","        # 💡 수정: src_len에 맞는 위치 텐서 생성 (pos 변수 정의)\n","        src_pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        src = self.dropout(self.input_emb(src) + self.pos_emb(src_pos)) # [배치 크기, src_len, emb_dim]\n","\n","        # 디코더 입력 처리\n","        trg_len = trg.shape[1]\n","        # 💡 수정: trg_len에 맞는 위치 텐서 생성\n","        trg_pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        trg = self.dropout(self.output_emb(trg) + self.pos_emb(trg_pos)) # [배치 크기, trg_len, emb_dim]\n","\n","        # 2. 인코더 실행\n","        enc_src = src\n","        for layer in self.encoder:\n","             # 명시적으로 src_mask를 각 인코더 레이어에 전달\n","            enc_src = layer(enc_src, src_mask)\n","\n","        # 3. 디코더 실행\n","        output = trg\n","        for layer in self.decoder:\n","             # 명시적으로 trg_mask와 src_mask를 각 디코더 레이어에 전달\n","            output = layer(output, enc_src, trg_mask, src_mask)\n","\n","        # 4. 최종 출력\n","        output = self.fc_out(output) # [배치 크기, trg_len, output_dim]\n","        return output"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9L91OgsXgvgi","executionInfo":{"status":"ok","timestamp":1759286892066,"user_tz":-540,"elapsed":4,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def make_trg_mask(trg):\n","    # trg: [배치 크기, 타겟 시퀀스 길이]\n","    trg_len = trg.shape[1]\n","\n","    # 삼각형 마스크 (Causal Mask) 생성\n","    # 0은 어텐션 허용, -inf는 어텐션 차단\n","    trg_mask = torch.tril(torch.ones((trg_len, trg_len), dtype=torch.bool)).to(trg.device)\n","    trg_mask = trg_mask.float().masked_fill(trg_mask == 0, float('-inf')).masked_fill(trg_mask == 1, float(0.0))\n","    # trg_mask: [타겟 시퀀스 길이, 타겟 시퀀스 길이]\n","    return trg_mask"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"v603xaRHgvgi","executionInfo":{"status":"ok","timestamp":1759286892071,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# 문자열을 인덱스 리스트로 변환\n","def indexes_from_sentence(lang, sentence):\n","    return [lang.char2index[char] for char in sentence]\n","\n","# 페어를 텐서로 변환\n","def tensor_from_pair(pair, input_lang, output_lang, max_input_len, max_output_len):\n","    input_indexes = indexes_from_sentence(input_lang, pair[0])\n","    output_indexes = indexes_from_sentence(output_lang, pair[1])\n","\n","    # SOS, EOS 토큰 추가\n","    input_tensor = torch.tensor([input_lang.char2index[\"SOS\"]] + input_indexes + [input_lang.char2index[\"EOS\"]], dtype=torch.long)\n","    output_tensor = torch.tensor([output_lang.char2index[\"SOS\"]] + output_indexes + [output_lang.char2index[\"EOS\"]], dtype=torch.long)\n","\n","    # 패딩 (PAD 인덱스로 채우기)\n","    pad_idx_in = input_lang.char2index[\"PAD\"]\n","    pad_idx_out = output_lang.char2index[\"PAD\"]\n","\n","    input_pad = torch.full((max_input_len,), pad_idx_in, dtype=torch.long)\n","    input_pad[:len(input_tensor)] = input_tensor\n","\n","    output_pad = torch.full((max_output_len,), pad_idx_out, dtype=torch.long)\n","    output_pad[:len(output_tensor)] = output_tensor\n","\n","    return input_pad, output_pad"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1759286892108,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ongoJ7sogvgi","outputId":"49ecd50e-f19b-403d-b20b-5d7f1ede710a"},"outputs":[{"output_type":"stream","name":"stdout","text":["모델 파라미터 수: 2,656,526\n"]}],"source":["# 하이퍼파라미터 설정\n","INPUT_DIM = date_input_lang.n_chars\n","OUTPUT_DIM = date_output_lang.n_chars\n","EMB_DIM = 256\n","N_HEADS = 8\n","PF_DIM = 512\n","N_LAYERS = 2 # MVP이므로 2개 층 사용\n","DROPOUT = 0.1\n","MAX_INPUT_LEN = 20 # 최대 입력 길이 (데이터에 따라 설정)\n","MAX_OUTPUT_LEN = 12 # 최대 출력 길이 (데이터에 따라 설정: YYYY-MM-DD + SOS/EOS = 12)\n","N_EPOCHS = 1000 # 충분한 학습 반복\n","BATCH_SIZE = len(raw_data) # 작은 데이터셋이므로 전체 배치 사용\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model = Seq2SeqTransformer(INPUT_DIM, OUTPUT_DIM, EMB_DIM, N_HEADS, PF_DIM, N_LAYERS, DROPOUT, max(MAX_INPUT_LEN, MAX_OUTPUT_LEN)).to(device)\n","# optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","# criterion = nn.CrossEntropyLoss(ignore_index=0) # 패딩(인덱스 0)은 손실 계산에서 제외\n","\n","model = Seq2SeqTransformer(INPUT_DIM, OUTPUT_DIM, EMB_DIM, N_HEADS, PF_DIM, N_LAYERS, DROPOUT, max(MAX_INPUT_LEN, MAX_OUTPUT_LEN)).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","# 변경: PAD 인덱스를 가져와서 ignore_index로 사용\n","pad_idx = date_output_lang.char2index[\"PAD\"]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","\n","print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["c59219d49cb943c8a7b7e87792c6a993","bd5b5e1123084ad5a47c1df0b40d35bd","fbdb273125ed497dbf135adfca73d78f","da75c75bace94d898c6eb39c759666f7","c8ffdbb7f9c84a99ba608cfb87cb1250","269f65f5e8c54517b7df377502179ec5","db5044239bbb49808d8af804e569e626","c113427526914788ba476b765009c4e5","fb597123841143e89e4e8f7b7a6d0757","2c155b381b934c8b98d82128e5151379","e0703ed1573d4b348afdd2048b0ec0d2"]},"executionInfo":{"elapsed":479795,"status":"ok","timestamp":1759287371906,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"DGhFF_3Lgvgj","outputId":"378509fb-46b5-45f3-9833-168dcf3e4c9f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59219d49cb943c8a7b7e87792c6a993"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 100 | Train Loss: 0.0004\n","Epoch: 200 | Train Loss: 0.0002\n","Epoch: 300 | Train Loss: 0.0001\n","Epoch: 400 | Train Loss: 0.0000\n","Epoch: 500 | Train Loss: 0.0001\n","Epoch: 600 | Train Loss: 0.0000\n","Epoch: 700 | Train Loss: 0.0000\n","Epoch: 800 | Train Loss: 0.0000\n","Epoch: 900 | Train Loss: 0.0000\n","Epoch: 1000 | Train Loss: 0.0000\n"]}],"source":["# 데이터 준비\n","input_tensors, output_tensors = zip(*[tensor_from_pair(p, date_input_lang, date_output_lang, MAX_INPUT_LEN, MAX_OUTPUT_LEN) for p in raw_data])\n","SRC = torch.stack(input_tensors).to(device)\n","TRG = torch.stack(output_tensors).to(device)\n","\n","pbar = tqdm(range(N_EPOCHS))\n","for epoch in pbar:\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # 인코더 입력 마스크 (패딩 마스크) - 이 예시에서는 패딩 마스크를 간단하게 생략하거나 None 처리 가능\n","    # 하지만 실제로는 패딩 토큰 인덱스(0)에 맞춰 src_mask를 만들어야 함. 여기서는 None으로 간주하고 생략\n","    src_mask = None\n","\n","    # 디코더 입력 (타겟 시퀀스에서 마지막 EOS 토큰 제외)\n","    trg_input = TRG[:, :-1]\n","\n","    # 인과 관계 마스크 생성\n","    trg_mask = make_trg_mask(trg_input)\n","\n","    # 모델 예측\n","    #output = model(SRC, trg_input, src_mask, None) # src_mask는 None으로 단순화\n","    output = model(SRC, trg_input, src_mask, trg_mask)\n","\n","    # 실제 타겟 (SOS 토큰 제외)\n","    output_dim = output.shape[-1]\n","    output = output.contiguous().view(-1, output_dim)\n","    trg_target = TRG[:, 1:].contiguous().view(-1)\n","\n","    # 손실 계산 및 역전파\n","    loss = criterion(output, trg_target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 100 == 0:\n","        print(f'Epoch: {epoch+1:03} | Train Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157418,"status":"ok","timestamp":1759290057228,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"U8-E4NZLgvgj","outputId":"89a7e90c-c4c9-442b-9425-3a18493d7e19"},"outputs":[{"output_type":"stream","name":"stdout","text":["입력: 21 Oct 2020          | 정답: 2020-10-21 | 예측: 2020-10-21 | O\n","최종 트랜스포머 MVP 정확도: 100.00%\n"]}],"source":["def translate_sentence(model, src_tensor, input_lang, output_lang, max_len, device):\n","    model.eval()\n","    with torch.no_grad():\n","        # 인코딩 시작\n","        src = src_tensor.unsqueeze(0).to(device)\n","        src_mask = None # 패딩 마스크 생략\n","\n","        src_len = src.shape[1]\n","\n","        # 💡 수정 1: src_pos 텐서 정의 (device 지정)\n","        src_pos = torch.arange(0, src_len, device=device).unsqueeze(0)\n","        src = model.dropout(model.input_emb(src) + model.pos_emb(src_pos))\n","\n","        # 💡 수정 2: model.encoder를 반복문으로 실행\n","        enc_src = src\n","        for layer in model.encoder:\n","            enc_src = layer(enc_src, src_mask)\n","\n","        # 디코딩 (자동 회귀)\n","        trg_indexes = [output_lang.char2index[\"SOS\"]]\n","\n","        for i in range(max_len):\n","            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","            trg_mask = make_trg_mask(trg_tensor)\n","\n","            trg_len = trg_tensor.shape[1]\n","\n","            # 💡 수정 3: trg_pos 텐서 정의 (device 지정)\n","            trg_pos = torch.arange(0, trg_len, device=device).unsqueeze(0)\n","            trg_emb = model.dropout(model.output_emb(trg_tensor) + model.pos_emb(trg_pos))\n","\n","            # 💡 수정 4: model.decoder를 반복문으로 실행\n","            output = trg_emb\n","            for layer in model.decoder:\n","                 # 디코더의 각 레이어를 명시적으로 호출\n","                output = layer(output, enc_src, trg_mask, src_mask)\n","\n","            # 마지막 토큰에 대한 예측만 사용\n","            pred_token = model.fc_out(output[:, -1, :]).argmax(dim=-1).item()\n","            trg_indexes.append(pred_token)\n","\n","            if pred_token == output_lang.char2index[\"EOS\"]:\n","                break\n","\n","        trg_tokens = [output_lang.index2char[i] for i in trg_indexes]\n","        return ''.join(trg_tokens[1:-1])\n","\n","# 정확도 테스트\n","correct_count = 0\n","for i, pair in enumerate(raw_data):\n","    src_tensor = SRC[i]\n","    predicted_output = translate_sentence(model, src_tensor, date_input_lang, date_output_lang, MAX_OUTPUT_LEN, device)\n","\n","    if predicted_output == pair[1]:\n","        correct_count += 1\n","\n","    print(f\"\\r입력: {pair[0]:<20} | 정답: {pair[1]:<10} | 예측: {predicted_output:<10} | {'O' if predicted_output == pair[1] else 'X'}\", end='')\n","\n","accuracy = correct_count / len(raw_data)\n","print(f\"\\n최종 트랜스포머 MVP 정확도: {accuracy * 100:.2f}%\")"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1759287528253,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"xcnG1rxGgvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1759287528256,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ljjUsF0ugvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1759287528260,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"wPp6AoUMgvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1759287528302,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Jo_KCd9mgvgj"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"env_colab_250827","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c59219d49cb943c8a7b7e87792c6a993":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd5b5e1123084ad5a47c1df0b40d35bd","IPY_MODEL_fbdb273125ed497dbf135adfca73d78f","IPY_MODEL_da75c75bace94d898c6eb39c759666f7"],"layout":"IPY_MODEL_c8ffdbb7f9c84a99ba608cfb87cb1250"}},"bd5b5e1123084ad5a47c1df0b40d35bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_269f65f5e8c54517b7df377502179ec5","placeholder":"​","style":"IPY_MODEL_db5044239bbb49808d8af804e569e626","value":"100%"}},"fbdb273125ed497dbf135adfca73d78f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c113427526914788ba476b765009c4e5","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb597123841143e89e4e8f7b7a6d0757","value":1000}},"da75c75bace94d898c6eb39c759666f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c155b381b934c8b98d82128e5151379","placeholder":"​","style":"IPY_MODEL_e0703ed1573d4b348afdd2048b0ec0d2","value":" 1000/1000 [07:59&lt;00:00,  1.62it/s]"}},"c8ffdbb7f9c84a99ba608cfb87cb1250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"269f65f5e8c54517b7df377502179ec5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db5044239bbb49808d8af804e569e626":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c113427526914788ba476b765009c4e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb597123841143e89e4e8f7b7a6d0757":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c155b381b934c8b98d82128e5151379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0703ed1573d4b348afdd2048b0ec0d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}