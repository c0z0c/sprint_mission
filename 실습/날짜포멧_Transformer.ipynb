{"cells":[{"cell_type":"markdown","metadata":{"id":"tQv15fF-MfKH"},"source":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"0mkjoNR-gvgd","executionInfo":{"status":"ok","timestamp":1759286886772,"user_tz":-540,"elapsed":3,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# %load_ext autoreload\n","# %autoreload 2"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"-B9an7HNgvgf","executionInfo":{"status":"ok","timestamp":1759286886778,"user_tz":-540,"elapsed":5,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# !pip install -q \"numpy<2\"\n","# !pip install -q albumentations\n","# !pip install -q ultralytics"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5167,"status":"ok","timestamp":1759286891946,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"4QvcZx75gvgf","outputId":"83c64d3a-8659-4995-bee5-9273694ecdfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_utils' from '/content/helper_utils.py'>"]},"metadata":{},"execution_count":21}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_utils.py\", \"helper_utils.py\")\n","import importlib\n","import helper_utils as hu\n","importlib.reload(hu)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1759286891963,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"TXoYK8FtMfKM","outputId":"f23fec04-0478-436f-fe9a-485a4d50a545"},"outputs":[{"output_type":"stream","name":"stdout","text":["ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:cuda\n"]}],"source":["# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from collections import OrderedDict\n","\n","# --- ê¸°íƒ€ ---\n","import re\n","import os\n","import sys\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU ì„¤ì •\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:{__device}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ckKTgI3ggvgg","executionInfo":{"status":"ok","timestamp":1759286891967,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_dataset(n_examples):\n","    \"\"\"ëª¨ë“  ê°€ëŠ¥í•œ ì›” ì´ë¦„ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n","    dataset = []\n","\n","    # ëª¨ë“  ì›” ì´ë¦„ê³¼ ì¶•ì•½í˜•ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨\n","    full_months = ['January', 'February', 'March', 'April', 'May', 'June',\n","                   'July', 'August', 'September', 'October', 'November', 'December']\n","\n","    short_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n","                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n","\n","    for i in range(n_examples):\n","        year = random.randint(1990, 2030)\n","        month = (i % 12) + 1\n","        day = random.randint(1, 28)\n","\n","        current_date = datetime(year, month, day)\n","\n","        # í¬ë§· ì„ íƒì„ ë” ê· ë“±í•˜ê²Œ\n","        format_choice = i % 4\n","\n","        if format_choice == 0:  # ì „ì²´ ì›” ì´ë¦„\n","            input_str = f\"{full_months[month-1]} {day:02d}, {year}\"\n","        elif format_choice == 1:  # ì¶•ì•½ ì›” ì´ë¦„\n","            input_str = f\"{day:02d} {short_months[month-1]} {year}\"\n","        elif format_choice == 2:  # ìˆ«ì ìŠ¬ë˜ì‹œ\n","            input_str = f\"{year}/{month:02d}/{day:02d}\"\n","        else:  # ìˆ«ì í•˜ì´í”ˆ\n","            input_str = f\"{month:02d}-{day:02d}-{year}\"\n","\n","        output_str = current_date.strftime('%Y-%m-%d')\n","        dataset.append((input_str, output_str))\n","\n","    random.shuffle(dataset)\n","    return dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1759286892000,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"73xj1QXSgvgh","outputId":"44c5bf41-9ccd-428f-e853-cc9c33014928"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('04-20-2024', '2024-04-20'),\n"," ('08-14-2002', '2002-08-14'),\n"," ('January 19, 2018', '2018-01-19'),\n"," ('2011/07/22', '2011-07-22'),\n"," ('10 Oct 2000', '2000-10-10'),\n"," ('27 Feb 1992', '1992-02-27'),\n"," ('04-23-2012', '2012-04-23'),\n"," ('2007/11/08', '2007-11-08'),\n"," ('15 Jun 2017', '2017-06-15'),\n"," ('20 Feb 1993', '1993-02-20')]"]},"metadata":{},"execution_count":24}],"source":["raw_data = create_dataset(5000)\n","raw_data[:10]"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"kDzZXJGvgvgh","executionInfo":{"status":"ok","timestamp":1759286892006,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# ë¬¸ì ë‹¨ìœ„ í† í°í™”ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ Lang í´ë˜ìŠ¤\n","class CharLang:\n","    def __init__(self, name):\n","        self.name = name\n","\n","        # PAD, SOS, EOS ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€ (PAD=0)\n","        self.char2index = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n","        self.index2char = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n","        self.n_chars = 3\n","\n","    def add_sentence(self, sentence):\n","        for char in sentence:\n","            if char not in self.char2index:\n","                self.char2index[char] = self.n_chars\n","                self.index2char[self.n_chars] = char\n","                self.n_chars += 1\n","\n","# ë¬¸ì ë‹¨ìœ„ ì–¸ì–´ í´ë˜ìŠ¤ ìƒì„±\n","date_input_lang = CharLang(\"date_input\")\n","date_output_lang = CharLang(\"date_output\")\n","\n","# ë¬¸ì ë‹¨ìœ„ë¡œ vocabulary êµ¬ì¶•\n","for pair in raw_data:\n","    date_input_lang.add_sentence(pair[0])\n","    date_output_lang.add_sentence(pair[1])\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"0zMQhaYsgvgh","executionInfo":{"status":"ok","timestamp":1759286892018,"user_tz":-540,"elapsed":9,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import numpy as np\n","\n","# ë°ì´í„° ë° CharLang í´ë˜ìŠ¤ëŠ” ì´ë¯¸ ì •ì˜ë˜ì–´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ê³  ê°€ì •\n","# date_input_lang, date_output_lang ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"kQZMV6cogvgi","executionInfo":{"status":"ok","timestamp":1759286892025,"user_tz":-540,"elapsed":4,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["class TransformerEncoderLayer(nn.Module):\n","    def __init__(self, emb_dim, n_heads, pf_dim, dropout):\n","        super().__init__()\n","        self.attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        self.ff = nn.Sequential(\n","            nn.Linear(emb_dim, pf_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(pf_dim, emb_dim)\n","        )\n","        self.norm1 = nn.LayerNorm(emb_dim)\n","        self.norm2 = nn.LayerNorm(emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_mask=None):\n","        # Multi-Head Attention\n","        _src = self.norm1(src)\n","        attn_output, _ = self.attn(_src, _src, _src, attn_mask=src_mask)\n","        src = src + self.dropout(attn_output) # Add & Norm 1\n","\n","        # Feed Forward\n","        _src = self.norm2(src)\n","        ff_output = self.ff(_src)\n","        src = src + self.dropout(ff_output) # Add & Norm 2\n","\n","        return src\n","\n","class TransformerDecoderLayer(nn.Module):\n","    def __init__(self, emb_dim, n_heads, pf_dim, dropout):\n","        super().__init__()\n","        # 1. Masked Multi-Head Attention (Self-Attention)\n","        self.self_attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        # 2. Encoder-Decoder Attention (Cross-Attention)\n","        self.enc_attn = nn.MultiheadAttention(emb_dim, n_heads, dropout=dropout, batch_first=True)\n","        # 3. Feed Forward\n","        self.ff = nn.Sequential(\n","            nn.Linear(emb_dim, pf_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(pf_dim, emb_dim)\n","        )\n","\n","        self.norm1 = nn.LayerNorm(emb_dim)\n","        self.norm2 = nn.LayerNorm(emb_dim)\n","        self.norm3 = nn.LayerNorm(emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        # 1. Masked Multi-Head Attention (Self-Attention)\n","        _trg = self.norm1(trg)\n","        self_attn_output, _ = self.self_attn(_trg, _trg, _trg, attn_mask=trg_mask)\n","        trg = trg + self.dropout(self_attn_output) # Add & Norm 1\n","\n","        # 2. Encoder-Decoder Attention (Cross-Attention)\n","        _trg = self.norm2(trg)\n","        enc_attn_output, _ = self.enc_attn(_trg, enc_src, enc_src, attn_mask=src_mask)\n","        trg = trg + self.dropout(enc_attn_output) # Add & Norm 2\n","\n","        # 3. Feed Forward\n","        _trg = self.norm3(trg)\n","        ff_output = self.ff(_trg)\n","        trg = trg + self.dropout(ff_output) # Add & Norm 3\n","\n","        return trg"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"G5HKgEM-gvgi","executionInfo":{"status":"ok","timestamp":1759286892057,"user_tz":-540,"elapsed":28,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self, input_dim, output_dim, emb_dim, n_heads, pf_dim, n_layers, dropout, max_len):\n","        super().__init__()\n","\n","        # 1. nn.Sequential ëŒ€ì‹  nn.ModuleList ì‚¬ìš© (ë§ˆìŠ¤í¬ ì¸ìˆ˜ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•¨)\n","        self.encoder = nn.ModuleList([TransformerEncoderLayer(emb_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)])\n","        self.decoder = nn.ModuleList([TransformerDecoderLayer(emb_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)])\n","\n","        self.input_emb = nn.Embedding(input_dim, emb_dim)\n","        self.output_emb = nn.Embedding(output_dim, emb_dim)\n","\n","        # ìœ„ì¹˜ ì¸ì½”ë”©\n","        self.pos_emb = nn.Embedding(max_len, emb_dim)\n","\n","        self.fc_out = nn.Linear(emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # device ì €ì¥\n","\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        # src: [ë°°ì¹˜ í¬ê¸°, src_len], trg: [ë°°ì¹˜ í¬ê¸°, trg_len]\n","        batch_size = src.shape[0]\n","\n","        # 1. ì…ë ¥ ì„ë² ë”© ë° ìœ„ì¹˜ ì¸ì½”ë”©\n","\n","        # ì¸ì½”ë” ì…ë ¥ ì²˜ë¦¬\n","        src_len = src.shape[1]\n","        # ğŸ’¡ ìˆ˜ì •: src_lenì— ë§ëŠ” ìœ„ì¹˜ í…ì„œ ìƒì„± (pos ë³€ìˆ˜ ì •ì˜)\n","        src_pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        src = self.dropout(self.input_emb(src) + self.pos_emb(src_pos)) # [ë°°ì¹˜ í¬ê¸°, src_len, emb_dim]\n","\n","        # ë””ì½”ë” ì…ë ¥ ì²˜ë¦¬\n","        trg_len = trg.shape[1]\n","        # ğŸ’¡ ìˆ˜ì •: trg_lenì— ë§ëŠ” ìœ„ì¹˜ í…ì„œ ìƒì„±\n","        trg_pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        trg = self.dropout(self.output_emb(trg) + self.pos_emb(trg_pos)) # [ë°°ì¹˜ í¬ê¸°, trg_len, emb_dim]\n","\n","        # 2. ì¸ì½”ë” ì‹¤í–‰\n","        enc_src = src\n","        for layer in self.encoder:\n","             # ëª…ì‹œì ìœ¼ë¡œ src_maskë¥¼ ê° ì¸ì½”ë” ë ˆì´ì–´ì— ì „ë‹¬\n","            enc_src = layer(enc_src, src_mask)\n","\n","        # 3. ë””ì½”ë” ì‹¤í–‰\n","        output = trg\n","        for layer in self.decoder:\n","             # ëª…ì‹œì ìœ¼ë¡œ trg_maskì™€ src_maskë¥¼ ê° ë””ì½”ë” ë ˆì´ì–´ì— ì „ë‹¬\n","            output = layer(output, enc_src, trg_mask, src_mask)\n","\n","        # 4. ìµœì¢… ì¶œë ¥\n","        output = self.fc_out(output) # [ë°°ì¹˜ í¬ê¸°, trg_len, output_dim]\n","        return output"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"9L91OgsXgvgi","executionInfo":{"status":"ok","timestamp":1759286892066,"user_tz":-540,"elapsed":4,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def make_trg_mask(trg):\n","    # trg: [ë°°ì¹˜ í¬ê¸°, íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´]\n","    trg_len = trg.shape[1]\n","\n","    # ì‚¼ê°í˜• ë§ˆìŠ¤í¬ (Causal Mask) ìƒì„±\n","    # 0ì€ ì–´í…ì…˜ í—ˆìš©, -infëŠ” ì–´í…ì…˜ ì°¨ë‹¨\n","    trg_mask = torch.tril(torch.ones((trg_len, trg_len), dtype=torch.bool)).to(trg.device)\n","    trg_mask = trg_mask.float().masked_fill(trg_mask == 0, float('-inf')).masked_fill(trg_mask == 1, float(0.0))\n","    # trg_mask: [íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´, íƒ€ê²Ÿ ì‹œí€€ìŠ¤ ê¸¸ì´]\n","    return trg_mask"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"v603xaRHgvgi","executionInfo":{"status":"ok","timestamp":1759286892071,"user_tz":-540,"elapsed":2,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# ë¬¸ìì—´ì„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n","def indexes_from_sentence(lang, sentence):\n","    return [lang.char2index[char] for char in sentence]\n","\n","# í˜ì–´ë¥¼ í…ì„œë¡œ ë³€í™˜\n","def tensor_from_pair(pair, input_lang, output_lang, max_input_len, max_output_len):\n","    input_indexes = indexes_from_sentence(input_lang, pair[0])\n","    output_indexes = indexes_from_sentence(output_lang, pair[1])\n","\n","    # SOS, EOS í† í° ì¶”ê°€\n","    input_tensor = torch.tensor([input_lang.char2index[\"SOS\"]] + input_indexes + [input_lang.char2index[\"EOS\"]], dtype=torch.long)\n","    output_tensor = torch.tensor([output_lang.char2index[\"SOS\"]] + output_indexes + [output_lang.char2index[\"EOS\"]], dtype=torch.long)\n","\n","    # íŒ¨ë”© (PAD ì¸ë±ìŠ¤ë¡œ ì±„ìš°ê¸°)\n","    pad_idx_in = input_lang.char2index[\"PAD\"]\n","    pad_idx_out = output_lang.char2index[\"PAD\"]\n","\n","    input_pad = torch.full((max_input_len,), pad_idx_in, dtype=torch.long)\n","    input_pad[:len(input_tensor)] = input_tensor\n","\n","    output_pad = torch.full((max_output_len,), pad_idx_out, dtype=torch.long)\n","    output_pad[:len(output_tensor)] = output_tensor\n","\n","    return input_pad, output_pad"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1759286892108,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ongoJ7sogvgi","outputId":"49ecd50e-f19b-403d-b20b-5d7f1ede710a"},"outputs":[{"output_type":"stream","name":"stdout","text":["ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: 2,656,526\n"]}],"source":["# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n","INPUT_DIM = date_input_lang.n_chars\n","OUTPUT_DIM = date_output_lang.n_chars\n","EMB_DIM = 256\n","N_HEADS = 8\n","PF_DIM = 512\n","N_LAYERS = 2 # MVPì´ë¯€ë¡œ 2ê°œ ì¸µ ì‚¬ìš©\n","DROPOUT = 0.1\n","MAX_INPUT_LEN = 20 # ìµœëŒ€ ì…ë ¥ ê¸¸ì´ (ë°ì´í„°ì— ë”°ë¼ ì„¤ì •)\n","MAX_OUTPUT_LEN = 12 # ìµœëŒ€ ì¶œë ¥ ê¸¸ì´ (ë°ì´í„°ì— ë”°ë¼ ì„¤ì •: YYYY-MM-DD + SOS/EOS = 12)\n","N_EPOCHS = 1000 # ì¶©ë¶„í•œ í•™ìŠµ ë°˜ë³µ\n","BATCH_SIZE = len(raw_data) # ì‘ì€ ë°ì´í„°ì…‹ì´ë¯€ë¡œ ì „ì²´ ë°°ì¹˜ ì‚¬ìš©\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# model = Seq2SeqTransformer(INPUT_DIM, OUTPUT_DIM, EMB_DIM, N_HEADS, PF_DIM, N_LAYERS, DROPOUT, max(MAX_INPUT_LEN, MAX_OUTPUT_LEN)).to(device)\n","# optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","# criterion = nn.CrossEntropyLoss(ignore_index=0) # íŒ¨ë”©(ì¸ë±ìŠ¤ 0)ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸\n","\n","model = Seq2SeqTransformer(INPUT_DIM, OUTPUT_DIM, EMB_DIM, N_HEADS, PF_DIM, N_LAYERS, DROPOUT, max(MAX_INPUT_LEN, MAX_OUTPUT_LEN)).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","# ë³€ê²½: PAD ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì™€ì„œ ignore_indexë¡œ ì‚¬ìš©\n","pad_idx = date_output_lang.char2index[\"PAD\"]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n","\n","print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["c59219d49cb943c8a7b7e87792c6a993","bd5b5e1123084ad5a47c1df0b40d35bd","fbdb273125ed497dbf135adfca73d78f","da75c75bace94d898c6eb39c759666f7","c8ffdbb7f9c84a99ba608cfb87cb1250","269f65f5e8c54517b7df377502179ec5","db5044239bbb49808d8af804e569e626","c113427526914788ba476b765009c4e5","fb597123841143e89e4e8f7b7a6d0757","2c155b381b934c8b98d82128e5151379","e0703ed1573d4b348afdd2048b0ec0d2"]},"executionInfo":{"elapsed":479795,"status":"ok","timestamp":1759287371906,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"DGhFF_3Lgvgj","outputId":"378509fb-46b5-45f3-9833-168dcf3e4c9f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59219d49cb943c8a7b7e87792c6a993"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 100 | Train Loss: 0.0004\n","Epoch: 200 | Train Loss: 0.0002\n","Epoch: 300 | Train Loss: 0.0001\n","Epoch: 400 | Train Loss: 0.0000\n","Epoch: 500 | Train Loss: 0.0001\n","Epoch: 600 | Train Loss: 0.0000\n","Epoch: 700 | Train Loss: 0.0000\n","Epoch: 800 | Train Loss: 0.0000\n","Epoch: 900 | Train Loss: 0.0000\n","Epoch: 1000 | Train Loss: 0.0000\n"]}],"source":["# ë°ì´í„° ì¤€ë¹„\n","input_tensors, output_tensors = zip(*[tensor_from_pair(p, date_input_lang, date_output_lang, MAX_INPUT_LEN, MAX_OUTPUT_LEN) for p in raw_data])\n","SRC = torch.stack(input_tensors).to(device)\n","TRG = torch.stack(output_tensors).to(device)\n","\n","pbar = tqdm(range(N_EPOCHS))\n","for epoch in pbar:\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # ì¸ì½”ë” ì…ë ¥ ë§ˆìŠ¤í¬ (íŒ¨ë”© ë§ˆìŠ¤í¬) - ì´ ì˜ˆì‹œì—ì„œëŠ” íŒ¨ë”© ë§ˆìŠ¤í¬ë¥¼ ê°„ë‹¨í•˜ê²Œ ìƒëµí•˜ê±°ë‚˜ None ì²˜ë¦¬ ê°€ëŠ¥\n","    # í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” íŒ¨ë”© í† í° ì¸ë±ìŠ¤(0)ì— ë§ì¶° src_maskë¥¼ ë§Œë“¤ì–´ì•¼ í•¨. ì—¬ê¸°ì„œëŠ” Noneìœ¼ë¡œ ê°„ì£¼í•˜ê³  ìƒëµ\n","    src_mask = None\n","\n","    # ë””ì½”ë” ì…ë ¥ (íƒ€ê²Ÿ ì‹œí€€ìŠ¤ì—ì„œ ë§ˆì§€ë§‰ EOS í† í° ì œì™¸)\n","    trg_input = TRG[:, :-1]\n","\n","    # ì¸ê³¼ ê´€ê³„ ë§ˆìŠ¤í¬ ìƒì„±\n","    trg_mask = make_trg_mask(trg_input)\n","\n","    # ëª¨ë¸ ì˜ˆì¸¡\n","    #output = model(SRC, trg_input, src_mask, None) # src_maskëŠ” Noneìœ¼ë¡œ ë‹¨ìˆœí™”\n","    output = model(SRC, trg_input, src_mask, trg_mask)\n","\n","    # ì‹¤ì œ íƒ€ê²Ÿ (SOS í† í° ì œì™¸)\n","    output_dim = output.shape[-1]\n","    output = output.contiguous().view(-1, output_dim)\n","    trg_target = TRG[:, 1:].contiguous().view(-1)\n","\n","    # ì†ì‹¤ ê³„ì‚° ë° ì—­ì „íŒŒ\n","    loss = criterion(output, trg_target)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 100 == 0:\n","        print(f'Epoch: {epoch+1:03} | Train Loss: {loss.item():.4f}')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157418,"status":"ok","timestamp":1759290057228,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"U8-E4NZLgvgj","outputId":"89a7e90c-c4c9-442b-9425-3a18493d7e19"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì…ë ¥: 21 Oct 2020          | ì •ë‹µ: 2020-10-21 | ì˜ˆì¸¡: 2020-10-21 | O\n","ìµœì¢… íŠ¸ëœìŠ¤í¬ë¨¸ MVP ì •í™•ë„: 100.00%\n"]}],"source":["def translate_sentence(model, src_tensor, input_lang, output_lang, max_len, device):\n","    model.eval()\n","    with torch.no_grad():\n","        # ì¸ì½”ë”© ì‹œì‘\n","        src = src_tensor.unsqueeze(0).to(device)\n","        src_mask = None # íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒëµ\n","\n","        src_len = src.shape[1]\n","\n","        # ğŸ’¡ ìˆ˜ì • 1: src_pos í…ì„œ ì •ì˜ (device ì§€ì •)\n","        src_pos = torch.arange(0, src_len, device=device).unsqueeze(0)\n","        src = model.dropout(model.input_emb(src) + model.pos_emb(src_pos))\n","\n","        # ğŸ’¡ ìˆ˜ì • 2: model.encoderë¥¼ ë°˜ë³µë¬¸ìœ¼ë¡œ ì‹¤í–‰\n","        enc_src = src\n","        for layer in model.encoder:\n","            enc_src = layer(enc_src, src_mask)\n","\n","        # ë””ì½”ë”© (ìë™ íšŒê·€)\n","        trg_indexes = [output_lang.char2index[\"SOS\"]]\n","\n","        for i in range(max_len):\n","            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","            trg_mask = make_trg_mask(trg_tensor)\n","\n","            trg_len = trg_tensor.shape[1]\n","\n","            # ğŸ’¡ ìˆ˜ì • 3: trg_pos í…ì„œ ì •ì˜ (device ì§€ì •)\n","            trg_pos = torch.arange(0, trg_len, device=device).unsqueeze(0)\n","            trg_emb = model.dropout(model.output_emb(trg_tensor) + model.pos_emb(trg_pos))\n","\n","            # ğŸ’¡ ìˆ˜ì • 4: model.decoderë¥¼ ë°˜ë³µë¬¸ìœ¼ë¡œ ì‹¤í–‰\n","            output = trg_emb\n","            for layer in model.decoder:\n","                 # ë””ì½”ë”ì˜ ê° ë ˆì´ì–´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œ\n","                output = layer(output, enc_src, trg_mask, src_mask)\n","\n","            # ë§ˆì§€ë§‰ í† í°ì— ëŒ€í•œ ì˜ˆì¸¡ë§Œ ì‚¬ìš©\n","            pred_token = model.fc_out(output[:, -1, :]).argmax(dim=-1).item()\n","            trg_indexes.append(pred_token)\n","\n","            if pred_token == output_lang.char2index[\"EOS\"]:\n","                break\n","\n","        trg_tokens = [output_lang.index2char[i] for i in trg_indexes]\n","        return ''.join(trg_tokens[1:-1])\n","\n","# ì •í™•ë„ í…ŒìŠ¤íŠ¸\n","correct_count = 0\n","for i, pair in enumerate(raw_data):\n","    src_tensor = SRC[i]\n","    predicted_output = translate_sentence(model, src_tensor, date_input_lang, date_output_lang, MAX_OUTPUT_LEN, device)\n","\n","    if predicted_output == pair[1]:\n","        correct_count += 1\n","\n","    print(f\"\\rì…ë ¥: {pair[0]:<20} | ì •ë‹µ: {pair[1]:<10} | ì˜ˆì¸¡: {predicted_output:<10} | {'O' if predicted_output == pair[1] else 'X'}\", end='')\n","\n","accuracy = correct_count / len(raw_data)\n","print(f\"\\nìµœì¢… íŠ¸ëœìŠ¤í¬ë¨¸ MVP ì •í™•ë„: {accuracy * 100:.2f}%\")"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1759287528253,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"xcnG1rxGgvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1759287528256,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ljjUsF0ugvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1759287528260,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"wPp6AoUMgvgj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1759287528302,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Jo_KCd9mgvgj"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"env_colab_250827","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c59219d49cb943c8a7b7e87792c6a993":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd5b5e1123084ad5a47c1df0b40d35bd","IPY_MODEL_fbdb273125ed497dbf135adfca73d78f","IPY_MODEL_da75c75bace94d898c6eb39c759666f7"],"layout":"IPY_MODEL_c8ffdbb7f9c84a99ba608cfb87cb1250"}},"bd5b5e1123084ad5a47c1df0b40d35bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_269f65f5e8c54517b7df377502179ec5","placeholder":"â€‹","style":"IPY_MODEL_db5044239bbb49808d8af804e569e626","value":"100%"}},"fbdb273125ed497dbf135adfca73d78f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c113427526914788ba476b765009c4e5","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb597123841143e89e4e8f7b7a6d0757","value":1000}},"da75c75bace94d898c6eb39c759666f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c155b381b934c8b98d82128e5151379","placeholder":"â€‹","style":"IPY_MODEL_e0703ed1573d4b348afdd2048b0ec0d2","value":"â€‡1000/1000â€‡[07:59&lt;00:00,â€‡â€‡1.62it/s]"}},"c8ffdbb7f9c84a99ba608cfb87cb1250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"269f65f5e8c54517b7df377502179ec5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db5044239bbb49808d8af804e569e626":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c113427526914788ba476b765009c4e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb597123841143e89e4e8f7b7a6d0757":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c155b381b934c8b98d82128e5151379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0703ed1573d4b348afdd2048b0ec0d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}