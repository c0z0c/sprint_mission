{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb497806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54383,
     "status": "ok",
     "timestamp": 1759244428821,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "fb497806",
    "outputId": "c98f783d-68a3-4945-849c-ba42ae2cd4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜\\ì‹¤ìŠµ\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜\\ì‹¤ìŠµ\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜\\ì‹¤ìŠµ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'helper_utils' from 'd:\\\\GoogleDrive\\\\homepage\\\\ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜\\\\ì‹¤ìŠµ\\\\helper_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_utils.py\", \"helper_utils.py\")\n",
    "import importlib\n",
    "import helper_utils as hu\n",
    "importlib.reload(hu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "KnU9362K56JE",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759244428835,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "KnU9362K56JE"
   },
   "outputs": [],
   "source": [
    "# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n",
    "from sklearn.linear_model import LinearRegression  # ì„ í˜•/ë‹¤ì¤‘ íšŒê·€\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler  # ë‹¤í•­ íŠ¹ì„±, ì •ê·œí™”\n",
    "from sklearn.model_selection import train_test_split  # ë°ì´í„° ë¶„í• \n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")  # ë‹¤ì–‘í•œ ì˜ˆì œ ë°ì´í„°ì…‹\n",
    "from sklearn import datasets  # ì¶”ê°€ ë°ì´í„°ì…‹\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree  # ê²°ì •íŠ¸ë¦¬\n",
    "from sklearn.ensemble import RandomForestClassifier  # ëœë¤í¬ë ˆìŠ¤íŠ¸\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error  # í‰ê°€ ì§€í‘œ\n",
    "\n",
    "# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n",
    "from PIL import Image  # ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "\n",
    "# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n",
    "import torch\n",
    "import torch.nn as nn  # ì‹ ê²½ë§\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # í™œì„±í™” í•¨ìˆ˜\n",
    "from torch.utils.data import Dataset, DataLoader  # PyTorch ë°ì´í„°ì…‹/ë¡œë”\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# --- ê¸°íƒ€ ---\n",
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "import tarfile\n",
    "import shutil\n",
    "import json\n",
    "import signal\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "import matplotlib.pyplot as plt  # ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "# --- ë””ë°”ì´ìŠ¤ ì„¤ì • ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "SqkmI0Wp7Enl",
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1759244428893,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "SqkmI0Wp7Enl"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71cc49c",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759244428896,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "b71cc49c"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.hidden_size = hidden_size  # ìˆ˜ì •: hidden_szie â†’ hidden_size\n",
    "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "  def forward(self, input_):\n",
    "    embedded = self.embedding(input_)\n",
    "    output, hidden = self.gru(embedded)\n",
    "    return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36e01a7",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759244428905,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "e36e01a7"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "  def __init__(self, hidden_size):\n",
    "    super().__init__()\n",
    "    self.W = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "    self.U = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "    self.V = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "  def forward(self, decoder_hidden, encoder_outputs):\n",
    "    s_proj = self.W(decoder_hidden.permute(1, 0, 2))\n",
    "    h_proj = self.U(encoder_outputs)\n",
    "    scored = self.V(torch.tanh(s_proj + h_proj))\n",
    "    attn_weights = F.softmax(scored, dim=1)\n",
    "    # batch matrix multiplcation\n",
    "    context = torch.bmm(attn_weights.permute(0, 2, 1), encoder_outputs)\n",
    "\n",
    "    return context, attn_weights.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0754075",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759244428914,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "d0754075"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "  def __init__(self, hidden_size, output_size):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "    self.attention = BahdanauAttention(hidden_size)\n",
    "    self.gru = nn.GRU(hidden_size * 2, hidden_size, batch_first=True)\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, decoder_input, decoder_hidden, encoder_outputs):\n",
    "    embedded = self.embedding(decoder_input)\n",
    "    context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
    "    rnn_input = torch.cat((embedded, context), dim=2)\n",
    "    output, hidden = self.gru(rnn_input, decoder_hidden)\n",
    "    output = F.log_softmax(self.out(output.squeeze(1)), dim=1)\n",
    "\n",
    "    return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539dd091",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759244428926,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "539dd091"
   },
   "outputs": [],
   "source": [
    "def train_bahdanau(input_tensor, target_tensor, encoder, decoder, optimizer, criterion):\n",
    "    encoder_optimizer, decoder_optimizer = optimizer\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    loss = 0\n",
    "    target_length = target_tensor.size(1)\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        loss += criterion(decoder_output, target_tensor[:, di])\n",
    "        decoder_input = target_tensor[:, di].unsqueeze(1)\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbf7e18-3d73-4ada-b78f-f94e77eb5f31",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1759244428944,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "dcbf7e18-3d73-4ada-b78f-f94e77eb5f31"
   },
   "outputs": [],
   "source": [
    "INPUT_FORMATS = [\n",
    "    '%B %d, %Y',  # June 18, 2025\n",
    "    '%d %b %Y',   # 18 Jun 2025\n",
    "    '%Y/%m/%d',   # 2025/06/18\n",
    "    '%m-%d-%Y'    # 06-18-2025\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b97cd3b",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759244428958,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "6b97cd3b"
   },
   "outputs": [],
   "source": [
    "OUTPUT_FORMATS = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ce1797",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759244428967,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "c2ce1797"
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_examples):\n",
    "    \"\"\"ëª¨ë“  ê°€ëŠ¥í•œ ì›” ì´ë¦„ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    dataset = []\n",
    "\n",
    "    # ëª¨ë“  ì›” ì´ë¦„ê³¼ ì¶•ì•½í˜•ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨\n",
    "    full_months = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "    short_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "    for i in range(n_examples):\n",
    "        year = random.randint(1990, 2030)\n",
    "        month = (i % 12) + 1\n",
    "        day = random.randint(1, 28)\n",
    "\n",
    "        current_date = datetime(year, month, day)\n",
    "\n",
    "        # í¬ë§· ì„ íƒì„ ë” ê· ë“±í•˜ê²Œ\n",
    "        format_choice = i % 4\n",
    "\n",
    "        if format_choice == 0:  # ì „ì²´ ì›” ì´ë¦„\n",
    "            input_str = f\"{full_months[month-1]} {day:02d}, {year}\"\n",
    "        elif format_choice == 1:  # ì¶•ì•½ ì›” ì´ë¦„\n",
    "            input_str = f\"{day:02d} {short_months[month-1]} {year}\"\n",
    "        elif format_choice == 2:  # ìˆ«ì ìŠ¬ë˜ì‹œ\n",
    "            input_str = f\"{year}/{month:02d}/{day:02d}\"\n",
    "        else:  # ìˆ«ì í•˜ì´í”ˆ\n",
    "            input_str = f\"{month:02d}-{day:02d}-{year}\"\n",
    "\n",
    "        output_str = current_date.strftime('%Y-%m-%d')\n",
    "        dataset.append((input_str, output_str))\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5864f1e3-7977-4fca-964d-5f8b1255b18e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759244428978,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "5864f1e3-7977-4fca-964d-5f8b1255b18e"
   },
   "outputs": [],
   "source": [
    "raw_data = create_dataset(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00552cce-7702-45fe-9962-a1417092b181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759244428982,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "00552cce-7702-45fe-9962-a1417092b181",
    "outputId": "5e92e636-86a5-4ac6-b515-f87517d808b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('05 Jun 1992', '1992-06-05'),\n",
       " ('12-01-2009', '2009-12-01'),\n",
       " ('08-13-2018', '2018-08-13'),\n",
       " ('2017/11/25', '2017-11-25'),\n",
       " ('1997/07/06', '1997-07-06'),\n",
       " ('2020/03/18', '2020-03-18'),\n",
       " ('September 19, 2024', '2024-09-19'),\n",
       " ('1992/07/22', '1992-07-22'),\n",
       " ('May 10, 2013', '2013-05-10'),\n",
       " ('September 13, 1995', '1995-09-13')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ccde058",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759244428987,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "5ccde058"
   },
   "outputs": [],
   "source": [
    "# ë¬¸ì ë‹¨ìœ„ í† í°í™”ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ Lang í´ë˜ìŠ¤\n",
    "class CharLang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {}\n",
    "        self.index2char = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_chars = 2\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for char in sentence:\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = self.n_chars\n",
    "                self.index2char[self.n_chars] = char\n",
    "                self.n_chars += 1\n",
    "\n",
    "# ë¬¸ì ë‹¨ìœ„ ì–¸ì–´ í´ë˜ìŠ¤ ìƒì„±\n",
    "date_input_lang = CharLang(\"date_input\")\n",
    "date_output_lang = CharLang(\"date_output\")\n",
    "\n",
    "# ë¬¸ì ë‹¨ìœ„ë¡œ vocabulary êµ¬ì¶•\n",
    "for pair in raw_data:\n",
    "    date_input_lang.add_sentence(pair[0])\n",
    "    date_output_lang.add_sentence(pair[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ec4c71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1759244429000,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "94ec4c71",
    "outputId": "5a7a08e4-0989-432a-a364-588bdc1d67aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input character vocabulary size: 32\n",
      "Output character vocabulary size: 13\n",
      "date_input_lang {'0': 2, '5': 3, ' ': 4, 'J': 5, 'u': 6, 'n': 7, '1': 8, '9': 9, '2': 10, '-': 11, '8': 12, '3': 13, '7': 14, '/': 15, '6': 16, 'S': 17, 'e': 18, 'p': 19, 't': 20, 'm': 21, 'b': 22, 'r': 23, ',': 24, '4': 25, 'M': 26, 'a': 27, 'y': 28, 'F': 29, 'O': 30, 'c': 31}\n",
      "date_output_lang {'1': 2, '9': 3, '2': 4, '-': 5, '0': 6, '6': 7, '5': 8, '8': 9, '3': 10, '7': 11, '4': 12}\n",
      "=== date_input_lang ë¶„ì„ ===\n",
      "Language name: date_input\n",
      "Total characters: 32\n",
      "\n",
      "Index to Character mapping:\n",
      "0 â†’ 'SOS'\n",
      "1 â†’ 'EOS'\n",
      "2 â†’ '0'\n",
      "3 â†’ '5'\n",
      "4 â†’ ' '\n",
      "5 â†’ 'J'\n",
      "6 â†’ 'u'\n",
      "7 â†’ 'n'\n",
      "8 â†’ '1'\n",
      "9 â†’ '9'\n",
      "10 â†’ '2'\n",
      "\n",
      "=== ìƒ˜í”Œ ì…ë ¥ ë¬¸ì¥ë“¤ì˜ í† í°í™” ===\n",
      "Input: 'June 18, 2025'\n",
      "Character list: ['J', 'u', 'n', 'e', ' ', '1', '8', ',', ' ', '2', '0', '2', '5']\n",
      "Character indices: [5, 6, 7, 18, 4, 8, 12, 24, 4, 10, 2, 10, 3]\n",
      "Reconstructed: 'June 18, 2025'\n",
      "Match: True\n",
      "--------------------------------------------------\n",
      "Input: '18 Jun 2025'\n",
      "Character list: ['1', '8', ' ', 'J', 'u', 'n', ' ', '2', '0', '2', '5']\n",
      "Character indices: [8, 12, 4, 5, 6, 7, 4, 10, 2, 10, 3]\n",
      "Reconstructed: '18 Jun 2025'\n",
      "Match: True\n",
      "--------------------------------------------------\n",
      "Input: '2025/06/18'\n",
      "Character list: ['2', '0', '2', '5', '/', '0', '6', '/', '1', '8']\n",
      "Character indices: [10, 2, 10, 3, 15, 2, 16, 15, 8, 12]\n",
      "Reconstructed: '2025/06/18'\n",
      "Match: True\n",
      "--------------------------------------------------\n",
      "Input: '06-18-2025'\n",
      "Character list: ['0', '6', '-', '1', '8', '-', '2', '0', '2', '5']\n",
      "Character indices: [2, 16, 11, 8, 12, 11, 10, 2, 10, 3]\n",
      "Reconstructed: '06-18-2025'\n",
      "Match: True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input character vocabulary size: {date_input_lang.n_chars}\")\n",
    "print(f\"Output character vocabulary size: {date_output_lang.n_chars}\")\n",
    "print(\"date_input_lang\", date_input_lang.char2index)\n",
    "print(\"date_output_lang\", date_output_lang.char2index)\n",
    "\n",
    "# date_input_lang ìƒì„¸ í™•ì¸\n",
    "print(\"=== date_input_lang ë¶„ì„ ===\")\n",
    "print(f\"Language name: {date_input_lang.name}\")\n",
    "print(f\"Total characters: {date_input_lang.n_chars}\")\n",
    "print()\n",
    "\n",
    "# print(\"Character to Index mapping:\")\n",
    "# for char, idx in sorted(date_input_lang.char2index.items()):\n",
    "#     print(f\"'{char}' â†’ {idx}\")\n",
    "# print()\n",
    "\n",
    "print(\"Index to Character mapping:\")\n",
    "for idx, char in sorted(date_input_lang.index2char.items()):\n",
    "    if idx <= 10:  # ì²˜ìŒ ëª‡ ê°œë§Œ ì¶œë ¥\n",
    "        print(f\"{idx} â†’ '{char}'\")\n",
    "print()\n",
    "\n",
    "# ìƒ˜í”Œ ë¬¸ì¥ë“¤ì´ ì–´ë–»ê²Œ í† í°í™”ë˜ëŠ”ì§€ í™•ì¸\n",
    "print(\"=== ìƒ˜í”Œ ì…ë ¥ ë¬¸ì¥ë“¤ì˜ í† í°í™” ===\")\n",
    "sample_inputs = [\n",
    "    \"June 18, 2025\",\n",
    "    \"18 Jun 2025\",\n",
    "    \"2025/06/18\",\n",
    "    \"06-18-2025\"\n",
    "]\n",
    "\n",
    "for sample in sample_inputs:\n",
    "    print(f\"Input: '{sample}'\")\n",
    "    char_list = [char for char in sample]\n",
    "    char_indices = [date_input_lang.char2index.get(char, -1) for char in sample]\n",
    "    print(f\"Character list: {char_list}\")\n",
    "    print(f\"Character indices: {char_indices}\")\n",
    "\n",
    "    # ì—­ë³€í™˜ í…ŒìŠ¤íŠ¸\n",
    "    reconstructed = ''.join([date_input_lang.index2char.get(idx, '?') for idx in char_indices if idx != -1])\n",
    "    print(f\"Reconstructed: '{reconstructed}'\")\n",
    "    print(f\"Match: {sample == reconstructed}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "DGTQs610JL3h",
   "metadata": {
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1759244743452,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "DGTQs610JL3h"
   },
   "outputs": [],
   "source": [
    "def create_weighted_criterion(output_lang, device=device):\n",
    "    # í´ë˜ìŠ¤(ë¬¸ì) ê°€ì¤‘ì¹˜ ê¸°ë³¸ ì„¤ì •\n",
    "    weights = torch.ones(output_lang.n_chars, device=device)\n",
    "\n",
    "    # ìˆ«ì ì „ì²´ ê°€ì¤‘ì¹˜ ì¦ê°€\n",
    "    for char, idx in output_lang.char2index.items():\n",
    "        if char.isdigit():\n",
    "            weights[idx] = 2.0\n",
    "\n",
    "    # '0','1' ê°™ì´ í˜¼ë™ë˜ëŠ” ìˆ«ìì— ì¶”ê°€ ê°€ì¤‘ì¹˜ (ì˜µì…˜)\n",
    "    for c in ['0','1']:\n",
    "        if c in output_lang.char2index:\n",
    "            weights[output_lang.char2index[c]] = 2.5\n",
    "\n",
    "    # êµ¬ë¶„ì í•˜ì´í”ˆì— ê°€ì¤‘ì¹˜\n",
    "    if '-' in output_lang.char2index:\n",
    "        weights[output_lang.char2index['-']] = 2.0\n",
    "    if '/' in output_lang.char2index:\n",
    "        weights[output_lang.char2index['/']] = 1.5\n",
    "\n",
    "    # reduction='none'ë¡œ ê°œë³„ í† í° ì†ì‹¤ ë°˜í™˜\n",
    "    return nn.CrossEntropyLoss(weight=weights, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ada2d65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ada2d65",
    "outputId": "e7238602-101f-43ae-fbf3-db88a642e2d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1004/10000 [01:23<06:28, 23.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000 / 10000, Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2002/10000 [02:20<10:32, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2000 / 10000, Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3002/10000 [03:43<07:09, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3000 / 10000, Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4001/10000 [05:26<11:21,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4000 / 10000, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5004/10000 [06:27<04:28, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000 / 10000, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6002/10000 [07:51<06:17, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6000 / 10000, Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7001/10000 [09:42<07:26,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7000 / 10000, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8000/10000 [11:19<04:59,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8000 / 10000, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9004/10000 [12:38<00:46, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9000 / 10000, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [13:28<00:00, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000 / 10000, Loss: 0.0000\n",
      "Character-level date format translation model training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì ë‹¨ìœ„ í…ì„œ ë³€í™˜ í•¨ìˆ˜\n",
    "def char_tensor_from_sentence(lang, sentence):\n",
    "    indexes = [lang.char2index[char] for char in sentence]\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "# ëª¨ë¸ ì¬ìƒì„± (vocabulary í¬ê¸°ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ)\n",
    "hidden_size = 256\n",
    "date_encoder = EncoderRNN(date_input_lang.n_chars, hidden_size).to(device)\n",
    "date_decoder = BahdanauAttnDecoderRNN(hidden_size, date_output_lang.n_chars).to(device)\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ì¬ì„¤ì •\n",
    "date_encoder_optimizer = optim.Adam(date_encoder.parameters(), lr=0.0005)\n",
    "date_decoder_optimizer = optim.Adam(date_decoder.parameters(), lr=0.0005)\n",
    "date_optimizers = (date_encoder_optimizer, date_decoder_optimizer)\n",
    "#criterion = nn.NLLLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = create_weighted_criterion(date_output_lang)\n",
    "\n",
    "# í•™ìŠµ (ë¬¸ì ë‹¨ìœ„)\n",
    "n_iters = 10000\n",
    "#n_iters = 10\n",
    "print_every = 1000\n",
    "\n",
    "pbar = tqdm(range(1, n_iters + 1))\n",
    "for iteration in pbar:\n",
    "    pair = random.choice(raw_data)\n",
    "    input_tensor = char_tensor_from_sentence(date_input_lang, pair[0]).transpose(0, 1)\n",
    "    target_tensor = char_tensor_from_sentence(date_output_lang, pair[1]).transpose(0, 1)\n",
    "\n",
    "    loss = train_bahdanau(input_tensor, target_tensor, date_encoder, date_decoder, date_optimizers, criterion)\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "        print(f\"Iteration: {iteration} / {n_iters}, Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Character-level date format translation model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adc2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0804656",
   "metadata": {
    "id": "f0804656"
   },
   "outputs": [],
   "source": [
    "def evaluate_char_date_translation(input_sentence, encoder, decoder):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = char_tensor_from_sentence(date_input_lang, input_sentence).transpose(0, 1)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_chars = []\n",
    "        decoder_attentions = []\n",
    "\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions.append(attn_weights.squeeze().cpu().numpy())\n",
    "\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "            else:\n",
    "                decoded_chars.append(date_output_lang.index2char[topi.item()])\n",
    "            decoder_input = topi.squeeze().detach().view(1, -1)\n",
    "\n",
    "        return ''.join(decoded_chars), decoder_attentions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524d0440",
   "metadata": {
    "id": "524d0440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Character-level Date Format Translation Results ===\n",
      "Input: September 20, 2025\n",
      "Output: 2025-09-20\n",
      "----------------------------------------\n",
      "Input: 18 Jun 2025\n",
      "Output: 2025-06-18\n",
      "----------------------------------------\n",
      "Input: 2025/06/18\n",
      "Output: 2025-06-18\n",
      "----------------------------------------\n",
      "Input: 06-18-2025\n",
      "Output: 2025-06-18\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸\n",
    "test_examples = [\n",
    "    \"September 20, 2025\",\n",
    "    \"18 Jun 2025\",\n",
    "    \"2025/06/18\",\n",
    "    \"06-18-2025\"\n",
    "]\n",
    "\n",
    "print(\"=== Character-level Date Format Translation Results ===\")\n",
    "for test_input in test_examples:\n",
    "    try:\n",
    "        predicted_output, attentions = evaluate_char_date_translation(test_input, date_encoder, date_decoder)\n",
    "        print(f\"Input: {test_input}\")\n",
    "        print(f\"Output: {predicted_output}\")\n",
    "        print(\"-\" * 40)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with input '{test_input}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e519be",
   "metadata": {
    "id": "e9e519be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unit Test for Date Translation Model (50 tests) ===\n",
      "Test   1: FAIL\n",
      "  Input:     '2021/01/11'\n",
      "  Expected:  '2021-01-11'\n",
      "  Predicted: '2021-11-11'\n",
      "--------------------------------------------------\n",
      "Test   2: PASS\n",
      "  Input:     '04-07-2025'\n",
      "  Expected:  '2025-04-07'\n",
      "  Predicted: '2025-04-07'\n",
      "--------------------------------------------------\n",
      "Test   3: FAIL\n",
      "  Input:     '31 Oct 2023'\n",
      "  Expected:  '2023-10-31'\n",
      "  Predicted: '2023-10-13'\n",
      "--------------------------------------------------\n",
      "Test   4: PASS\n",
      "  Input:     '24 Sep 2021'\n",
      "  Expected:  '2021-09-24'\n",
      "  Predicted: '2021-09-24'\n",
      "--------------------------------------------------\n",
      "Test   5: FAIL\n",
      "  Input:     '30 Jan 2020'\n",
      "  Expected:  '2020-01-30'\n",
      "  Predicted: '2020-06-03'\n",
      "--------------------------------------------------\n",
      "Test   6: FAIL\n",
      "  Input:     '11-29-2021'\n",
      "  Expected:  '2021-11-29'\n",
      "  Predicted: '2021-11-21'\n",
      "--------------------------------------------------\n",
      "Test   7: PASS\n",
      "  Input:     '2022/06/26'\n",
      "  Expected:  '2022-06-26'\n",
      "  Predicted: '2022-06-26'\n",
      "--------------------------------------------------\n",
      "Test   8: FAIL\n",
      "  Input:     '03-31-2022'\n",
      "  Expected:  '2022-03-31'\n",
      "  Predicted: '2022-03-13'\n",
      "--------------------------------------------------\n",
      "Test   9: ERROR\n",
      "  Input: 'March 17, 2025'\n",
      "  Error: 'h'\n",
      "--------------------------------------------------\n",
      "Test  10: PASS\n",
      "  Input:     '2023/07/04'\n",
      "  Expected:  '2023-07-04'\n",
      "  Predicted: '2023-07-04'\n",
      "--------------------------------------------------\n",
      "Test  11: FAIL\n",
      "  Input:     '2022/10/22'\n",
      "  Expected:  '2022-10-22'\n",
      "  Predicted: '2022-01-22'\n",
      "--------------------------------------------------\n",
      "Test  14: ERROR\n",
      "  Input: '09 Apr 2024'\n",
      "  Error: 'A'\n",
      "--------------------------------------------------\n",
      "Test  15: ERROR\n",
      "  Input: '15 Aug 2021'\n",
      "  Error: 'A'\n",
      "--------------------------------------------------\n",
      "Test  16: ERROR\n",
      "  Input: 'July 17, 2021'\n",
      "  Error: 'l'\n",
      "--------------------------------------------------\n",
      "Test  19: FAIL\n",
      "  Input:     '2024/01/29'\n",
      "  Expected:  '2024-01-29'\n",
      "  Predicted: '2024-11-29'\n",
      "--------------------------------------------------\n",
      "Test  23: ERROR\n",
      "  Input: 'October 28, 2020'\n",
      "  Error: 'o'\n",
      "--------------------------------------------------\n",
      "Test  26: FAIL\n",
      "  Input:     '01-10-2020'\n",
      "  Expected:  '2020-01-10'\n",
      "  Predicted: '2020-10-10'\n",
      "--------------------------------------------------\n",
      "Test  30: FAIL\n",
      "  Input:     '11-30-2023'\n",
      "  Expected:  '2023-11-30'\n",
      "  Predicted: '2023-11-03'\n",
      "--------------------------------------------------\n",
      "Test  31: ERROR\n",
      "  Input: 'March 16, 2025'\n",
      "  Error: 'h'\n",
      "--------------------------------------------------\n",
      "Test  33: FAIL\n",
      "  Input:     '2023/01/28'\n",
      "  Expected:  '2023-01-28'\n",
      "  Predicted: '2023-11-28'\n",
      "--------------------------------------------------\n",
      "Test  34: FAIL\n",
      "  Input:     '16 Jan 2021'\n",
      "  Expected:  '2021-01-16'\n",
      "  Predicted: '2021-06-16'\n",
      "--------------------------------------------------\n",
      "Test  36: ERROR\n",
      "  Input: '19 Dec 2022'\n",
      "  Error: 'D'\n",
      "--------------------------------------------------\n",
      "Test  38: FAIL\n",
      "  Input:     '10-26-2023'\n",
      "  Expected:  '2023-10-26'\n",
      "  Predicted: '2023-01-26'\n",
      "--------------------------------------------------\n",
      "Test  40: FAIL\n",
      "  Input:     '31 Mar 2020'\n",
      "  Expected:  '2020-03-31'\n",
      "  Predicted: '2020-05-10'\n",
      "--------------------------------------------------\n",
      "Test  42: ERROR\n",
      "  Input: '30 Jul 2024'\n",
      "  Error: 'l'\n",
      "--------------------------------------------------\n",
      "Test  43: FAIL\n",
      "  Input:     '2022/01/18'\n",
      "  Expected:  '2022-01-18'\n",
      "  Predicted: '2022-11-18'\n",
      "--------------------------------------------------\n",
      "Test  45: ERROR\n",
      "  Input: '14 Nov 2022'\n",
      "  Error: 'N'\n",
      "--------------------------------------------------\n",
      "Test  47: FAIL\n",
      "  Input:     '01-18-2024'\n",
      "  Expected:  '2024-01-18'\n",
      "  Predicted: '2024-10-18'\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Test Results Summary ===\n",
      "Total Tests:   50\n",
      "Successful:    26 (52.0%)\n",
      "Failed:        24 (48.0%)\n",
      "Success Rate:  52.0%\n"
     ]
    }
   ],
   "source": [
    "def unit_test_date_translation(n_tests=100):\n",
    "    \"\"\"\n",
    "    ë‚ ì§œ í¬ë§· ë³€í™˜ ëª¨ë¸ì˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        n_tests: í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ê°œìˆ˜\n",
    "\n",
    "    Returns:\n",
    "        success_count, fail_count: ì„±ê³µ ë° ì‹¤íŒ¨ ê±´ìˆ˜\n",
    "    \"\"\"\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "\n",
    "    print(f\"=== Unit Test for Date Translation Model ({n_tests} tests) ===\")\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "\n",
    "    for i in range(n_tests):\n",
    "        try:\n",
    "            # í…ŒìŠ¤íŠ¸ìš© ë‚ ì§œ ìƒì„±\n",
    "            test_date = start_date + timedelta(days=random.randint(0, 2000))\n",
    "\n",
    "            # INPUT_FORMATS ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ ì„ íƒ\n",
    "            input_format = random.choice(INPUT_FORMATS)\n",
    "\n",
    "            # ì…ë ¥ ë¬¸ìì—´ ìƒì„±\n",
    "            input_str = test_date.strftime(input_format)\n",
    "\n",
    "            # ì˜ˆìƒ ì¶œë ¥ (ì •ë‹µ)\n",
    "            expected_output = test_date.strftime(OUTPUT_FORMATS)\n",
    "\n",
    "            # ëª¨ë¸ ì˜ˆì¸¡\n",
    "            predicted_output, attentions = evaluate_char_date_translation(input_str, date_encoder, date_decoder)\n",
    "\n",
    "            # ê²°ê³¼ ë¹„êµ\n",
    "            if predicted_output == expected_output:\n",
    "                success_count += 1\n",
    "                status = \"PASS\"\n",
    "            else:\n",
    "                fail_count += 1\n",
    "                status = \"FAIL\"\n",
    "\n",
    "            # ì²˜ìŒ 10ê°œì™€ ì‹¤íŒ¨í•œ ì¼€ì´ìŠ¤ë§Œ ì¶œë ¥\n",
    "            if i < 10 or predicted_output != expected_output:\n",
    "                print(f\"Test {i+1:3d}: {status}\")\n",
    "                print(f\"  Input:     '{input_str}'\")\n",
    "                print(f\"  Expected:  '{expected_output}'\")\n",
    "                print(f\"  Predicted: '{predicted_output}'\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        except Exception as e:\n",
    "            fail_count += 1\n",
    "            print(f\"Test {i+1:3d}: ERROR\")\n",
    "            print(f\"  Input: '{input_str if 'input_str' in locals() else 'N/A'}'\")\n",
    "            print(f\"  Error: {e}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    total_tests = success_count + fail_count\n",
    "    success_rate = (success_count / total_tests * 100) if total_tests > 0 else 0\n",
    "\n",
    "    print(f\"\\n=== Test Results Summary ===\")\n",
    "    print(f\"Total Tests:   {total_tests}\")\n",
    "    print(f\"Successful:    {success_count} ({success_rate:.1f}%)\")\n",
    "    print(f\"Failed:        {fail_count} ({100-success_rate:.1f}%)\")\n",
    "    print(f\"Success Rate:  {success_rate:.1f}%\")\n",
    "\n",
    "    return success_count, fail_count\n",
    "\n",
    "# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "success, fail = unit_test_date_translation(n_tests=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a51b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d032971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1NkmVs7u-0w0QnfqyBSzldbfkR1tNa1vK",
     "timestamp": 1759207323827
    }
   ]
  },
  "kernelspec": {
   "display_name": "env_colab_250827",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
