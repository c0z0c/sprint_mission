---
layout: default
title: "축구 경기 영상 시맨틱 세그멘테이션(Semantic Segmentation) 기술 보고서"
description: "축구 경기 영상 시맨틱 세그멘테이션(Semantic Segmentation) 기술 보고서"
cache-control: no-cache
date: 2025-09-02
expires: 0
pragma: no-cache
---

# 축구 경기 영상 시맨틱 세그멘테이션(Semantic Segmentation) 기술 보고서

## 1. 미션 개요

### 1.1. 프로젝트 목표
본 연구에서는 U-Net 아키텍처를 활용하여 축구 경기 영상 내 다양한 객체들을 픽셀 단위로 분할하는 시맨틱 세그멘테이션 작업을 수행했습니다. UEFA 슈퍼컵 2017 레알 마드리드 vs 맨체스터 유나이티드 경기에서 추출한 프레임을 기반으로, 11개 클래스에 대한 정밀한 객체 분할 모델을 개발하고 성능을 평가했습니다.

### 1.2. 주요 도전과제
축구 경기 영상의 시맨틱 세그멘테이션은 다음과 같은 기술적 도전을 포함합니다:
- **클래스 불균형**: 축구공과 같은 작은 객체 vs 잔디와 같은 대면적 객체
- **객체 간 경계 모호성**: 선수 간 중첩, 관중석과 배경의 구분
- **실시간성 요구**: 실제 경기 분석에서의 처리 속도 최적화
- **다양한 조명 조건**: 경기장 조명, 그림자, 시간대별 변화

## 2. 데이터셋 분석

### 2.1. 데이터 구성
```
총 이미지 수: 100장 (1920×1080 해상도)
총 어노테이션 수: 915개
이미지당 평균 어노테이션: 9.2개
세그멘테이션 포함률: 100%
```
  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/%EC%B6%95%EA%B5%AC_%EC%8B%9C%EB%A7%A8%ED%8B%B1_%EC%84%B8%EA%B7%B8%EB%A9%98%ED%85%8C%EC%9D%B4%EC%85%98_%EC%85%88%ED%94%8C.png" width="1020px"/>

### 2.2. 클래스별 분포 분석
| 클래스 | 어노테이션 수 | 평균 면적 | 특성 |
|--------|---------------|-----------|------|
| Team A | 192개 | 75,780 픽셀 | 주요 객체, 중간 크기 |
| Team B | 210개 | 80,459 픽셀 | 주요 객체, 중간 크기 |
| Ground | 86개 | 977,063 픽셀 | 대면적 배경 |
| Audience | 94개 | 552,828 픽셀 | 대면적 배경 |
| Ball | 64개 | 3,682 픽셀 | **최소 객체, 높은 중요도** |
| Advertisements | 96개 | 337,971 픽셀 | 중간 면적 |
| Goalkeeper A/B | 85개 | 42,610 픽셀 | 소수 중요 객체 |
| Goal Bar | 64개 | 46,774 픽셀 | 구조물, 중요 |
| Referee | 24개 | 32,532 픽셀 | **최소 빈도 클래스** |

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EB%B3%84_%EC%96%B4%EC%BD%94%ED%85%8C%EC%9D%B4%EC%85%98_%EB%B6%84%ED%8F%AC_%EB%A7%89%EB%8C%80%EA%B7%B8%EB%9E%98%ED%94%84.png" width="640px"/> <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EB%B3%84_%EC%96%B4%EC%BD%94%ED%85%8C%EC%9D%B4%EC%85%98_%EB%B6%84%ED%8F%AC_%ED%8C%8C%EC%9D%B4%EA%B7%B8%EB%9E%98%ED%94%84.png" width="380px"/>

---

### 2.3. 데이터셋 분할 전략
```
훈련 데이터: 70개 이미지 (70%)
검증 데이터: 20개 이미지 (20%) 
테스트 데이터: 10개 이미지 (10%)
```

**데이터 증강 실험**:
- 기본 그룹: 증강 없음 (원본 데이터만 사용)
- 증강 그룹: 훈련×8배, 검증×2배 (560/40/10 구성)

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A6%9D%EA%B0%95_%ED%9A%A8%EA%B3%BC_%EC%8B%9C%EA%B0%81%ED%99%94.png" width="1020px"/>

## 3. 모델 아키텍처 설계

### 3.1. U-Net 변형 모델들

#### 3.1.1. UNet300 (커스텀 구현)
```python
입력 크기: 300×300×3
아키텍처: 4단계 인코더-디코더 + 스킵 커넥션
채널 진행: 3→64→128→256→512→1024→512→256→128→64→11
주요 특징: BatchNorm 추가, Bilinear 업샘플링
```

**구조적 특징**:
- **인코더**: 각 단계마다 Conv2d + BatchNorm2d + ReLU 반복
- **보틀넥**: 최대 1024 채널로 특징 추출
- **디코더**: ConvTranspose2d + 스킵 커넥션으로 해상도 복원
- **출력층**: 1×1 컨볼루션으로 클래스 수만큼 출력

#### 3.1.2. U-Net ResNet34 (사전학습 백본)
```python
백본: ResNet34 (ImageNet 사전학습)
라이브러리: segmentation-models-pytorch
인코더: 고정 vs 파인튜닝 옵션
디코더: 축구 데이터에 맞춤 학습
```

**주요 장점**:
- **사전학습 가중치** 활용으로 빠른 수렴
- **강력한 특징 추출**: ImageNet에서 학습된 일반적 특징
- **전이 학습**: 축구 도메인에 특화된 파인튜닝

### 3.2. 스킵 커넥션(Skip Connection)의 중요성

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/3_2_%EC%8A%A4%ED%82%B5_%EC%BB%A4%EB%84%A5%EC%85%98.png" width="400px"/>

스킵 커넥션은 인코딩 과정에서 손실된 세부 정보를 디코딩 단계에서 복원하는 핵심 메커니즘입니다. 특히 축구공과 같은 작은 객체의 경계를 정확히 복원하는 데 중요한 역할을 합니다.

## 4. 손실 함수 비교 분석

### 4.1. 손실 함수별 특성

#### 4.1.1. CrossEntropy Loss
```python
특징: 기본 다중 클래스 분류 손실
수식: L = -∑(y_i × log(ŷ_i))
장점: 안정적인 수렴, 구현 간단
단점: 클래스 불균형 미고려
```

#### 4.1.2. Weighted CrossEntropy Loss
```python
특징: 클래스 빈도 기반 가중치 적용
가중치 계산: w_i = 1 / frequency_i
효과: 축구공, 골키퍼 등 소수 클래스 강화
적용 예: Ball 클래스 가중치 5.0 적용
```

#### 4.1.3. Focal Loss
```python
수식: FL = -α × (1-p_t)^γ × log(p_t)
파라미터: α=1.0, γ=2.0
특징: 어려운 샘플(오분류가 많은 픽셀)에 집중
효과: 객체 경계 부분의 정확도 향상
```

#### 4.1.4. Dice Loss
```python
수식: Dice = 2×|X∩Y| / (|X|+|Y|)
손실: L_dice = 1 - Dice
특징: 세그멘테이션 형태 보존에 특화
효과: IoU 지표와 직접적인 상관관계
```

#### 4.1.5. Combined Loss (권장)
```python
L_combined = 0.4×L_ce + 0.3×L_focal + 0.2×L_dice + 0.1×L_iou
설계 이유:
- CrossEntropy: 기본 분류 성능 확보
- Focal: 어려운 샘플 집중 학습
- Dice: 형태 보존 최적화
- IoU: 평가 지표와 손실의 정렬
```

### 4.2. 손실 함수별 성능 비교

| 손실 함수 | 설명 | 주요 효과 | 권장 상황 |
|-----------|------|-----------|-----------|
| **CrossEntropy** | 표준 다중클래스 분류 | 안정적 기본 성능 | 균형잡힌 데이터셋 |
| **Weighted CE** | 클래스 빈도 기반 가중치 | 소수 클래스 성능 향상 | 심한 클래스 불균형 |
| **Focal Loss** | 어려운 샘플 집중 | 경계 정확도 향상 | 작은 객체 다수 |
| **Dice Loss** | 형태 보존 최적화 | IoU 직접 최적화 | 의료영상, 정밀 분할 |
| **Combined** | 다중 손실 조합 | 종합적 성능 최적화 | **복잡한 실제 데이터** |

## 5. 실험 결과 분석

### 5.1. 성능 평가 지표

#### 5.1.1. 주요 지표 정의
- **Pixel Accuracy**: 전체 픽셀 중 올바르게 분류된 비율
- **Mean IoU (Intersection over Union)**: 교집합/합집합 비율의 클래스별 평균
- **Mean Dice**: 2×교집합/(예측+실제)의 클래스별 평균
- **Class-wise 성능**: 클래스별 세부 분석

#### 5.1.2. 배경 클래스 제외 평가의 중요성

축구 세그멘테이션에서는 **Foreground IoU**(배경 제외)가 더 중요한 지표입니다:

**배경 클래스의 특성**:
- 일반적으로 전체 픽셀의 대부분을 차지 (면적상 우세)
- 객체를 발견하지 못한 픽셀은 자동으로 배경으로 분류됨
- 배경 예측 자체는 상대적으로 쉬운 작업

**배경 포함 평가의 문제점**:
- 배경 클래스의 높은 정확도가 전체 성능을 인위적으로 상승시킴
- 실제 관심 객체의 분할 실패를 은폐하는 효과
- **배경과 실제 객체 성능 간 반비례 관계**: 객체 탐지 실패 → 배경 증가

**따라서 평가 기준**:
- **Foreground IoU**가 진정한 세그멘테이션 성능 지표
- **0.5 이상의 Foreground IoU**를 양호한 성능으로 평가
- 실제 관심 객체(선수, 공, 골대 등)의 분할 정확도가 핵심

### 5.2. 기본 데이터 실험 결과 (70/20/10 분할)

| 모델 | 손실함수 | Pixel Acc | Mean IoU (FG) | Mean Dice (FG) | 평가 |
|------|----------|-----------|---------------|----------------|------|
| **UNet300** | CrossEntropy | 85.9% | **0.583** | 0.638 | 양호 |
| **UNet300** | Weighted CE | 79.9% | 0.361 | 0.446 | 보통 |
| **UNet300** | Combined | 88.0% | **0.615** | 0.669 | 양호 |
| **UNet300** | Dice | 87.2% | **0.526** | 0.589 | 양호 |
| **ResNet34** | CrossEntropy | 86.6% | **0.590** | 0.644 | 양호 |
| **ResNet34** | Weighted CE | 80.1% | 0.425 | 0.512 | 보통 |
| **ResNet34** | Combined | 91.8% | **0.686** | 0.739 | **우수** |
| **ResNet34** | Dice | 89.2% | **0.614** | 0.667 | 양호 |
| **ResNet34 (freeze)** | CrossEntropy | 85.0% | **0.640** | 0.690 | 양호 |

- UNet300 (UNet Size 300) CrossEntropy

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_ce_ad.png" width="80%"/>

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_ce_ad_%EB%B6%84%ED%8F%AC.png" width="80%"/>

- ResNet34 Combined

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_resnet34_combined_01.png" width="80%"/>

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_resnet34_combined_%EB%B6%84%ED%8F%AC.png" width="80%"/>


### 5.3. 증강 데이터 실험 결과 (560/40/10 분할)

| 모델 | 손실함수 | Pixel Acc | Mean IoU (FG) | Mean Dice (FG) | 평가 |
|------|----------|-----------|---------------|----------------|------|
| **UNet300** | CrossEntropy | 89.2% | **0.614** | 0.667 | 양호 |
| **UNet300** | Weighted CE | 79.8% | 0.384 | 0.469 | 보통 |
| **UNet300** | Combined | 89.1% | **0.556** | 0.613 | 양호 |
| **UNet300** | Dice | 88.9% | **0.677** | 0.721 | 양호 |
| **ResNet34** | CrossEntropy | 89.2% | **0.619** | 0.671 | 양호 |
| **ResNet34** | Weighted CE | 90.6% | **0.759** | 0.820 | **우수** |
| **ResNet34** | Combined | 92.6% | **0.787** | 0.838 | **우수** |
| **ResNet34** | Dice | 92.3% | **0.739** | 0.778 | **우수** |
| **ResNet34 (freeze)** | CrossEntropy | 93.6% | **0.698** | 0.755 | 양호 |

- UNet300 (UNet Size 300) CrossEntropy

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_ce_ad.png" width="80%"/>

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_ce_ad_%EB%B6%84%ED%8F%AC.png" width="80%"/>

- ResNet34 Combined

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_combined_ad.png" width="80%"/>

  - <img src="https://c0z0c.github.io/sprint_mission/%EC%8A%A4%ED%94%84%EB%A6%B0%ED%8A%B8%EB%AF%B8%EC%85%98_%EC%99%84%EB%A3%8C/image/08_4%ED%8C%80_%EA%B9%80%EB%AA%85%ED%99%98/test_run_unet_train_improved_combined_ad_%EB%B6%84%ED%8F%AC.png" width="80%"/>


### 5.4. 주요 발견사항

#### 5.4.1. 모델 아키텍처 비교
1. **사전학습 ResNet34 백본이 커스텀 UNet300보다 우수한 성능**
   - ImageNet에서 학습된 강력한 특징 추출 능력
   - 전이학습의 효과로 적은 데이터로도 높은 성능
   
2. **인코더 고정 vs 파인튜닝**
   - 파인튜닝이 대부분 상황에서 더 좋은 결과
   - 단, 데이터가 적을 때는 고정이 과적합 방지에 도움

#### 5.4.2. 손실 함수 효과 분석
1. **Combined Loss가 가장 균형잡힌 성능**
   - 다양한 문제(불균형, 형태보존, 경계정확도)를 동시 해결
   - 특히 복잡한 축구 장면에서 효과적

2. **Weighted CrossEntropy의 제한성**
   - 클래스 불균형은 해결하지만 전체 성능 저하 경향
   - 과도한 가중치로 인한 학습 불안정성

3. **Dice Loss의 특화 효과**
   - 형태 보존에 뛰어난 성능
   - IoU 지표와의 높은 상관관계

#### 5.4.3. 데이터 증강의 영향
1. **증강 데이터의 긍정적 효과**
   - ResNet34 + 증강에서 최고 성능 달성 (Foreground IoU 0.787)
   - 작은 데이터셋의 한계 극복

2. **모델별 증강 민감도 차이**
   - 사전학습 모델이 증강에 더 잘 반응
   - 커스텀 모델은 증강 효과가 제한적

### 5.5. 클래스별 성능 분석

#### 5.5.1. 우수한 성능 클래스
- **Team A/B**: IoU 0.8+ 달성, 상대적으로 큰 크기와 뚜렷한 색상
- **Goalkeeper**: IoU 0.9+ 달성, 독특한 유니폼으로 구분 용이

#### 5.5.2. 도전적인 클래스
- **Ball**: 작은 크기에도 불구하고 IoU 0.6-0.8 달성 (개선됨)
- **Ground**: 조명과 그림자로 인한 분할 어려움
- **Audience**: 복잡한 배경과의 구분 문제
- **Referee**: 데이터 부족으로 인한 성능 한계

## 6. 기술적 혁신 요소

### 6.1. 아키텍처 최적화

#### 6.1.1. 해상도 불일치 해결
```python
# 크기 불일치 문제 해결
e4_resized = F.interpolate(e4, size=d4.shape[2:], 
                          mode='bilinear', align_corners=False)
d4 = torch.cat((d4, e4_resized), dim=1)
```

U-Net의 스킵 커넥션에서 발생하는 해상도 불일치를 bilinear interpolation으로 해결하여 정보 손실을 최소화했습니다.

#### 6.1.2. 배치 정규화(BatchNorm) 적용
모든 컨볼루션 레이어에 BatchNorm을 추가하여 학습 안정성과 수렴 속도를 향상시켰습니다.

### 6.2. 손실 함수 혁신

#### 6.2.1. 동적 클래스 가중치 계산
```python
def get_class_weights_from_data(dataset, num_classes):
    class_frequencies = class_counts / total_pixels
    class_weights = 1.0 / (class_frequencies + 1e-8)
    return class_weights / class_weights.mean()
```

데이터셋 분석을 통한 자동 가중치 계산으로 수동 튜닝의 필요성을 제거했습니다.

#### 6.2.2. 다중 손실 조합 전략
서로 다른 특성의 손실 함수를 최적 비율로 조합하여 종합적 성능을 향상시켰습니다.

### 6.3. 훈련 전략 최적화

#### 6.3.1. 차별적 학습률(Differential Learning Rate)
```python
optimizer = optim.Adam([
    {'params': encoder_params, 'lr': lr * 0.1},  # 낮은 학습률
    {'params': decoder_params, 'lr': lr}         # 기본 학습률
])
```

사전학습된 인코더는 낮은 학습률로, 새로운 디코더는 높은 학습률로 설정하여 효과적인 전이학습을 구현했습니다.

#### 6.3.2. 동적 학습률 스케줄링
```python
scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
```

검증 성능 기반으로 학습률을 자동 조정하여 최적 성능을 달성했습니다.

## 7. 성능 최적화 전략

### 7.1. 메모리 효율성
- GPU 메모리 사용량 최적화를 위한 배치 크기 조정
- 그래디언트 체크포인팅을 통한 메모리 절약
- 모델 저장 시 예측 결과 크기 제한 (상위 10개만 저장)

### 7.2. 추론 속도 개선
- 입력 해상도 300×300으로 통일하여 처리 속도 향상
- BatchNorm과 ReLU 최적화를 통한 연산 효율성 증대

### 7.3. 일반화 성능 향상
- 다양한 데이터 증강 기법 적용
- 앙상블 기법을 통한 성능 안정성 확보

## 8. 실무 적용 가능성

### 8.1. 실시간 경기 분석
- **선수 추적**: Team A/B 분할을 통한 실시간 선수 위치 추적
- **전술 분석**: Ground 영역 분석을 통한 포메이션 및 점유율 계산
- **하이라이트 생성**: Ball 추적을 통한 자동 하이라이트 영상 생성

### 8.2. 방송 기술 개선
- **가상 그래픽 삽입**: 정확한 Ground 분할을 통한 AR 효과
- **자동 카메라 워크**: 주요 객체 추적 기반 카메라 제어
- **실시간 통계**: 선수별 활동량, 점유 시간 등 자동 계산

### 8.3. 확장 가능성
- **다른 스포츠 적용**: 농구, 테니스 등 다른 스포츠로 전이학습
- **의료 영상**: U-Net 구조의 의료 영상 분할 적용
- **자율주행**: 도로, 차량, 보행자 분할 기술로 확장

## 9. 한계점 및 개선 방안

### 9.1. 현재 한계점

#### 9.1.1. 데이터 한계
- **소규모 데이터셋**: 100장의 제한된 훈련 데이터
- **단일 경기**: 하나의 경기에서만 추출한 데이터로 일반화 한계
- **조명 조건**: 특정 조명 조건에서만 테스트됨

#### 9.1.2. 클래스 불균형 미해결
- **Referee 클래스**: 24개 어노테이션으로 성능 한계
- **배경 클래스**: 대부분이 배경으로 분류되어 불균형 심화

#### 9.1.3. 실시간 처리 한계
- **추론 속도**: 현재 모델의 실시간 처리 능력 미검증
- **메모리 사용량**: 고해상도 영상 처리 시 메모리 부족 가능성

### 9.2. 개선 방안

#### 9.2.1. 데이터 확장
```python
데이터 수집 계획:
- 다양한 경기 영상 (최소 10경기 이상)
- 다양한 조명 조건 (주간/야간 경기)
- 다양한 카메라 앵글 (측면/상단/골대 뒷편)
- 다양한 날씨 조건 (맑음/비/눈)
```

#### 9.2.2. 모델 경량화
- **MobileNet 백본**: 실시간 처리를 위한 경량 모델 적용
- **지식 증류(Knowledge Distillation)**: 큰 모델의 성능을 작은 모델로 전이
- **양자화(Quantization)**: INT8 연산을 통한 추론 속도 향상

#### 9.2.3. 고급 기법 도입
- **Transformer 기반 세그멘테이션**: SegFormer, SETR 등 최신 아키텍처 적용
- **자가 학습(Self-supervised Learning)**: 레이블 없는 영상 데이터 활용
- **도메인 적응(Domain Adaptation)**: 다양한 경기장, 날씨 조건 적응

## 10. 결론

### 10.1. 주요 성과

본 연구를 통해 다음과 같은 기술적 성과를 달성했습니다:

1. **최고 성능**: ResNet34 + Combined Loss + 데이터 증강으로 **Foreground IoU 0.787** 달성
2. **실용성 검증**: 축구 경기 영상에서 실제 적용 가능한 수준의 정확도 확보
3. **기술 혁신**: 다중 손실 조합, 차별적 학습률 등 최적화 기법 개발
4. **포괄적 분석**: 8가지 모델-손실함수 조합의 체계적 비교 분석

### 10.2. 기술적 기여도

#### 10.2.1. 시맨틱 세그멘테이션 분야
- 축구 도메인에 특화된 손실 함수 조합 전략 제시
- 클래스 불균형 문제에 대한 종합적 해결 방안 제공
- 소규모 데이터셋에서의 효과적인 전이학습 전략 입증

#### 10.2.2. 스포츠 분석 분야  
- 실시간 축구 경기 분석을 위한 기술적 기반 마련
- 방송 기술과 스포츠 분석의 융합 가능성 제시
- 다른 스포츠로의 확장 가능성 입증

### 10.3. 최종 평가

본 연구는 축구 경기 영상의 시맨틱 세그멘테이션에서 **실용적인 수준의 성능**을 달성했습니다. 특히 사전학습된 ResNet34 백본과 Combined Loss의 조합이 가장 우수한 결과를 보였으며, 이는 실제 상용 서비스에 적용 가능한 수준입니다.

**주요 성취**:
- **정량적 성능**: Foreground IoU 0.787 (우수 등급)
- **정성적 품질**: 선수, 공, 골대 등 주요 객체의 정확한 분할
- **기술적 혁신**: 다중 손실 조합, 차별적 학습률 등 최적화 기법 개발
- **실무 적용성**: 방송 및 스포츠 분석 분야에서 즉시 활용 가능한 수준

**핵심 기술 기여**:
1. **축구 도메인 특화 최적화**: 클래스 불균형과 작은 객체 탐지 문제 해결
2. **효율적 전이학습**: 사전학습 모델을 활용한 소규모 데이터 학습 전략
3. **종합적 성능 평가**: 8가지 모델-손실함수 조합의 체계적 분석
4. **실용적 구현**: 실시간 처리를 고려한 아키텍처 설계

---

## 용어 목록

| 용어 | 정의 |
|------|------|
| **Semantic Segmentation** | 이미지의 각 픽셀을 의미론적 클래스로 분류하는 작업 |
| **U-Net** | 의료 영상 세그멘테이션을 위해 개발된 인코더-디코더 구조 |
| **Skip Connection** | 인코더와 디코더 간 직접 연결로 세부 정보 보존 |
| **IoU (Intersection over Union)** | 예측 영역과 실제 영역의 교집합/합집합 비율 |
| **Dice Score** | 두 영역의 겹침 정도를 측정하는 지표 |
| **Transfer Learning** | 사전학습된 모델을 새로운 도메인에 적용하는 기법 |
| **Data Augmentation** | 원본 데이터를 변형하여 학습 데이터를 확장하는 기법 |
| **Cross Entropy Loss** | 다중 클래스 분류를 위한 표준 손실 함수 |
| **Focal Loss** | 어려운 샘플에 집중하는 손실 함수 |
| **Batch Normalization** | 학습 안정성을 위한 정규화 기법 |
| **Fine-tuning** | 사전학습된 모델을 목표 작업에 맞게 조정하는 과정 |
| **Foreground Classes** | 배경을 제외한 실제 관심 객체 클래스들 |
| **Class Imbalance** | 클래스별 데이터 분포가 불균등한 상태 |
| **Pixel Accuracy** | 전체 픽셀 중 올바르게 분류된 픽셀의 비율 |
| **Mean IoU** | 모든 클래스에 대한 IoU의 평균값 |