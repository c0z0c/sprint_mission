{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewHNdIswgIrV"
   },
   "source": [
    "# ğŸ‰ Google Colab face_recognition ë¬¸ì œ ì™„ì „ í•´ê²°!\n",
    "\n",
    "## âœ… ë¬¸ì œ í•´ê²° ì™„ë£Œ\n",
    "\n",
    "**ì´ ë…¸íŠ¸ë¶ì€ Google Colabì—ì„œ ë°œìƒí•˜ëŠ” `face_recognition` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì˜¤ë¥˜ë¥¼ ì™„ì „íˆ í•´ê²°í–ˆìŠµë‹ˆë‹¤.**\n",
    "\n",
    "### âŒ ê¸°ì¡´ ë¬¸ì œ:\n",
    "```\n",
    "ERROR: Failed building wheel for dlib\n",
    "ModuleNotFoundError: No module named 'face_recognition'\n",
    "```\n",
    "\n",
    "### âœ… í•´ê²° ë°©ë²•:\n",
    "- `face_recognition` ë¼ì´ë¸ŒëŸ¬ë¦¬ **ì™„ì „ ì œê±°**\n",
    "- **OpenCV ê¸°ë°˜** ì–¼êµ´ ê°ì§€ ë° ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "- **ë” ê°•ë ¥í•œ íŠ¹ì§• ì¶”ì¶œ**: íˆìŠ¤í† ê·¸ë¨ + LBP + ê¸°í•˜í•™ì  + ì—ì§€ íŠ¹ì§•\n",
    "- **ë‹¤ì¤‘ ìœ ì‚¬ë„ ë©”íŠ¸ë¦­**: ì½”ì‚¬ì¸ + ìœ í´ë¦¬ë“œ + LPIPS\n",
    "\n",
    "### ğŸš€ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥\n",
    "ì´ì œ Google Colabì—ì„œ **ì„¤ì¹˜ ì˜¤ë¥˜ ì—†ì´** ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4dL9Ba0ZAxO"
   },
   "source": [
    "# ğŸ¨ AI ì´ë¯¸ì§€ ìƒì„± ë° ì–¼êµ´ ìœ ì‚¬ë„ ë¶„ì„ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ğŸ“‹ ëª©ì°¨\n",
    "1. [í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬](#1-í™˜ê²½-ì„¤ì •)\n",
    "2. [Stable Diffusion íŒŒì´í”„ë¼ì¸](#2-stable-diffusion-íŒŒì´í”„ë¼ì¸)\n",
    "3. [ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸°](#3-ì–¼êµ´-ìœ ì‚¬ë„-í‰ê°€ê¸°)\n",
    "4. [ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜](#4-ì´ë¯¸ì§€-ìƒì„±-í•¨ìˆ˜)\n",
    "5. [ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°](#5-ìŠ¤ë§ˆíŠ¸-í”„ë¡¬í”„íŠ¸-ìƒì„±ê¸°)\n",
    "6. [ìë™ ìœ ì‚¬ ì–¼êµ´ íƒìƒ‰](#6-ìë™-ìœ ì‚¬-ì–¼êµ´-íƒìƒ‰)\n",
    "7. [ì‹¤í–‰ ì˜ˆì œ](#7-ì‹¤í–‰-ì˜ˆì œ)\n",
    "\n",
    "## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥\n",
    "- **Stable Diffusion ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±**\n",
    "- **OpenCV + LPIPS ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€**\n",
    "- **ì¸êµ¬í†µê³„í•™ì  ì •ë³´ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±**\n",
    "- **ìë™ ìœ ì‚¬ ì–¼êµ´ íƒìƒ‰ ë° í•„í„°ë§**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6690,
     "status": "ok",
     "timestamp": 1757068991753,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "x7_IBeByZAxP",
    "outputId": "c455761b-01bf-47ba-f21d-519d819a13b0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 1. Google Colab í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ (face_recognition ë¬¸ì œ í•´ê²°)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Google Colab í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ (face_recognition ë¬¸ì œ í•´ê²°)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Colab í™˜ê²½ í™•ì¸\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒŸ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "    # Colabì—ì„œ Google Drive ë§ˆìš´íŠ¸\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # LPIPS ì„¤ì¹˜ (Colabì—ì„œ í•„ìš”)\n",
    "    print(\"ğŸ“¦ LPIPS ì„¤ì¹˜ ì¤‘...\")\n",
    "    !pip install -q lpips\n",
    "\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸš€ ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì‹œë“œ ì„¤ì •\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# OpenCVë§Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“œ (face_recognition ëŒ€ì‹ )\n",
    "USE_OPENCV_ONLY = True\n",
    "print(f\"ğŸ”§ OpenCV ì „ìš© ëª¨ë“œ: {USE_OPENCV_ONLY}\")\n",
    "\n",
    "print(\"âœ… ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì • ì™„ë£Œ (face_recognition ì œì™¸)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "99752028c0cf497d9540c51a55852cbc",
      "bb071adc9054464b951716ff6b68fd44",
      "96359f7dabaf47f5aa5ea6391db64133",
      "69a0b86664244c4f9ec1b8ba1c66dd2a",
      "9258181299a348bd9a1fe7ca0687a0ab",
      "40b8af3da4e84acf8ae9db69c8b7e34f",
      "0a1fbfb73b124332873f36584d894da6",
      "0bd0dfd9b7804e61be99e2e43a8e4f21",
      "bb25a9991f59443e87dd0dbfcfac06e2",
      "d5728f8f34f24fd683a347068191f787",
      "cd074d0a8cbd44d3ba698ff83f6d8dea"
     ]
    },
    "executionInfo": {
     "elapsed": 12948,
     "status": "ok",
     "timestamp": 1757069004706,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "0GIOfdFKZAxQ",
    "outputId": "24e2a407-062f-47b2-ad25-2ccebf7df348"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (Colab ìµœì í™”)\n",
    "# =============================================================================\n",
    "\n",
    "# Colabì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ Colabìš© íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
    "    !pip install -q diffusers transformers accelerate\n",
    "    !pip install -q xformers  # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    import lpips\n",
    "\n",
    "    print(\"ğŸ”„ Stable Diffusion ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    print(\"â° ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ 3-5ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...\")\n",
    "\n",
    "    # Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        safety_checker=None,\n",
    "        requires_safety_checker=False\n",
    "    )\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "    # Colab ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •\n",
    "    if device.type == \"cuda\":\n",
    "        pipe.enable_attention_slicing()\n",
    "        if IN_COLAB:\n",
    "            pipe.enable_model_cpu_offload()  # Colabì—ì„œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "            pipe.enable_xformers_memory_efficient_attention()  # xformers ì‚¬ìš©\n",
    "\n",
    "    # LPIPS ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    print(\"âœ… Stable Diffusion íŒŒì´í”„ë¼ì¸ ë° LPIPS ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1757069004744,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "taqPJn3dZAxQ",
    "outputId": "36bdf0da-05b9-4a61-f5cb-63e14773b54b"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. OpenCV ì „ìš© ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸° (face_recognition ì—†ì´)\n",
    "# =============================================================================\n",
    "\n",
    "class FaceSimilarityEvaluator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV ì „ìš© ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸° (Colab í˜¸í™˜)\"\"\"\n",
    "        print(f\"ğŸ¯ OpenCV ì „ìš© í‰ê°€ê¸° ì´ˆê¸°í™”: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™”\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "        # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            if self.reference_image is None:\n",
    "                print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {reference_image_path}\")\n",
    "                self.reference_features = None\n",
    "                return\n",
    "\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "            self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "            if self.reference_features is not None:\n",
    "                print(\"âœ… ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ ì„±ê³µ\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        else:\n",
    "            print(f\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}\")\n",
    "            self.reference_features = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"OpenCVë¥¼ ì‚¬ìš©í•œ ê°•í™”ëœ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ë¡œ ì–¼êµ´ ê°ì§€\n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ\n",
    "            largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "            x, y, w, h = largest_face\n",
    "\n",
    "            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ ë° ì •ê·œí™”\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "\n",
    "            # íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”ë¡œ ì¡°ëª… ì •ê·œí™”\n",
    "            face_normalized = cv2.equalizeHist(face_resized)\n",
    "\n",
    "            # 1. íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•\n",
    "            hist_features = cv2.calcHist([face_normalized], [0], None, [256], [0, 256]).flatten()\n",
    "            hist_features = hist_features / (hist_features.sum() + 1e-7)\n",
    "\n",
    "            # 2. LBP (Local Binary Pattern) íŠ¹ì§•\n",
    "            lbp_features = self.calculate_lbp(face_normalized)\n",
    "\n",
    "            # 3. ëˆˆ ê°ì§€ íŠ¹ì§• (ì–¼êµ´ êµ¬ì¡° ë¶„ì„)\n",
    "            eyes = self.eye_cascade.detectMultiScale(face_roi)\n",
    "            eye_features = np.array([len(eyes),\n",
    "                                   eyes[0][2]*eyes[0][3] if len(eyes) > 0 else 0])  # ëˆˆ ê°œìˆ˜ì™€ í¬ê¸°\n",
    "\n",
    "            # 4. ê¸°í•˜í•™ì  íŠ¹ì§• (ì–¼êµ´ ë¹„ìœ¨)\n",
    "            geometric_features = np.array([w/h, w, h])  # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ê³¼ í¬ê¸°\n",
    "\n",
    "            # 5. ì—ì§€ íŠ¹ì§•\n",
    "            edges = cv2.Canny(face_normalized, 50, 150)\n",
    "            edge_features = np.array([np.sum(edges > 0) / (128*128)])  # ì—ì§€ ë°€ë„\n",
    "\n",
    "            # ëª¨ë“  íŠ¹ì§• ê²°í•©\n",
    "            combined_features = np.concatenate([\n",
    "                hist_features,      # íˆìŠ¤í† ê·¸ë¨ (256ê°œ)\n",
    "                lbp_features,       # LBP (26ê°œ)\n",
    "                eye_features,       # ëˆˆ íŠ¹ì§• (2ê°œ)\n",
    "                geometric_features, # ê¸°í•˜í•™ì  íŠ¹ì§• (3ê°œ)\n",
    "                edge_features      # ì—ì§€ íŠ¹ì§• (1ê°œ)\n",
    "            ])\n",
    "\n",
    "            return combined_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_lbp(self, image, radius=3, n_points=24):\n",
    "        \"\"\"Local Binary Pattern ê³„ì‚° (scikit-image ì—†ì´)\"\"\"\n",
    "        try:\n",
    "            # ê°„ë‹¨í•œ LBP êµ¬í˜„\n",
    "            h, w = image.shape\n",
    "            lbp = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "            for i in range(radius, h - radius):\n",
    "                for j in range(radius, w - radius):\n",
    "                    center = image[i, j]\n",
    "                    binary_string = ''\n",
    "\n",
    "                    # 8ë°©í–¥ ê²€ì‚¬ (ê°„ë‹¨í™”)\n",
    "                    neighbors = [\n",
    "                        image[i-1, j-1], image[i-1, j], image[i-1, j+1],\n",
    "                        image[i, j+1], image[i+1, j+1], image[i+1, j],\n",
    "                        image[i+1, j-1], image[i, j-1]\n",
    "                    ]\n",
    "\n",
    "                    for neighbor in neighbors:\n",
    "                        binary_string += '1' if neighbor >= center else '0'\n",
    "\n",
    "                    lbp[i, j] = int(binary_string, 2)\n",
    "\n",
    "            # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 26))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            return hist\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"LBP ê³„ì‚° ì˜¤ë¥˜: {e}\")\n",
    "            # ëŒ€ì•ˆ: ê°„ë‹¨í•œ í…ìŠ¤ì²˜ íŠ¹ì§•\n",
    "            return np.histogram(image.ravel(), bins=26)[0].astype(\"float\")\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ìœ ì‚¬ë„ í‰ê°€\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 1. OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "                cosine_sim = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                face_similarity = max(0, cosine_sim)\n",
    "                scores['face_similarity'] = face_similarity\n",
    "\n",
    "                # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„\n",
    "                euclidean_dist = np.linalg.norm(self.reference_features - generated_features)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist / 1000)  # ì •ê·œí™”\n",
    "                scores['euclidean_similarity'] = euclidean_sim\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "                scores['euclidean_similarity'] = 0.0\n",
    "\n",
    "            # 2. LPIPS ì ìˆ˜ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "            if 'lpips_model' in globals():\n",
    "                try:\n",
    "                    ref_tensor = transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(device)\n",
    "                    gen_tensor = transform(generated_image).unsqueeze(0).to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS ê³„ì‚° ì˜¤ë¥˜: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 3. ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )\n",
    "            face_weight = 0.5\n",
    "            euclidean_weight = 0.3\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['euclidean_similarity'] * euclidean_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"í‰ê°€ ì˜¤ë¥˜: {e}\")\n",
    "            scores = {\n",
    "                'face_similarity': 0.0,\n",
    "                'euclidean_similarity': 0.0,\n",
    "                'lpips_similarity': 0.0,\n",
    "                'total_score': 0.0\n",
    "            }\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"âœ… OpenCV ì „ìš© FaceSimilarityEvaluator í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757069004763,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "nao847V0ZAxQ",
    "outputId": "7b93a592-d9a5-4407-8f34-f0b1d9d97b69"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "def generate_image(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                  num_inference_steps=30, guidance_scale=7.5,\n",
    "                  save_path=None, show_image=True):\n",
    "    \"\"\"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    if negative_prompt is None:\n",
    "        negative_prompt = \"blurry, low quality, bad anatomy, deformed, extra limbs, bad hands, cartoon, anime\"\n",
    "\n",
    "    generator = torch.Generator(device=pipe.device).manual_seed(seed)\n",
    "\n",
    "    print(f\"ì´ë¯¸ì§€ ìƒì„± ì¤‘... (ì‹œë“œ: {seed})\")\n",
    "    print(f\"í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "\n",
    "    try:\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "\n",
    "        if save_path:\n",
    "            image.save(save_path)\n",
    "            print(f\"ì´ë¯¸ì§€ ì €ì¥ë¨: {save_path}\")\n",
    "\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Generated (Seed: {seed})\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… generate_image í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1757069004776,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "-SEYqFAUZAxR",
    "outputId": "33fad6ba-4977-4b5d-fe4a-d8c30414f5bb"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°\n",
    "# =============================================================================\n",
    "\n",
    "def generate_demographic_prompts(age_group=\"20ëŒ€\", gender=\"ì—¬ì„±\", ethnicity=\"ì•„ì‹œì•ˆ\"):\n",
    "    \"\"\"ë‚˜ì´, ì„±ë³„, ì¸ì¢… ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "\n",
    "    age_keywords = {\n",
    "        \"10ëŒ€\": [\"young teenager\", \"youthful\", \"teenage\"],\n",
    "        \"20ëŒ€\": [\"young adult\", \"early twenties\", \"youthful adult\"],\n",
    "        \"30ëŒ€\": [\"adult\", \"mature young adult\", \"thirty-something\"],\n",
    "        \"40ëŒ€\": [\"middle-aged adult\", \"mature\", \"experienced adult\"],\n",
    "        \"50ëŒ€\": [\"mature adult\", \"middle-aged\", \"distinguished\"]\n",
    "    }\n",
    "\n",
    "    gender_keywords = {\n",
    "        \"ë‚¨ì„±\": [\"man\", \"male\", \"gentleman\"],\n",
    "        \"ì—¬ì„±\": [\"woman\", \"female\", \"lady\"]\n",
    "    }\n",
    "\n",
    "    ethnicity_keywords = {\n",
    "        \"ì•„ì‹œì•ˆ\": [\"Asian\", \"East Asian\", \"Korean\"],\n",
    "        \"ë°±ì¸\": [\"Caucasian\", \"white\", \"European\"],\n",
    "        \"í‘ì¸\": [\"African American\", \"black\", \"African\"],\n",
    "        \"íˆìŠ¤íŒ¨ë‹‰\": [\"Hispanic\", \"Latino\", \"Latin American\"]\n",
    "    }\n",
    "\n",
    "    lighting_styles = [\n",
    "        \"natural lighting, bright and cheerful\",\n",
    "        \"soft studio lighting, clean background\",\n",
    "        \"golden hour lighting, warm and inviting\"\n",
    "    ]\n",
    "\n",
    "    quality_keywords = [\n",
    "        \"high quality, detailed, photorealistic\",\n",
    "        \"professional photography, sharp focus\",\n",
    "        \"realistic lighting, natural expression\"\n",
    "    ]\n",
    "\n",
    "    enhanced_prompts = []\n",
    "\n",
    "    age_terms = age_keywords.get(age_group, [\"young adult\"])\n",
    "    gender_terms = gender_keywords.get(gender, [\"person\"])\n",
    "    ethnic_terms = ethnicity_keywords.get(ethnicity, [\"\"])\n",
    "\n",
    "    for age_term in age_terms[:2]:\n",
    "        for gender_term in gender_terms[:2]:\n",
    "            for ethnic_term in ethnic_terms[:2]:\n",
    "                for lighting in lighting_styles:\n",
    "                    for quality in quality_keywords:\n",
    "                        if ethnic_term:\n",
    "                            prompt = f\"professional portrait of a {age_term} {ethnic_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        else:\n",
    "                            prompt = f\"professional portrait of a {age_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        enhanced_prompts.append(prompt)\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° ë° ì…”í”Œ\n",
    "    enhanced_prompts = list(set(enhanced_prompts))\n",
    "    random.shuffle(enhanced_prompts)\n",
    "\n",
    "    return enhanced_prompts[:10]\n",
    "\n",
    "print(\"âœ… generate_demographic_prompts í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757069004792,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "cfzlGTFaZAxR",
    "outputId": "3e53864f-b0ee-4ffd-dcda-788a6456c66e"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. ìë™ ìœ ì‚¬ ì–¼êµ´ íƒìƒ‰ í•¨ìˆ˜ (ìµœì¢… í†µí•© ë²„ì „)\n",
    "# =============================================================================\n",
    "\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6,\n",
    "                                   max_attempts=50, target_count=3,\n",
    "                                   age_group=\"20ëŒ€\", gender=\"ì—¬ì„±\", ethnicity=\"ì•„ì‹œì•ˆ\"):\n",
    "    \"\"\"OpenCV ê¸°ë°˜ ìë™ ì–¼êµ´ ìœ ì‚¬ë„ íƒìƒ‰\"\"\"\n",
    "\n",
    "    print(\"ğŸ”„ ìë™ ìœ ì‚¬ë„ íƒìƒ‰ ì‹œì‘...\")\n",
    "    print(f\"ğŸ¯ ê²€ìƒ‰ ì¡°ê±´: {age_group} {gender} {ethnicity}\")\n",
    "\n",
    "    # í‰ê°€ê¸° ì´ˆê¸°í™”\n",
    "    try:\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        if evaluator.reference_features is None:\n",
    "            print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í‰ê°€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "    # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    enhanced_prompts = generate_demographic_prompts(age_group, gender, ethnicity)\n",
    "\n",
    "    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì¶”ê°€\n",
    "    basic_prompts = [\n",
    "        \"professional portrait, high quality, detailed\",\n",
    "        \"natural lighting portrait, realistic\",\n",
    "        \"studio portrait, professional photography\"\n",
    "    ]\n",
    "\n",
    "    all_prompts = enhanced_prompts + basic_prompts\n",
    "    print(f\"ğŸ¨ ì´ {len(all_prompts)}ê°œì˜ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "    successful_images = []\n",
    "    attempts = 0\n",
    "    prompt_idx = 0\n",
    "\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces\"\n",
    "\n",
    "    print(f\"ğŸ¯ ëª©í‘œ: {target_count}ê°œì˜ ìœ ì‚¬í•œ ì–¼êµ´ ì°¾ê¸° (ìœ ì‚¬ë„ >= {target_score})\")\n",
    "\n",
    "    while len(successful_images) < target_count and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        current_prompt = all_prompts[prompt_idx % len(all_prompts)]\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\nğŸ”„ ì‹œë„ {attempts}/{max_attempts}\")\n",
    "        print(f\"ğŸ“ í”„ë¡¬í”„íŠ¸: {current_prompt}\")\n",
    "\n",
    "        try:\n",
    "            # ì´ë¯¸ì§€ ìƒì„±\n",
    "            generated_image = generate_image(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                prompt_idx += 1\n",
    "                continue\n",
    "\n",
    "            # ìœ ì‚¬ë„ í‰ê°€\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "\n",
    "            print(f\"ğŸ“Š í‰ê°€ ê²°ê³¼:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "            # ëª©í‘œ ì ìˆ˜ ë‹¬ì„± ì‹œ ì €ì¥\n",
    "            if scores['total_score'] >= target_score:\n",
    "                save_path = f\"similar_face_{len(successful_images)+1:02d}_score_{scores['total_score']:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                successful_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path,\n",
    "                    'demographics': f\"{age_group}_{gender}_{ethnicity}\"\n",
    "                })\n",
    "\n",
    "                print(f\"âœ… ì„±ê³µ! ({len(successful_images)}/{target_count})\")\n",
    "\n",
    "                # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(successful_images)} (Score: {scores['total_score']:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"âŒ ëª©í‘œ ì ìˆ˜ ë¯¸ë‹¬ (í˜„ì¬: {scores['total_score']:.4f}, ëª©í‘œ: {target_score})\")\n",
    "\n",
    "            prompt_idx += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "            prompt_idx += 1\n",
    "\n",
    "    print(f\"\\nğŸ¯ íƒìƒ‰ ì™„ë£Œ: {len(successful_images)}ê°œì˜ ì„±ê³µì ì¸ ì´ë¯¸ì§€ ìƒì„±\")\n",
    "\n",
    "    # ê²°ê³¼ ì •ë ¬ (ì´ ì ìˆ˜ ê¸°ì¤€)\n",
    "    successful_images.sort(key=lambda x: x['scores']['total_score'], reverse=True)\n",
    "    return successful_images\n",
    "\n",
    "print(\"âœ… find_similar_faces_auto_enhanced í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1757069005248,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "VdZFm0hdZAxR",
    "outputId": "efe94bee-05f4-46ab-e6cf-5e7fd0aa7cb4"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. Colab í™˜ê²½ ì„¤ì • ë° ì‹¤í–‰ ì˜ˆì œ\n",
    "# =============================================================================\n",
    "\n",
    "# í™˜ê²½ë³„ íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "if IN_COLAB:\n",
    "    # Colab í™˜ê²½: Google Drive ê²½ë¡œ\n",
    "    reference_photo = \"/content/drive/MyDrive/homepage/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜_ì‘ì—…ì¤‘/test.png\"\n",
    "    print(\"ğŸŒŸ Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰\")\n",
    "    print(\"ğŸ“ Google Driveì—ì„œ íŒŒì¼ ë¡œë“œ\")\n",
    "else:\n",
    "    # ë¡œì»¬ í™˜ê²½\n",
    "    reference_photo = \"test.png\"\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰\")\n",
    "\n",
    "print(f\"ğŸ“· ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ: {reference_photo}\")\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ì°¸ì¡° ì´ë¯¸ì§€ í‘œì‹œ\n",
    "if os.path.exists(reference_photo):\n",
    "    print(\"âœ… ì°¸ì¡° ì´ë¯¸ì§€ í™•ì¸ë¨\")\n",
    "\n",
    "    try:\n",
    "        # ì°¸ì¡° ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°\n",
    "        ref_img = Image.open(reference_photo)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(ref_img)\n",
    "        plt.title(\"ğŸ“· ì°¸ì¡° ì´ë¯¸ì§€\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {ref_img.size}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    if IN_COLAB:\n",
    "        print(\"ğŸ’¡ Google Driveê°€ ë§ˆìš´íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        print(\"ğŸ’¡ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:\")\n",
    "        print(\"   /content/drive/MyDrive/homepage/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜_ì‘ì—…ì¤‘/test.png\")\n",
    "\n",
    "        # Google Drive ë‚´ìš© í™•ì¸\n",
    "        drive_path = \"/content/drive/MyDrive\"\n",
    "        if os.path.exists(drive_path):\n",
    "            print(f\"\\nğŸ“‚ Google Drive ë£¨íŠ¸ í´ë” ë‚´ìš©:\")\n",
    "            for item in os.listdir(drive_path)[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ\n",
    "                print(f\"   ğŸ“ {item}\")\n",
    "    else:\n",
    "        print(\"ğŸ“‚ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ì´ë¯¸ì§€ íŒŒì¼:\")\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                print(f\"   ğŸ“ {file}\")\n",
    "\n",
    "print(\"\\nğŸš€ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ’¡ ë‹¤ìŒ ì…€ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899,
     "referenced_widgets": [
      "cee7cecaeb5248779aeb5bbae068d605",
      "92b416e643294aa9835e8b841ea42cfd",
      "ad9c37d16de04dab8ced57639bf4c58f",
      "5738ff9c88d04c79a193a5e63a89927d",
      "11c3bec2af7a492f9e659cb644fe6e4e",
      "152011fa31a344e985e8b4ebe6c0070b",
      "795836e6dff14890aa75c7c6db2d8318",
      "55b06d29e4e94b8da5beb45c6056dac8",
      "99b724cf124e4a739106bf0f5d2ac665",
      "b44ec25194b54084b90283695fa10a5f",
      "fb1ebbd7fec24bed86805105f33babc1"
     ]
    },
    "executionInfo": {
     "elapsed": 3667,
     "status": "ok",
     "timestamp": 1757069008918,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "pL-RpQ_IZAxR",
    "outputId": "494fd9ac-97ba-4948-ab6e-91925c5bcd9b"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. Colab ì•ˆì „ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# =============================================================================\n",
    "\n",
    "# ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if os.path.exists(reference_photo):\n",
    "    print(\"ğŸ§ª Colab í™˜ê²½ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "\n",
    "    try:\n",
    "        # 1. ê°„ë‹¨í•œ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "        print(\"ğŸ¨ 1ë‹¨ê³„: ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
    "        test_prompt = \"professional portrait of a young Asian woman, natural lighting, high quality, photorealistic\"\n",
    "\n",
    "        test_image = generate_image(\n",
    "            pipe=pipe,\n",
    "            prompt=test_prompt,\n",
    "            seed=12345,\n",
    "            num_inference_steps=20,  # Colabì—ì„œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¶•ì†Œ\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if test_image:\n",
    "            print(\"âœ… ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ!\")\n",
    "\n",
    "            # 2. ìœ ì‚¬ë„ í‰ê°€ í…ŒìŠ¤íŠ¸\n",
    "            print(\"\\nğŸ“Š 2ë‹¨ê³„: ìœ ì‚¬ë„ í‰ê°€ í…ŒìŠ¤íŠ¸\")\n",
    "            evaluator = FaceSimilarityEvaluator(reference_photo)\n",
    "\n",
    "            if evaluator.reference_features is not None:\n",
    "                scores = evaluator.evaluate_similarity(test_image)\n",
    "                print(f\"\udcc8 ìœ ì‚¬ë„ í‰ê°€ ê²°ê³¼:\")\n",
    "                for key, value in scores.items():\n",
    "                    print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "                # ì„±ê³µ ê¸°ì¤€ í™•ì¸\n",
    "                if scores['total_score'] > 0.3:\n",
    "                    print(\"âœ… ìœ ì‚¬ë„ í‰ê°€ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™!\")\n",
    "                else:\n",
    "                    print(\"âš ï¸ ìœ ì‚¬ë„ê°€ ë‚®ì§€ë§Œ ì‹œìŠ¤í…œì€ ì •ìƒ ì‘ë™ ì¤‘\")\n",
    "\n",
    "            else:\n",
    "                print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨\")\n",
    "\n",
    "        else:\n",
    "            print(\"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}\")\n",
    "        print(\"ğŸ’¡ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•´ë³´ì„¸ìš”.\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ Google Driveì— test.png íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ’¡ ì „ì²´ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ì…€ì˜ find_similar_faces_auto_enhanced() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IKYMDw4ZAxS"
   },
   "source": [
    "## ğŸ“š Google Colab ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "### \udf1f Colab í™˜ê²½ ìµœì í™”\n",
    "\n",
    "**ì´ ë…¸íŠ¸ë¶ì€ Google Colabì—ì„œ `face_recognition` ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ OpenCV ì „ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.**\n",
    "\n",
    "### ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­\n",
    "\n",
    "1. **face_recognition ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°**: dlib ì»´íŒŒì¼ ì˜¤ë¥˜ í•´ê²°\n",
    "2. **OpenCV ì „ìš© ì–¼êµ´ ê°ì§€**: Haar Cascade + ê°•í™”ëœ íŠ¹ì§• ì¶”ì¶œ\n",
    "3. **Colab ë©”ëª¨ë¦¬ ìµœì í™”**: CPU offload + attention slicing\n",
    "4. **ìë™ í™˜ê²½ ê°ì§€**: Colabê³¼ ë¡œì»¬ í™˜ê²½ ìë™ êµ¬ë¶„\n",
    "\n",
    "### ğŸš€ ì‹¤í–‰ ìˆœì„œ\n",
    "\n",
    "1. **ì…€ 1**: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "2. **ì…€ 2**: Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ì²« ì‹¤í–‰ ì‹œ 3-5ë¶„ ì†Œìš”)\n",
    "3. **ì…€ 3**: OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸°\n",
    "4. **ì…€ 4-6**: ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "5. **ì…€ 7**: ì°¸ì¡° ì´ë¯¸ì§€ í™•ì¸\n",
    "6. **ì…€ 8**: í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "\n",
    "### ğŸ“ íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "\n",
    "```python\n",
    "# Google Driveì— íŒŒì¼ ì—…ë¡œë“œ ê²½ë¡œ:\n",
    "# /content/drive/MyDrive/homepage/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜_ì‘ì—…ì¤‘/test.png\n",
    "\n",
    "# ë˜ëŠ” Colabì— ì§ì ‘ ì—…ë¡œë“œ:\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # test.png ì—…ë¡œë“œ\n",
    "reference_photo = \"test.png\"\n",
    "```\n",
    "\n",
    "### âš™ï¸ ë§¤ê°œë³€ìˆ˜ ê¶Œì¥ê°’ (Colab ìµœì í™”)\n",
    "\n",
    "- **`num_inference_steps`**: 20-30 (ë¹ ë¥¸ ìƒì„±)\n",
    "- **`target_score`**: 0.4-0.6 (OpenCV íŠ¹ì„±ìƒ ë‚®ê²Œ ì„¤ì •)\n",
    "- **`max_attempts`**: 20-30 (Colab ì‹œê°„ ì œí•œ)\n",
    "- **`target_count`**: 3-5ê°œ\n",
    "\n",
    "### ğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” íŒ\n",
    "\n",
    "```python\n",
    "# GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ:\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì¬ì´ˆê¸°í™”\n",
    "pipe.enable_model_cpu_offload()\n",
    "```\n",
    "\n",
    "### ğŸš¨ Colab ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "1. **ëŸ°íƒ€ì„ ì—°ê²° ëŠê¹€**: ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ì—°ê²°ì´ ëŠê¸¸ ìˆ˜ ìˆìŒ\n",
    "2. **GPU ì‚¬ìš©ëŸ‰ ì œí•œ**: ë¬´ë£Œ ê³„ì •ì€ GPU ì‚¬ìš©ëŸ‰ ì œí•œ ìˆìŒ\n",
    "3. **íŒŒì¼ ì €ì¥**: ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” Google Driveì— ìë™ ì €ì¥\n",
    "4. **ë©”ëª¨ë¦¬ ì œí•œ**: ë³µì¡í•œ ì‘ì—… ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ ê°€ëŠ¥\n",
    "\n",
    "### ğŸ’¡ ë¬¸ì œ í•´ê²°\n",
    "\n",
    "**\"CUDA out of memory\" ì˜¤ë¥˜ ì‹œ:**\n",
    "```python\n",
    "# 1. ëŸ°íƒ€ì„ ì¬ì‹œì‘: ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ì¬ì‹œì‘\n",
    "# 2. ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹¤í–‰\n",
    "# 3. inference_steps ì¤„ì´ê¸° (20ìœ¼ë¡œ ì„¤ì •)\n",
    "```\n",
    "\n",
    "**ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ:**\n",
    "```python\n",
    "# Google Drive ë§ˆìš´íŠ¸ í™•ì¸\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
    "import os\n",
    "print(os.listdir('/content/drive/MyDrive'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1757069008962,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "8--M503d9RjR",
    "outputId": "f9eb7418-1b99-4ae4-9e0c-9e66c9330569"
   },
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° ì°¸ì¡° ì´ë¯¸ì§€ í™•ì¸\n",
    "test_image_path = \"test.png\"\n",
    "\n",
    "print(\"ğŸ§ª OpenCV ê¸°ë°˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸...\")\n",
    "\n",
    "# ì°¸ì¡° ì´ë¯¸ì§€ ì¡´ì¬ í™•ì¸\n",
    "if os.path.exists(test_image_path):\n",
    "    print(f\"âœ… ì°¸ì¡° ì´ë¯¸ì§€ ë°œê²¬: {test_image_path}\")\n",
    "\n",
    "    # OpenCV ê¸°ë°˜ í‰ê°€ê¸° í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        evaluator = FaceSimilarityEvaluator(test_image_path)\n",
    "        print(\"âœ… OpenCV ê¸°ë°˜ ì–¼êµ´ í‰ê°€ê¸° ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "\n",
    "        # ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸\n",
    "        if evaluator.reference_features is not None:\n",
    "            test_image = Image.open(test_image_path)\n",
    "            scores = evaluator.evaluate_similarity(test_image)\n",
    "            print(f\"ğŸ” ìê¸° ì°¸ì¡° í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í‰ê°€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {test_image_path}\")\n",
    "    print(\"í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤:\")\n",
    "    for file in os.listdir(\".\"):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  ğŸ“ {file}\")\n",
    "\n",
    "print(\"ğŸ”§ ì‹œìŠ¤í…œì´ face_recognition ì—†ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1757069008981,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "AUnSsXwV9RjR",
    "outputId": "2341c853-81f5-4124-c9ad-89b9b8415c54"
   },
   "outputs": [],
   "source": [
    "# face_recognition ì—†ì´ ì‘ë™í•˜ëŠ” SmartPromptGenerator\n",
    "class SmartPromptGenerator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°\"\"\"\n",
    "        print(f\"ğŸ¨ OpenCV ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image_path = reference_image_path\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "            self.features = self.analyze_features()\n",
    "        else:\n",
    "            print(f\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}\")\n",
    "            self.features = {}\n",
    "\n",
    "    def analyze_features(self):\n",
    "        \"\"\"OpenCVë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ì ì¸ ì–¼êµ´ íŠ¹ì§• ë¶„ì„\"\"\"\n",
    "        features = {}\n",
    "\n",
    "        try:\n",
    "            # ì–¼êµ´ ê°ì§€\n",
    "            gray = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ\n",
    "                x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "\n",
    "                # ê¸°ë³¸ íŠ¹ì§•ë“¤\n",
    "                features.update({\n",
    "                    'face_detected': True,\n",
    "                    'face_size': 'large' if w * h > 10000 else 'medium' if w * h > 5000 else 'small',\n",
    "                    'face_ratio': w / h,\n",
    "                })\n",
    "\n",
    "                # ì´ë¯¸ì§€ ë°ê¸° ë¶„ì„\n",
    "                brightness = np.mean(gray[y:y+h, x:x+w])\n",
    "                features['brightness'] = 'bright' if brightness > 150 else 'dark' if brightness < 100 else 'normal'\n",
    "\n",
    "                # ìƒ‰ìƒ ë¶„ì„ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "                face_roi = self.reference_image_rgb[y:y+h, x:x+w]\n",
    "                avg_color = np.mean(face_roi, axis=(0, 1))\n",
    "                features['skin_tone'] = 'warm' if avg_color[0] > avg_color[2] else 'cool'\n",
    "\n",
    "            else:\n",
    "                features['face_detected'] = False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"íŠ¹ì§• ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "            features['face_detected'] = False\n",
    "\n",
    "        return features\n",
    "\n",
    "    def generate_smart_prompts(self, count=10):\n",
    "        \"\"\"ë¶„ì„ëœ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "\n",
    "        base_prompts = [\n",
    "            \"a professional portrait photo of a person\",\n",
    "            \"a high-quality headshot of a person\",\n",
    "            \"a realistic portrait of a person\",\n",
    "            \"a detailed face portrait of a person\",\n",
    "            \"a studio portrait of a person\",\n",
    "            \"a professional photograph of a person\",\n",
    "            \"a clear portrait photo of a person\",\n",
    "            \"a high-resolution portrait of a person\",\n",
    "            \"a realistic headshot of a person\",\n",
    "            \"a professional studio portrait of a person\"\n",
    "        ]\n",
    "\n",
    "        # íŠ¹ì§• ê¸°ë°˜ ìˆ˜ì •ìë“¤\n",
    "        modifiers = []\n",
    "\n",
    "        if self.features.get('face_detected', False):\n",
    "            if self.features.get('brightness') == 'bright':\n",
    "                modifiers.append(\"well-lit\")\n",
    "            elif self.features.get('brightness') == 'dark':\n",
    "                modifiers.append(\"dramatic lighting\")\n",
    "\n",
    "            if self.features.get('skin_tone') == 'warm':\n",
    "                modifiers.append(\"warm tones\")\n",
    "            elif self.features.get('skin_tone') == 'cool':\n",
    "                modifiers.append(\"cool tones\")\n",
    "\n",
    "        # í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ\n",
    "        quality_keywords = [\n",
    "            \"high quality\", \"detailed\", \"sharp focus\", \"professional\",\n",
    "            \"photorealistic\", \"8k resolution\", \"studio lighting\"\n",
    "        ]\n",
    "\n",
    "        smart_prompts = []\n",
    "        for i, base in enumerate(base_prompts[:count]):\n",
    "            prompt = base\n",
    "\n",
    "            # ìˆ˜ì •ì ì¶”ê°€\n",
    "            if modifiers and i % 3 == 0:\n",
    "                prompt += f\", {', '.join(modifiers[:2])}\"\n",
    "\n",
    "            # í’ˆì§ˆ í‚¤ì›Œë“œ ì¶”ê°€\n",
    "            if i % 2 == 0:\n",
    "                prompt += f\", {quality_keywords[i % len(quality_keywords)]}\"\n",
    "\n",
    "            smart_prompts.append(prompt)\n",
    "\n",
    "        return smart_prompts, self.features\n",
    "\n",
    "print(\"âœ… OpenCV ê¸°ë°˜ SmartPromptGenerator í´ë˜ìŠ¤ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "try:\n",
    "    prompt_gen = SmartPromptGenerator(\"test.png\")\n",
    "    smart_prompts, features = prompt_gen.generate_smart_prompts(5)\n",
    "    print(\"ğŸ¨ ìƒì„±ëœ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸:\")\n",
    "    for i, prompt in enumerate(smart_prompts, 1):\n",
    "        print(f\"  {i}. {prompt}\")\n",
    "    print(f\"ğŸ“Š ë¶„ì„ëœ íŠ¹ì§•: {features}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757069008994,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "-YB3-DK89RjR",
    "outputId": "c47c3f12-44b8-4a31-e71c-d1758e0d76f6"
   },
   "outputs": [],
   "source": [
    "# ê°œì„ ëœ find_similar_faces_auto_enhanced í•¨ìˆ˜ (ë‚˜ì´, ì„±ë³„, ì¸ì¢… ì •ë³´ ì¶”ê°€)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6, max_attempts=50, target_count=3,\n",
    "                                   age_group=\"20ëŒ€\", gender=\"ì—¬ì„±\", ethnicity=\"ì•„ì‹œì•ˆ\"):\n",
    "    \"\"\"OpenCV ê¸°ë°˜ ìë™ ì–¼êµ´ ìœ ì‚¬ë„ íƒìƒ‰ (ê°œì¸ì •ë³´ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„ )\"\"\"\n",
    "\n",
    "    print(\"ğŸ”„ ê°œì„ ëœ OpenCV ê¸°ë°˜ ìë™ ìœ ì‚¬ë„ íƒìƒ‰ ì‹œì‘...\")\n",
    "    print(f\"ğŸ¯ ê²€ìƒ‰ ì¡°ê±´: {age_group} {gender} {ethnicity}\")\n",
    "\n",
    "    # OpenCV ê¸°ë°˜ í‰ê°€ê¸° ì´ˆê¸°í™”\n",
    "    try:\n",
    "        print(\"ğŸ¯ OpenCV ê¸°ë°˜ í‰ê°€ê¸° ì´ˆê¸°í™”...\")\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "        print(\"âœ… OpenCV ê¸°ë°˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "        # ê¸°ë³¸ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "        print(f\"ğŸ¨ ê¸°ë³¸ {len(smart_prompts)}ê°œì˜ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OpenCV ê¸°ë°˜ í‰ê°€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return []\n",
    "\n",
    "    # ê°œì¸ì •ë³´ ê¸°ë°˜ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    enhanced_prompts = generate_demographic_prompts(age_group, gender, ethnicity)\n",
    "\n",
    "    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì™€ ê°œì¸ì •ë³´ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê²°í•©\n",
    "    all_prompts = enhanced_prompts + smart_prompts[:5]  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë„ ì¼ë¶€ í¬í•¨\n",
    "\n",
    "    print(f\"ğŸ¨ ì´ {len(all_prompts)}ê°œì˜ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "    successful_images = []\n",
    "    attempts = 0\n",
    "    prompt_idx = 0\n",
    "\n",
    "    print(f\"ğŸ¯ ëª©í‘œ: {target_count}ê°œì˜ ìœ ì‚¬í•œ ì–¼êµ´ ì°¾ê¸° (ìœ ì‚¬ë„ >= {target_score})\")\n",
    "    print(f\"ğŸ“Š ë¶„ì„ëœ íŠ¹ì§•: {features}\")\n",
    "\n",
    "    while len(successful_images) < target_count and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        current_prompt = all_prompts[prompt_idx % len(all_prompts)]\n",
    "\n",
    "        print(f\"\\nğŸ”„ ì‹œë„ {attempts}/{max_attempts}\")\n",
    "        print(f\"ğŸ“ í”„ë¡¬í”„íŠ¸: {current_prompt}\")\n",
    "\n",
    "        try:\n",
    "            # ì´ë¯¸ì§€ ìƒì„±\n",
    "            with torch.no_grad():\n",
    "                result = pipe(\n",
    "                    current_prompt,\n",
    "                    num_inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    width=512,\n",
    "                    height=512\n",
    "                )\n",
    "\n",
    "            generated_image = result.images[0]\n",
    "\n",
    "            # ìœ ì‚¬ë„ í‰ê°€\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "\n",
    "            print(f\"ğŸ“Š í‰ê°€ ê²°ê³¼:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "            # ëª©í‘œ ì ìˆ˜ ë‹¬ì„± ì‹œ ì €ì¥\n",
    "            if scores['total_score'] >= target_score:\n",
    "                successful_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'attempt': attempts,\n",
    "                    'demographics': f\"{age_group}_{gender}_{ethnicity}\"\n",
    "                })\n",
    "                print(f\"âœ… ì„±ê³µ! ({len(successful_images)}/{target_count})\")\n",
    "\n",
    "                # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(successful_images)} (Score: {scores['total_score']:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print(f\"âŒ ëª©í‘œ ì ìˆ˜ ë¯¸ë‹¬ (í˜„ì¬: {scores['total_score']:.4f}, ëª©í‘œ: {target_score})\")\n",
    "\n",
    "            prompt_idx += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "            prompt_idx += 1\n",
    "\n",
    "    print(f\"\\nğŸ¯ íƒìƒ‰ ì™„ë£Œ: {len(successful_images)}ê°œì˜ ì„±ê³µì ì¸ ì´ë¯¸ì§€ ìƒì„±\")\n",
    "\n",
    "    # ê²°ê³¼ ì •ë ¬ (ì´ ì ìˆ˜ ê¸°ì¤€)\n",
    "    successful_images.sort(key=lambda x: x['scores']['total_score'], reverse=True)\n",
    "\n",
    "    return successful_images\n",
    "\n",
    "\n",
    "def generate_demographic_prompts(age_group, gender, ethnicity):\n",
    "    \"\"\"ë‚˜ì´, ì„±ë³„, ì¸ì¢… ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "\n",
    "    # ë‚˜ì´ ê·¸ë£¹ë³„ í‚¤ì›Œë“œ\n",
    "    age_keywords = {\n",
    "        \"10ëŒ€\": [\"young teenager\", \"youthful\", \"teenage\", \"adolescent\"],\n",
    "        \"20ëŒ€\": [\"young adult\", \"early twenties\", \"youthful adult\", \"young person\"],\n",
    "        \"30ëŒ€\": [\"adult\", \"mature young adult\", \"thirty-something\", \"professional adult\"],\n",
    "        \"40ëŒ€\": [\"middle-aged adult\", \"mature\", \"experienced adult\", \"forty-something\"],\n",
    "        \"50ëŒ€\": [\"mature adult\", \"middle-aged\", \"distinguished\", \"experienced person\"]\n",
    "    }\n",
    "\n",
    "    # ì„±ë³„ í‚¤ì›Œë“œ\n",
    "    gender_keywords = {\n",
    "        \"ë‚¨ì„±\": [\"man\", \"male\", \"gentleman\", \"guy\"],\n",
    "        \"ì—¬ì„±\": [\"woman\", \"female\", \"lady\", \"girl\"]\n",
    "    }\n",
    "\n",
    "    # ì¸ì¢… í‚¤ì›Œë“œ\n",
    "    ethnicity_keywords = {\n",
    "        \"ì•„ì‹œì•ˆ\": [\"Asian\", \"East Asian\", \"Korean\", \"Japanese\", \"Chinese\"],\n",
    "        \"ë°±ì¸\": [\"Caucasian\", \"white\", \"European\", \"Western\"],\n",
    "        \"í‘ì¸\": [\"African American\", \"black\", \"African\", \"dark-skinned\"],\n",
    "        \"íˆìŠ¤íŒ¨ë‹‰\": [\"Hispanic\", \"Latino\", \"Latin American\", \"Mediterranean\"],\n",
    "        \"ì¤‘ë™\": [\"Middle Eastern\", \"Arabic\", \"Persian\", \"Turkish\"]\n",
    "    }\n",
    "\n",
    "    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ (ë°ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤)\n",
    "    lighting_styles = [\n",
    "        \"natural lighting, bright and cheerful\",\n",
    "        \"soft natural daylight, warm atmosphere\",\n",
    "        \"bright studio lighting, clean background\",\n",
    "        \"outdoor natural light, fresh and bright\",\n",
    "        \"golden hour lighting, warm and inviting\",\n",
    "        \"soft window light, natural and bright\"\n",
    "    ]\n",
    "\n",
    "    # í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ\n",
    "    quality_keywords = [\n",
    "        \"high quality, detailed, photorealistic\",\n",
    "        \"professional photography, sharp focus, 8k resolution\",\n",
    "        \"natural skin tone, realistic features, detailed\",\n",
    "        \"clear facial features, professional portrait\",\n",
    "        \"realistic lighting, natural expression, high detail\"\n",
    "    ]\n",
    "\n",
    "    enhanced_prompts = []\n",
    "\n",
    "    # ê° ì¡°í•©ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    age_terms = age_keywords.get(age_group, [\"young adult\"])\n",
    "    gender_terms = gender_keywords.get(gender, [\"person\"])\n",
    "    ethnic_terms = ethnicity_keywords.get(ethnicity, [\"\"])\n",
    "\n",
    "    for age_term in age_terms[:2]:  # ìƒìœ„ 2ê°œ ë‚˜ì´ í‚¤ì›Œë“œ\n",
    "        for gender_term in gender_terms[:2]:  # ìƒìœ„ 2ê°œ ì„±ë³„ í‚¤ì›Œë“œ\n",
    "            for ethnic_term in ethnic_terms[:2]:  # ìƒìœ„ 2ê°œ ì¸ì¢… í‚¤ì›Œë“œ\n",
    "                for lighting in lighting_styles[:3]:  # ìƒìœ„ 3ê°œ ì¡°ëª… ìŠ¤íƒ€ì¼\n",
    "                    for quality in quality_keywords[:2]:  # ìƒìœ„ 2ê°œ í’ˆì§ˆ í‚¤ì›Œë“œ\n",
    "\n",
    "                        # í”„ë¡¬í”„íŠ¸ ì¡°í•©\n",
    "                        if ethnic_term:\n",
    "                            prompt = f\"professional portrait of a {age_term} {ethnic_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        else:\n",
    "                            prompt = f\"professional portrait of a {age_term} {gender_term}, {lighting}, {quality}\"\n",
    "\n",
    "                        enhanced_prompts.append(prompt)\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±° ë° ì…”í”Œ\n",
    "    enhanced_prompts = list(set(enhanced_prompts))\n",
    "    random.shuffle(enhanced_prompts)\n",
    "\n",
    "    print(f\"ğŸ¨ {age_group} {gender} {ethnicity} ê¸°ë°˜ {len(enhanced_prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„±\")\n",
    "\n",
    "    return enhanced_prompts[:15]  # ìƒìœ„ 15ê°œë§Œ ë°˜í™˜\n",
    "\n",
    "\n",
    "print(\"âœ… ê°œì„ ëœ find_similar_faces_auto_enhanced í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(\"ğŸš€ ì´ì œ ë‚˜ì´, ì„±ë³„, ì¸ì¢… ì •ë³´ë¡œ ë” ì •í™•í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1757069009050,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "wMQlEv_KWgWb",
    "outputId": "d6aac505-c8d4-4945-9f70-e9035828dd92"
   },
   "outputs": [],
   "source": [
    "# ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì œ\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ ê°œì„ ëœ find_similar_faces_auto_enhanced ì‚¬ìš© ì˜ˆì œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ë“¤\n",
    "print(\"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ë“¤:\")\n",
    "print(\"ë‚˜ì´ ê·¸ë£¹: 10ëŒ€, 20ëŒ€, 30ëŒ€, 40ëŒ€, 50ëŒ€\")\n",
    "print(\"ì„±ë³„: ë‚¨ì„±, ì—¬ì„±\")\n",
    "print(\"ì¸ì¢…: ì•„ì‹œì•ˆ, ë°±ì¸, í‘ì¸, íˆìŠ¤íŒ¨ë‹‰, ì¤‘ë™\")\n",
    "print()\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª ì˜ˆì œ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸:\")\n",
    "test_prompts = generate_demographic_prompts(\"20ëŒ€\", \"ì—¬ì„±\", \"ì•„ì‹œì•ˆ\")\n",
    "print(\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ (ìƒìœ„ 5ê°œ):\")\n",
    "for i, prompt in enumerate(test_prompts[:5], 1):\n",
    "    print(f\"  {i}. {prompt}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš©ë²•:\")\n",
    "print(\"\"\"\n",
    "# ê¸°ë³¸ ì‚¬ìš© (20ëŒ€ ì—¬ì„± ì•„ì‹œì•ˆ)\n",
    "similar_faces = find_similar_faces_auto_enhanced(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=\"test.png\",\n",
    "    target_score=0.6,\n",
    "    max_attempts=30,\n",
    "    target_count=3\n",
    ")\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ì„¤ì • (30ëŒ€ ë‚¨ì„± ë°±ì¸)\n",
    "similar_faces = find_similar_faces_auto_enhanced(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=\"test.png\",\n",
    "    target_score=0.65,\n",
    "    max_attempts=50,\n",
    "    target_count=5,\n",
    "    age_group=\"30ëŒ€\",\n",
    "    gender=\"ë‚¨ì„±\",\n",
    "    ethnicity=\"ë°±ì¸\"\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35339,
     "status": "ok",
     "timestamp": 1757069044390,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "stxgBgRDQidf",
    "outputId": "780a9d8a-d1dd-4bc1-f795-d7fcb1b86b33"
   },
   "outputs": [],
   "source": [
    "# !pip install -q \"numpy<2\"\n",
    "# !pip install -q kaggle\n",
    "# !pip install -q kagglehub\n",
    "# !pip install -q albumentations\n",
    "# !pip install -q ultralytics\n",
    "# !pip install -q --user opencv-python\n",
    "# !pip install -q torchvision\n",
    "# !pip install -q torch\n",
    "# !pip install -q pycocotools\n",
    "#!pip install --upgrade torchvision\n",
    "#!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "\n",
    "!pip install -q lpips\n",
    "print(f\"lpips ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "!pip install -q pytorch-fid\n",
    "print(f\"pytorch-fid ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "!pip install -q torch-fidelity\n",
    "print(f\"torch-fidelity ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "!pip install -q scipy\n",
    "print(f\"scipy ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "!pip install -q face_recognition\n",
    "print(f\"face_recognition ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "!pip install -q diffusers\n",
    "print(f\"diffusers ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1757069044411,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "y-PxX7m45GtI",
    "outputId": "47d651d3-dce5-4659-da47-e6c31a81c64a"
   },
   "outputs": [],
   "source": [
    "# ëŒ€ì•ˆ ë°©ë²•: OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸°\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import lpips\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class OpenCVFaceSimilarityEvaluator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸°\"\"\"\n",
    "        print(f\"OpenCV ê¸°ë°˜ í‰ê°€ê¸° ì´ˆê¸°í™” ì¤‘: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™”\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # ì°¸ì¡° ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ\n",
    "            self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "            if self.reference_features is not None:\n",
    "                print(\"âœ… ì°¸ì¡° ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}\")\n",
    "\n",
    "        # LPIPS ì´ˆê¸°í™”\n",
    "        try:\n",
    "            self.lpips_model = lpips.LPIPS(net='alex').to(__device)\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((512, 512)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "            ])\n",
    "            print(\"âœ… LPIPS ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ LPIPS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            self.lpips_model = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ (OpenCV ê¸°ë°˜)\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ\n",
    "            largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "            x, y, w, h = largest_face\n",
    "\n",
    "            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "\n",
    "            # íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ íŠ¹ì§•\n",
    "            hist_features = cv2.calcHist([face_resized], [0], None, [256], [0, 256]).flatten()\n",
    "\n",
    "            # LBP (Local Binary Pattern) íŠ¹ì§•\n",
    "            lbp_features = self.calculate_lbp(face_resized)\n",
    "\n",
    "            # íŠ¹ì§• ê²°í•©\n",
    "            combined_features = np.concatenate([hist_features, lbp_features])\n",
    "\n",
    "            return combined_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_lbp(self, image, radius=3, n_points=24):\n",
    "        \"\"\"Local Binary Pattern ê³„ì‚°\"\"\"\n",
    "        try:\n",
    "            from skimage.feature import local_binary_pattern\n",
    "            lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "            (hist, _) = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            return hist\n",
    "        except:\n",
    "            # skimageê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ëŒ€ì•ˆ ì‚¬ìš©\n",
    "            return np.histogram(image.ravel(), bins=50)[0].astype(\"float\")\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ìœ ì‚¬ë„ í‰ê°€\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 1. OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "                similarity = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                face_similarity = max(0, similarity)  # ìŒìˆ˜ ë°©ì§€\n",
    "                scores['face_similarity'] = face_similarity\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "\n",
    "            # 2. LPIPS ì ìˆ˜ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "            if self.lpips_model is not None:\n",
    "                try:\n",
    "                    ref_tensor = self.transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(__device)\n",
    "                    gen_tensor = self.transform(generated_image).unsqueeze(0).to(__device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = self.lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS ê³„ì‚° ì˜¤ë¥˜: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 3. ì¢…í•© ì ìˆ˜\n",
    "            face_weight = 0.8  # OpenCV ê¸°ë°˜ì´ë¯€ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì •\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"í‰ê°€ ì˜¤ë¥˜: {e}\")\n",
    "            scores = {'face_similarity': 0.0, 'lpips_similarity': 0.0, 'total_score': 0.0}\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"OpenCV ê¸°ë°˜ ì–¼êµ´ í‰ê°€ê¸° ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1757069044436,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "Ktzm_aa25GtJ",
    "outputId": "34482451-7c44-4ada-fabf-6423602cc0f5"
   },
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ find_similar_faces_auto í•¨ìˆ˜ë¥¼ OpenCV ê¸°ë°˜ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6, max_attempts=50, target_count=3, use_opencv_fallback=True):\n",
    "    \"\"\"í–¥ìƒëœ ìë™ ì–¼êµ´ ìœ ì‚¬ë„ íƒìƒ‰ (face_recognition + OpenCV ë°±ì—…)\"\"\"\n",
    "\n",
    "    print(\"ğŸ”„ ìë™ ìœ ì‚¬ë„ íƒìƒ‰ ì‹œì‘...\")\n",
    "\n",
    "    # ë¨¼ì € face_recognition ì‹œë„\n",
    "    evaluator = None\n",
    "    prompt_gen = None\n",
    "\n",
    "    try:\n",
    "        print(\"ğŸ¯ face_recognition ê¸°ë°˜ í‰ê°€ê¸° ì‹œë„...\")\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "        print(\"âœ… face_recognition ê¸°ë°˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "        # ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "        print(f\"ê°ì§€ëœ ì–¼êµ´ íŠ¹ì§•: {features}\")\n",
    "\n",
    "    except Exception as face_rec_error:\n",
    "        print(f\"âŒ face_recognition ì´ˆê¸°í™” ì‹¤íŒ¨: {face_rec_error}\")\n",
    "\n",
    "        if use_opencv_fallback:\n",
    "            print(\"ğŸ”„ OpenCV ê¸°ë°˜ ë°±ì—… ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜...\")\n",
    "            try:\n",
    "                evaluator = OpenCVFaceSimilarityEvaluator(reference_image_path)\n",
    "                print(\"âœ… OpenCV ê¸°ë°˜ í‰ê°€ê¸° ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "                # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "                smart_prompts = [\n",
    "                    \"professional portrait, high quality, detailed, sharp focus\",\n",
    "                    \"natural lighting portrait, realistic, professional photography\",\n",
    "                    \"soft studio lighting, headshot, detailed face\",\n",
    "                    \"outdoor natural portrait, clear lighting, high resolution\",\n",
    "                    \"casual portrait, friendly expression, detailed features\",\n",
    "                    \"business portrait, professional attire, studio lighting\"\n",
    "                ]\n",
    "                features = {\"system\": \"opencv_fallback\"}\n",
    "\n",
    "            except Exception as opencv_error:\n",
    "                print(f\"âŒ OpenCV ë°±ì—… ì‹œìŠ¤í…œë„ ì‹¤íŒ¨: {opencv_error}\")\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    if not evaluator:\n",
    "        print(\"âŒ í‰ê°€ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "\n",
    "    # ê³µí†µ íƒìƒ‰ ë¡œì§\n",
    "    found_images = []\n",
    "    attempt_count = 0\n",
    "\n",
    "    # ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces, bad hands, distorted face\"\n",
    "\n",
    "    print(f\"ğŸ¯ ëª©í‘œ: {target_count}ê°œ ì´ë¯¸ì§€ (ì ìˆ˜ {target_score} ì´ìƒ)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while len(found_images) < target_count and attempt_count < max_attempts:\n",
    "        attempt_count += 1\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ì„ íƒ (ìˆœí™˜)\n",
    "        prompt_idx = (attempt_count - 1) % len(smart_prompts)\n",
    "        current_prompt = smart_prompts[prompt_idx]\n",
    "\n",
    "        # ëœë¤ ì‹œë“œ\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\nğŸ” ì‹œë„ {attempt_count}/{max_attempts}\")\n",
    "        print(f\"ğŸ“ í”„ë¡¬í”„íŠ¸: {current_prompt}\")\n",
    "        print(f\"ğŸ² ì‹œë“œ: {seed}\")\n",
    "\n",
    "        try:\n",
    "            # ì´ë¯¸ì§€ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "            generated_image = alternative_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False  # ë°°ì¹˜ ì²˜ë¦¬ì‹œ í™”ë©´ ì¶œë ¥ ë„ê¸°\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                print(\"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨\")\n",
    "                continue\n",
    "\n",
    "            # ìœ ì‚¬ë„ í‰ê°€\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "            total_score = scores['total_score']\n",
    "\n",
    "            print(f\"ğŸ“Š ì ìˆ˜: {total_score:.3f} (ì–¼êµ´: {scores['face_similarity']:.3f}, LPIPS: {scores['lpips_similarity']:.3f})\")\n",
    "\n",
    "            # ëª©í‘œ ì ìˆ˜ ë‹¬ì„±ì‹œ ì €ì¥\n",
    "            if total_score >= target_score:\n",
    "                print(f\"âœ… ëª©í‘œ ë‹¬ì„±! (ì ìˆ˜: {total_score:.3f})\")\n",
    "\n",
    "                # ì´ë¯¸ì§€ ì €ì¥\n",
    "                save_path = f\"similar_face_{len(found_images)+1:02d}_score_{total_score:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                found_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path\n",
    "                })\n",
    "\n",
    "                # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(found_images)} (Score: {total_score:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹œë„ {attempt_count} ì˜¤ë¥˜: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"ğŸ íƒìƒ‰ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ”¢ ì‹œë„ íšŸìˆ˜: {attempt_count}\")\n",
    "    print(f\"ğŸ–¼ï¸ ë°œê²¬ëœ ì´ë¯¸ì§€: {len(found_images)}ê°œ\")\n",
    "\n",
    "    if found_images:\n",
    "        print(\"\\nğŸ“‹ ë°œê²¬ëœ ì´ë¯¸ì§€ ì •ë³´:\")\n",
    "        for i, result in enumerate(found_images):\n",
    "            print(f\"  {i+1}. ì ìˆ˜: {result['scores']['total_score']:.3f}, ê²½ë¡œ: {result['path']}\")\n",
    "\n",
    "    return found_images\n",
    "\n",
    "print(\"âœ… í†µí•© ìë™ íƒìƒ‰ í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643,
     "referenced_widgets": [
      "5b9024b085ef47a69cf529c626a6c356",
      "1892b885c9f3473ba320f52e687ed4b9",
      "a8ce3f62c420440091a27a5793643b84",
      "a32142681ece4dac8a9614442a929ac4",
      "31a79a6bb4574aa58aa478c99641fce9",
      "d00dd16c0c424e779d55f932a522de1d",
      "1221f3d8061943e395f0517c2bb0ba3b",
      "b0f5643c47c342dd897008e86771c9cb",
      "a4a2fd815d034542a243a342823da200",
      "2cde21101bff44979b3ed02110617631",
      "146f96d250c3474f89d5497506dadc1c"
     ]
    },
    "executionInfo": {
     "elapsed": 2388,
     "status": "ok",
     "timestamp": 1757069759993,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "gtKLPc9l5GtJ",
    "outputId": "8ff4d89f-b698-46d1-9b32-c2411bff52f6"
   },
   "outputs": [],
   "source": [
    "# ğŸš€ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "print(\"ğŸ”§ í™˜ê²½ ê°ì§€ ë° ì„¤ì •...\")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì • (helper í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "import os\n",
    "\n",
    "# ì½”ë© ì—¬ë¶€ í™•ì¸ (helper ëª¨ë“ˆ ì‚¬ìš©)\n",
    "try:\n",
    "    is_colab = helper.is_colab\n",
    "except:\n",
    "    # helperê°€ ì—†ìœ¼ë©´ ì§ì ‘ í™•ì¸\n",
    "    is_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if is_colab:\n",
    "    colab_path = \"/content/drive/MyDrive/homepage/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜_ì‘ì—…ì¤‘/test.png\"\n",
    "    reference_photo = colab_path\n",
    "    print(f\"âœ… ì½”ë© í™˜ê²½ - ê²½ë¡œ: {reference_photo}\")\n",
    "else:\n",
    "    local_path = \"test.png\"\n",
    "    reference_photo = local_path\n",
    "    print(f\"âœ… ë¡œì»¬ í™˜ê²½ - ê²½ë¡œ: {reference_photo}\")\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "if not os.path.exists(reference_photo):\n",
    "    print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    print(\"í˜„ì¬ ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "    print(\"ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡:\")\n",
    "    for file in os.listdir('.'):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  - {file}\")\n",
    "    reference_photo = None\n",
    "\n",
    "if reference_photo:\n",
    "    print(f\"\\nğŸ¯ í†µí•© ìë™ íƒìƒ‰ ì‹¤í–‰...\")\n",
    "\n",
    "    try:\n",
    "        # ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš© (enhanced ë²„ì „)\n",
    "        similar_faces = find_similar_faces_auto_enhanced(\n",
    "            pipe=pipe,\n",
    "            reference_image_path=reference_photo,\n",
    "            target_score=0.5,        # ê´€ëŒ€í•œ ì ìˆ˜\n",
    "            max_attempts=20,         # í…ŒìŠ¤íŠ¸ìš© ì ì€ ì‹œë„\n",
    "            target_count=2,          # 2ê°œë§Œ ì°¾ê¸°\n",
    "            age_group=\"30ëŒ€\",\n",
    "            gender=\"ë‚¨ì„±\",\n",
    "            ethnicity=\"ë°±ì¸\",\n",
    "            use_opencv_fallback=True # OpenCV ë°±ì—… í™œì„±í™”\n",
    "        )\n",
    "\n",
    "        if similar_faces:\n",
    "            print(f\"\\nğŸ‰ ì„±ê³µ! {len(similar_faces)}ê°œì˜ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "            # íˆìŠ¤í† ë¦¬ ê´€ë¦¬ì ì‚¬ìš© (ê¸°ì¡´ gen_manager ì¬ì‚¬ìš©)\n",
    "            print(\"\\nğŸ“š ìƒì„± íˆìŠ¤í† ë¦¬ ì €ì¥ ì¤‘...\")\n",
    "            for result in similar_faces:\n",
    "                metadata = {\n",
    "                    \"prompt\": result['prompt'],\n",
    "                    \"seed\": result['seed'],\n",
    "                    \"scores\": result['scores'],\n",
    "                    \"method\": \"auto_search\",\n",
    "                    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "                }\n",
    "                gen_id = gen_manager.save_generation(metadata, result['path'])\n",
    "                print(f\"  íˆìŠ¤í† ë¦¬ ID {gen_id}: {result['path']}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\nğŸ˜¢ ì¡°ê±´ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            print(\"ğŸ’¡ ì ìˆ˜ë¥¼ ë” ë‚®ì¶”ê±°ë‚˜ ì‹œë„ íšŸìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í†µí•© íƒìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        print(\"\\nğŸ”„ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)...\")\n",
    "        try:\n",
    "            # enhanced_face_generation í•¨ìˆ˜ ì¬ì‚¬ìš©\n",
    "            test_image = enhanced_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=\"professional portrait, high quality, realistic, detailed face\",\n",
    "                negative_prompt=\"blurry, low quality, bad anatomy, deformed\",\n",
    "                seed=42,\n",
    "                save_path=\"fallback_test.png\"\n",
    "            )\n",
    "\n",
    "            if test_image:\n",
    "                print(\"âœ… ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ! ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
    "        except Exception as fallback_e:\n",
    "            print(f\"âŒ ê¸°ë³¸ ìƒì„±ë„ ì‹¤íŒ¨: {fallback_e}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ test.png íŒŒì¼ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3323,
     "status": "ok",
     "timestamp": 1757069062961,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "riCoM4kZdb_T",
    "outputId": "2359d41c-1418-47db-d239-63cc4ee65c15"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import importlib\n",
    "import helper_c0z0c_dev as helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1757069062989,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "TXoYK8FtMfKM",
    "outputId": "871ced58-855d-40a9-9584-24289cb99366"
   },
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageDraw\n",
    "import albumentations as A\n",
    "import IPython.display\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from collections import OrderedDict\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as coco_mask\n",
    "\n",
    "# --- ê¸°íƒ€ ---\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timezone, timedelta\n",
    "import pytz\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "__device_cpu = torch.device('cpu')\n",
    "\n",
    "  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if __device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:{__device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "bdbb6d528d4949159dcd3fd07f0e0075",
      "6f63fcd64d9b42e9b9db0ab247ea3652",
      "f8ed5f9bb8004cea83322ae7519c721e",
      "ac3f515f265e4880b1772c3274695e75",
      "9cd78b5bebc442cea7600d375204bc9a",
      "2e901af9a07345c8b8307a5f2c06c2bb",
      "144506bedbdd4755a5a94a0257100323",
      "0322d0ac3c50446594dd6754e4068241",
      "b1d5c8d9fd5644bba6363bbd87d313fe",
      "fd761716247648c0aa57cf756c6b0f7b",
      "0e83df493cab467abe97477dd4b765cb"
     ]
    },
    "executionInfo": {
     "elapsed": 7435,
     "status": "ok",
     "timestamp": 1757069070425,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "Es-QZcrGYKSg",
    "outputId": "117fdf0f-df2a-4d8d-d010-1100e6f84b1c"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision matplotlib pillow requests\n",
    "import requests\n",
    "import io\n",
    "from diffusers import StableDiffusionPipeline\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUH9352r0XRf"
   },
   "outputs": [],
   "source": [
    "def alternative_face_generation(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                              num_inference_steps=30, guidance_scale=7.5,\n",
    "                              save_path=None, show_image=True):\n",
    "    \"\"\"í™•ì¥ëœ Stable Diffusion ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    try:\n",
    "        # ê¸°ë³¸ negative prompt ì„¤ì •\n",
    "        if negative_prompt is None:\n",
    "            negative_prompt = \"blurry, low quality, bad anatomy, deformed, extra limbs, bad hands, bad face, bad eyes, extra fingers, cartoon, anime, nsfw, inappropriate\"\n",
    "\n",
    "        # ëœë¤ ì‹œë“œ ê³ ì •\n",
    "        generator = torch.Generator(device=pipe.device).manual_seed(seed)\n",
    "\n",
    "        print(f\"ì´ë¯¸ì§€ ìƒì„± ì¤‘... (ì‹œë“œ: {seed})\")\n",
    "        print(f\"í”„ë¡¬í”„íŠ¸: {prompt}\")\n",
    "        if negative_prompt:\n",
    "            print(f\"ë„¤ê±°í‹°ë¸Œ: {negative_prompt}\")\n",
    "\n",
    "        # ì´ë¯¸ì§€ ìƒì„±\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "\n",
    "        # ì´ë¯¸ì§€ ì €ì¥\n",
    "        if save_path:\n",
    "            image.save(save_path)\n",
    "            print(f\"ì´ë¯¸ì§€ ì €ì¥ë¨: {save_path}\")\n",
    "\n",
    "            # ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "            metadata = {\n",
    "                \"prompt\": prompt,\n",
    "                \"negative_prompt\": negative_prompt,\n",
    "                \"seed\": seed,\n",
    "                \"steps\": num_inference_steps,\n",
    "                \"guidance_scale\": guidance_scale\n",
    "            }\n",
    "\n",
    "            import json\n",
    "            metadata_path = save_path.replace('.png', '_metadata.json')\n",
    "            with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Generated (Seed: {seed})\", fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        print(\"ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!\")\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1757069488412,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "6WCIVPBn0XRf",
    "outputId": "e89aa312-e9e7-47c9-a2c5-93d451b9a087"
   },
   "outputs": [],
   "source": [
    "# ğŸ¯ OpenCV ê¸°ë°˜ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€ê¸° (face_recognition ì™„ì „ ëŒ€ì²´)\n",
    "print(\"ğŸ”„ OpenCV ì „ìš© ì–¼êµ´ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import lpips\n",
    "    LPIPS_AVAILABLE = True\n",
    "    print(\"âœ… LPIPS ì‚¬ìš© ê°€ëŠ¥\")\n",
    "except ImportError:\n",
    "    LPIPS_AVAILABLE = False\n",
    "    print(\"âš ï¸ LPIPS ì—†ìŒ - ê¸°ë³¸ íŠ¹ì§•ë§Œ ì‚¬ìš©\")\n",
    "\n",
    "class OpenCVFaceEvaluator:\n",
    "    \"\"\"face_recognition ì—†ì´ OpenCVë§Œìœ¼ë¡œ ì–¼êµ´ ìœ ì‚¬ë„ í‰ê°€\"\"\"\n",
    "\n",
    "    def __init__(self, reference_image_path):\n",
    "        print(f\"ğŸ¯ OpenCV ì–¼êµ´ í‰ê°€ê¸° ì´ˆê¸°í™”: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV ì–¼êµ´ ê°ì§€ê¸°ë“¤ ì´ˆê¸°í™”\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "        # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ë° íŠ¹ì§• ì¶”ì¶œ\n",
    "        if not os.path.exists(reference_image_path):\n",
    "            raise FileNotFoundError(f\"ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image = cv2.imread(reference_image_path)\n",
    "        if self.reference_image is None:\n",
    "            raise ValueError(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "        self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "        if self.reference_features is None:\n",
    "            raise ValueError(\"ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "        print(\"âœ… ì°¸ì¡° ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ\")\n",
    "\n",
    "        # LPIPS ì´ˆê¸°í™” (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "        if LPIPS_AVAILABLE:\n",
    "            try:\n",
    "                self.lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.Resize((256, 256)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                ])\n",
    "                print(\"âœ… LPIPS ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ LPIPS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "                self.lpips_model = None\n",
    "        else:\n",
    "            self.lpips_model = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"OpenCV ê¸°ë°˜ ì¢…í•© ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì–¼êµ´ ê°ì§€\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(50, 50))\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ\n",
    "            x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "            face_normalized = cv2.equalizeHist(face_resized)\n",
    "\n",
    "            # 1. íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•\n",
    "            hist_features = cv2.calcHist([face_normalized], [0], None, [64], [0, 256]).flatten()\n",
    "            hist_features = hist_features / (hist_features.sum() + 1e-7)\n",
    "\n",
    "            # 2. LBP íŠ¹ì§• (ê°„ë‹¨í•œ êµ¬í˜„)\n",
    "            lbp_features = self.calculate_simple_lbp(face_normalized)\n",
    "\n",
    "            # 3. ê¸°í•˜í•™ì  íŠ¹ì§•\n",
    "            geometric_features = np.array([\n",
    "                w / h,  # ì–¼êµ´ ë¹„ìœ¨\n",
    "                w, h,   # í¬ê¸°\n",
    "                len(self.eye_cascade.detectMultiScale(face_roi)),  # ëˆˆ ê°œìˆ˜\n",
    "                np.std(face_normalized),  # í…ìŠ¤ì²˜ ë³€í™”ë„\n",
    "                np.mean(face_normalized)  # í‰ê·  ë°ê¸°\n",
    "            ])\n",
    "\n",
    "            # 4. ì—ì§€ íŠ¹ì§•\n",
    "            edges = cv2.Canny(face_normalized, 50, 150)\n",
    "            edge_features = np.array([\n",
    "                np.sum(edges > 0) / (128 * 128),  # ì—ì§€ ë°€ë„\n",
    "                np.mean(edges),\n",
    "                np.std(edges)\n",
    "            ])\n",
    "\n",
    "            # ëª¨ë“  íŠ¹ì§• ê²°í•©\n",
    "            all_features = np.concatenate([\n",
    "                hist_features,      # 64ê°œ\n",
    "                lbp_features,       # 26ê°œ\n",
    "                geometric_features, # 6ê°œ\n",
    "                edge_features      # 3ê°œ\n",
    "            ])\n",
    "\n",
    "            return all_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_simple_lbp(self, image):\n",
    "        \"\"\"ê°„ë‹¨í•œ LBP ê³„ì‚°\"\"\"\n",
    "        h, w = image.shape\n",
    "        lbp = np.zeros((h-2, w-2), dtype=np.uint8)\n",
    "\n",
    "        for i in range(1, h-1):\n",
    "            for j in range(1, w-1):\n",
    "                center = image[i, j]\n",
    "                binary_val = 0\n",
    "\n",
    "                # 8ë°©í–¥ ì´ì›ƒ ê²€ì‚¬\n",
    "                neighbors = [\n",
    "                    image[i-1, j-1], image[i-1, j], image[i-1, j+1],\n",
    "                    image[i, j+1], image[i+1, j+1], image[i+1, j],\n",
    "                    image[i+1, j-1], image[i, j-1]\n",
    "                ]\n",
    "\n",
    "                for k, neighbor in enumerate(neighbors):\n",
    "                    if neighbor >= center:\n",
    "                        binary_val += 2**k\n",
    "\n",
    "                lbp[i-1, j-1] = binary_val\n",
    "\n",
    "        # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 256))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        return hist\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"ìƒì„±ëœ ì´ë¯¸ì§€ì™€ì˜ ìœ ì‚¬ë„ í‰ê°€\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PILì„ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # 1. ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n",
    "                cosine_sim = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                scores['face_similarity'] = max(0, cosine_sim)\n",
    "\n",
    "                # 2. ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„\n",
    "                euclidean_dist = np.linalg.norm(self.reference_features - generated_features)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist / 100)\n",
    "                scores['euclidean_similarity'] = euclidean_sim\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "                scores['euclidean_similarity'] = 0.0\n",
    "\n",
    "            # 3. LPIPS (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "            if self.lpips_model is not None:\n",
    "                try:\n",
    "                    ref_tensor = self.transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(device)\n",
    "                    gen_tensor = self.transform(generated_image).unsqueeze(0).to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = self.lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS ê³„ì‚° ì˜¤ë¥˜: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 4. ì¢…í•© ì ìˆ˜\n",
    "            face_weight = 0.5\n",
    "            euclidean_weight = 0.3\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['euclidean_similarity'] * euclidean_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"í‰ê°€ ì˜¤ë¥˜: {e}\")\n",
    "            scores = {\n",
    "                'face_similarity': 0.0,\n",
    "                'euclidean_similarity': 0.0,\n",
    "                'lpips_similarity': 0.0,\n",
    "                'total_score': 0.0\n",
    "            }\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"âœ… OpenCV ê¸°ë°˜ ì–¼êµ´ í‰ê°€ê¸° í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"ğŸ¯ ì´ì œ face_recognition ì—†ì´ë„ ì™„ì „í•œ ì–¼êµ´ ìœ ì‚¬ë„ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì œ\n",
    "print(\"\\nğŸ’¡ ì‚¬ìš© ì˜ˆì œ:\")\n",
    "print(\"evaluator = OpenCVFaceEvaluator('your_reference_image.png')\")\n",
    "print(\"scores = evaluator.evaluate_similarity(generated_image)\")\n",
    "print(\"print(f'ìœ ì‚¬ë„: {scores[\\\"total_score\\\"]:.4f}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1757069488415,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "cm9ZJBRg0XRg"
   },
   "outputs": [],
   "source": [
    "class SmartPromptGenerator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œí•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "        print(f\"í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì¤‘: {reference_image_path}\")\n",
    "\n",
    "        # ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if not os.path.exists(reference_image_path):\n",
    "            raise FileNotFoundError(f\"ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_image_path}\")\n",
    "\n",
    "        try:\n",
    "            self.reference_image = face_recognition.load_image_file(reference_image_path)\n",
    "            print(\"ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ ì¤‘...\")\n",
    "            self.face_landmarks = face_recognition.face_landmarks(self.reference_image)\n",
    "\n",
    "            if self.face_landmarks:\n",
    "                print(f\"ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ ì™„ë£Œ ({len(self.face_landmarks)}ê°œ ì–¼êµ´)\")\n",
    "            else:\n",
    "                print(\"ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì˜¤ë¥˜: {e}\")\n",
    "            self.reference_image = None\n",
    "            self.face_landmarks = []\n",
    "\n",
    "    def analyze_face_features(self):\n",
    "        \"\"\"ì–¼êµ´ íŠ¹ì§• ë¶„ì„\"\"\"\n",
    "        if not self.face_landmarks:\n",
    "            print(\"ì–¼êµ´ ëœë“œë§ˆí¬ê°€ ì—†ì–´ ê¸°ë³¸ íŠ¹ì§•ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            return {\n",
    "                'eye_size': 'normal eyes',\n",
    "                'nose_type': 'straight nose',\n",
    "                'face_shape': 'balanced face'\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            landmarks = self.face_landmarks[0]\n",
    "            features = {}\n",
    "\n",
    "            # ëˆˆ ë¶„ì„\n",
    "            left_eye = landmarks.get('left_eye', [])\n",
    "            right_eye = landmarks.get('right_eye', [])\n",
    "\n",
    "            if left_eye and len(left_eye) >= 4:\n",
    "                eye_width = abs(left_eye[3][0] - left_eye[0][0])\n",
    "                features['eye_size'] = 'large eyes' if eye_width > 30 else 'normal eyes'\n",
    "            else:\n",
    "                features['eye_size'] = 'normal eyes'\n",
    "\n",
    "            # ì½” ë¶„ì„\n",
    "            nose_bridge = landmarks.get('nose_bridge', [])\n",
    "            features['nose_type'] = 'straight nose' if len(nose_bridge) > 3 else 'small nose'\n",
    "\n",
    "            # ì–¼êµ´í˜• ë¶„ì„ (ê°„ë‹¨í•œ ë²„ì „)\n",
    "            chin = landmarks.get('chin', [])\n",
    "            nose_bridge = landmarks.get('nose_bridge', [])\n",
    "\n",
    "            if chin and len(chin) >= 9 and nose_bridge and len(nose_bridge) >= 1:\n",
    "                face_width = abs(chin[0][0] - chin[-1][0])\n",
    "                face_height = abs(chin[8][1] - nose_bridge[0][1])\n",
    "\n",
    "                if face_height > face_width * 1.3:\n",
    "                    features['face_shape'] = 'oval face'\n",
    "                elif face_width > face_height * 1.1:\n",
    "                    features['face_shape'] = 'round face'\n",
    "                else:\n",
    "                    features['face_shape'] = 'balanced face'\n",
    "            else:\n",
    "                features['face_shape'] = 'balanced face'\n",
    "\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ì–¼êµ´ íŠ¹ì§• ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "            return {\n",
    "                'eye_size': 'normal eyes',\n",
    "                'nose_type': 'straight nose',\n",
    "                'face_shape': 'balanced face'\n",
    "            }\n",
    "\n",
    "    def generate_smart_prompts(self, base_descriptions=None):\n",
    "        \"\"\"ë¶„ì„ëœ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "        features = self.analyze_face_features()\n",
    "\n",
    "        if base_descriptions is None:\n",
    "            base_descriptions = [\n",
    "                \"professional portrait\",\n",
    "                \"natural lighting portrait\",\n",
    "                \"soft studio lighting\",\n",
    "                \"outdoor natural portrait\",\n",
    "                \"casual portrait\",\n",
    "                \"headshot photography\"\n",
    "            ]\n",
    "\n",
    "        # íŠ¹ì§• ê¸°ë°˜ ìˆ˜ì‹ì–´ ì¶”ê°€\n",
    "        feature_terms = []\n",
    "        for feature_type, feature_value in features.items():\n",
    "            feature_terms.append(feature_value)\n",
    "\n",
    "        # ê¸°ë³¸ í’ˆì§ˆ í–¥ìƒ í‚¤ì›Œë“œ\n",
    "        quality_terms = [\n",
    "            \"high quality\", \"detailed\", \"sharp focus\",\n",
    "            \"professional photography\", \"realistic\", \"8k resolution\"\n",
    "        ]\n",
    "\n",
    "        prompts = []\n",
    "        for base_desc in base_descriptions:\n",
    "            # íŠ¹ì§• + ê¸°ë³¸ ì„¤ëª… + í’ˆì§ˆ í‚¤ì›Œë“œ ì¡°í•©\n",
    "            feature_str = \", \".join(feature_terms[:2])  # ë„ˆë¬´ ë§ìœ¼ë©´ ê³¼ì í•©\n",
    "            quality_str = \", \".join(quality_terms[:3])\n",
    "\n",
    "            prompt = f\"{base_desc}, {feature_str}, {quality_str}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        print(f\"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ìˆ˜: {len(prompts)}\")\n",
    "        return prompts, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1757069488458,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "g29IwWA70XRg"
   },
   "outputs": [],
   "source": [
    "class ImageGenerationManager:\n",
    "    def __init__(self, history_file=\"generation_history.json\"):\n",
    "        \"\"\"ì´ë¯¸ì§€ ìƒì„± íˆìŠ¤í† ë¦¬ ê´€ë¦¬ì\"\"\"\n",
    "        self.history_file = history_file\n",
    "        self.load_history()\n",
    "\n",
    "    def load_history(self):\n",
    "        \"\"\"ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ\"\"\"\n",
    "        if os.path.exists(self.history_file):\n",
    "            with open(self.history_file, 'r', encoding='utf-8') as f:\n",
    "                self.history = json.load(f)\n",
    "        else:\n",
    "            self.history = {\"generations\": []}\n",
    "\n",
    "    def save_generation(self, metadata, image_path=None):\n",
    "        \"\"\"ìƒì„± ì •ë³´ ì €ì¥\"\"\"\n",
    "        generation_data = {\n",
    "            **metadata,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"image_path\": image_path,\n",
    "            \"generation_id\": len(self.history[\"generations\"]) + 1\n",
    "        }\n",
    "\n",
    "        self.history[\"generations\"].append(generation_data)\n",
    "\n",
    "        # íˆìŠ¤í† ë¦¬ íŒŒì¼ ì €ì¥\n",
    "        with open(self.history_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.history, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return generation_data[\"generation_id\"]\n",
    "\n",
    "    def regenerate_by_id(self, generation_id, pipe, save_new=True):\n",
    "        \"\"\"IDë¡œ ì´ë¯¸ì§€ ì¬ìƒì„±\"\"\"\n",
    "        generation = self.find_generation_by_id(generation_id)\n",
    "        if not generation:\n",
    "            print(f\"ID {generation_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "\n",
    "        return self.regenerate_from_metadata(generation, pipe, save_new)\n",
    "\n",
    "    def regenerate_from_metadata(self, metadata, pipe, save_new=True):\n",
    "        \"\"\"ë©”íƒ€ë°ì´í„°ë¡œë¶€í„° ì´ë¯¸ì§€ ì¬ìƒì„±\"\"\"\n",
    "        print(f\"ì¬ìƒì„± ì‹œì‘...\")\n",
    "        print(f\"ì›ë³¸ ì‹œë“œ: {metadata.get('seed', 'Unknown')}\")\n",
    "        print(f\"ì›ë³¸ í”„ë¡¬í”„íŠ¸: {metadata.get('prompt', 'Unknown')}\")\n",
    "\n",
    "        # ìƒˆ íŒŒì¼ëª… ìƒì„± (ì¬ìƒì„±ìš©)\n",
    "        save_path = None\n",
    "        if save_new:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f\"regenerated_{timestamp}_seed_{metadata.get('seed', 'unknown')}.png\"\n",
    "\n",
    "        # ì´ë¯¸ì§€ ì¬ìƒì„±\n",
    "        regenerated_image = alternative_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=metadata.get('prompt', ''),\n",
    "            negative_prompt=metadata.get('negative_prompt', ''),\n",
    "            seed=metadata.get('seed', 42),\n",
    "            num_inference_steps=metadata.get('steps', 30),\n",
    "            guidance_scale=metadata.get('guidance_scale', 7.5),\n",
    "            save_path=save_path,\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if regenerated_image and save_new:\n",
    "            # ì¬ìƒì„± ì •ë³´ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€\n",
    "            regen_metadata = {\n",
    "                **metadata,\n",
    "                \"is_regeneration\": True,\n",
    "                \"original_generation_id\": metadata.get('generation_id'),\n",
    "                \"regenerated_from\": metadata.get('image_path', 'Unknown')\n",
    "            }\n",
    "            self.save_generation(regen_metadata, save_path)\n",
    "\n",
    "        return regenerated_image\n",
    "\n",
    "    def find_generation_by_id(self, generation_id):\n",
    "        \"\"\"IDë¡œ ìƒì„± ì •ë³´ ì°¾ê¸°\"\"\"\n",
    "        for gen in self.history[\"generations\"]:\n",
    "            if gen.get(\"generation_id\") == generation_id:\n",
    "                return gen\n",
    "        return None\n",
    "\n",
    "    def search_generations(self, keyword=None, seed=None, limit=10):\n",
    "        \"\"\"ìƒì„± íˆìŠ¤í† ë¦¬ ê²€ìƒ‰\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for gen in self.history[\"generations\"]:\n",
    "            match = True\n",
    "\n",
    "            if keyword and keyword.lower() not in gen.get(\"prompt\", \"\").lower():\n",
    "                match = False\n",
    "\n",
    "            if seed and gen.get(\"seed\") != seed:\n",
    "                match = False\n",
    "\n",
    "            if match:\n",
    "                results.append(gen)\n",
    "\n",
    "        return results[-limit:]  # ìµœê·¼ í•­ëª©ë¶€í„°\n",
    "\n",
    "    def show_history(self, limit=10):\n",
    "        \"\"\"íˆìŠ¤í† ë¦¬ ì¶œë ¥\"\"\"\n",
    "        recent = self.history[\"generations\"][-limit:]\n",
    "\n",
    "        print(f\"ìµœê·¼ {len(recent)}ê°œ ìƒì„± ê¸°ë¡:\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for gen in reversed(recent):  # ìµœì‹ ìˆœ\n",
    "            print(f\"ID: {gen.get('generation_id', 'Unknown')}\")\n",
    "            print(f\"ì‹œë“œ: {gen.get('seed', 'Unknown')}\")\n",
    "            print(f\"ì‹œê°„: {gen.get('timestamp', 'Unknown')}\")\n",
    "            print(f\"í”„ë¡¬í”„íŠ¸: {gen.get('prompt', 'Unknown')[:60]}...\")\n",
    "            if gen.get('image_path'):\n",
    "                print(f\"íŒŒì¼: {gen.get('image_path')}\")\n",
    "            print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757069488465,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "kzk0UUpl0XRh",
    "outputId": "e13a763a-d217-4a5e-9fe4-62ad8e5196e4"
   },
   "outputs": [],
   "source": [
    "# ì „ì—­ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤\n",
    "gen_manager = ImageGenerationManager()\n",
    "\n",
    "# ê¸°ì¡´ í•¨ìˆ˜ ê°œì„  (ë©”íƒ€ë°ì´í„° ìë™ ì €ì¥)\n",
    "def enhanced_face_generation(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                           num_inference_steps=30, guidance_scale=7.5,\n",
    "                           save_path=None, show_image=True, auto_save_history=True):\n",
    "    \"\"\"íˆìŠ¤í† ë¦¬ ì €ì¥ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
    "\n",
    "    # ê¸°ì¡´ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    image = alternative_face_generation(\n",
    "        pipe=pipe,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        seed=seed,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        save_path=save_path,\n",
    "        show_image=show_image\n",
    "    )\n",
    "\n",
    "    # íˆìŠ¤í† ë¦¬ ìë™ ì €ì¥\n",
    "    if image and auto_save_history:\n",
    "        metadata = {\n",
    "            \"prompt\": prompt,\n",
    "            \"negative_prompt\": negative_prompt,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": num_inference_steps,\n",
    "            \"guidance_scale\": guidance_scale,\n",
    "            \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "        }\n",
    "\n",
    "        generation_id = gen_manager.save_generation(metadata, save_path)\n",
    "        print(f\"íˆìŠ¤í† ë¦¬ ì €ì¥ë¨ (ID: {generation_id})\")\n",
    "\n",
    "    return image\n",
    "\n",
    "def find_similar_faces_auto(pipe, reference_image_path, target_score=0.7, max_attempts=100, target_count=3):\n",
    "    \"\"\"ìë™ìœ¼ë¡œ ìœ ì‚¬í•œ ì–¼êµ´ ì´ë¯¸ì§€ ì°¾ê¸°\"\"\"\n",
    "\n",
    "    # í‰ê°€ê¸°ì™€ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”\n",
    "    evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "    prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "\n",
    "    # ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "    print(f\"ê°ì§€ëœ ì–¼êµ´ íŠ¹ì§•: {features}\")\n",
    "    print(f\"ìƒì„±ëœ ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ ìˆ˜: {len(smart_prompts)}\")\n",
    "\n",
    "    found_images = []\n",
    "    attempt_count = 0\n",
    "\n",
    "    # ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces, bad hands\"\n",
    "\n",
    "    print(f\"ëª©í‘œ: {target_count}ê°œ ì´ë¯¸ì§€ (ì ìˆ˜ {target_score} ì´ìƒ)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while len(found_images) < target_count and attempt_count < max_attempts:\n",
    "        attempt_count += 1\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ ì„ íƒ (ìˆœí™˜ ë˜ëŠ” ëœë¤)\n",
    "        prompt_idx = (attempt_count - 1) % len(smart_prompts)\n",
    "        current_prompt = smart_prompts[prompt_idx]\n",
    "\n",
    "        # ëœë¤ ì‹œë“œ\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\nì‹œë„ {attempt_count}/{max_attempts}\")\n",
    "        print(f\"í”„ë¡¬í”„íŠ¸: {current_prompt}\")\n",
    "        print(f\"ì‹œë“œ: {seed}\")\n",
    "\n",
    "        try:\n",
    "            # ì´ë¯¸ì§€ ìƒì„±\n",
    "            generated_image = alternative_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False  # ë°°ì¹˜ ì²˜ë¦¬ì‹œ í™”ë©´ ì¶œë ¥ ë„ê¸°\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                continue\n",
    "\n",
    "            # ìœ ì‚¬ë„ í‰ê°€\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "            total_score = scores['total_score']\n",
    "\n",
    "            print(f\"ì ìˆ˜: {total_score:.3f} (ì–¼êµ´: {scores['face_similarity']:.3f}, LPIPS: {scores['lpips_similarity']:.3f})\")\n",
    "\n",
    "            # ëª©í‘œ ì ìˆ˜ ë‹¬ì„±ì‹œ ì €ì¥\n",
    "            if total_score >= target_score:\n",
    "                print(f\"âœ… ëª©í‘œ ë‹¬ì„±! (ì ìˆ˜: {total_score:.3f})\")\n",
    "\n",
    "                # ì´ë¯¸ì§€ ì €ì¥\n",
    "                save_path = f\"similar_face_{len(found_images)+1:02d}_score_{total_score:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                found_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path\n",
    "                })\n",
    "\n",
    "                # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(found_images)} (Score: {total_score:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"íƒìƒ‰ ì™„ë£Œ!\")\n",
    "    print(f\"ì‹œë„ íšŸìˆ˜: {attempt_count}\")\n",
    "    print(f\"ë°œê²¬ëœ ì´ë¯¸ì§€: {len(found_images)}ê°œ\")\n",
    "\n",
    "    if found_images:\n",
    "        print(\"\\në°œê²¬ëœ ì´ë¯¸ì§€ ì •ë³´:\")\n",
    "        for i, result in enumerate(found_images):\n",
    "            print(f\"{i+1}. ì ìˆ˜: {result['scores']['total_score']:.3f}, ê²½ë¡œ: {result['path']}\")\n",
    "\n",
    "    return found_images\n",
    "\n",
    "print(\"ì´ë¯¸ì§€ ìƒì„± ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1757069488467,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "6254H8xj0XRh"
   },
   "outputs": [],
   "source": [
    "# ëŒ€ëŸ‰ ì¬ìƒì„± í•¨ìˆ˜\n",
    "def regenerate_favorites(pipe, generation_ids):\n",
    "    \"\"\"ì¦ê²¨ì°¾ê¸° ì´ë¯¸ì§€ë“¤ ì¬ìƒì„±\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for gen_id in generation_ids:\n",
    "        print(f\"\\nì¬ìƒì„± ì¤‘: ID {gen_id}\")\n",
    "        image = gen_manager.regenerate_by_id(gen_id, pipe, save_new=True)\n",
    "        if image:\n",
    "            results.append({\"id\": gen_id, \"image\": image})\n",
    "\n",
    "    return results\n",
    "\n",
    "# ë°°ì¹˜ ìƒì„± í•¨ìˆ˜\n",
    "def batch_generate_images(pipe, prompts, base_negative=None, seeds=None, save_folder=None):\n",
    "    \"\"\"ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¡œ ë°°ì¹˜ ìƒì„±\"\"\"\n",
    "\n",
    "    if save_folder is not None:\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    if isinstance(prompts, str):\n",
    "        prompts = [prompts]\n",
    "\n",
    "    if seeds is None:\n",
    "        seeds = [random.randint(1, 99999999) for _ in prompts]\n",
    "    elif len(seeds) < len(prompts):\n",
    "        seeds = seeds + [random.randint(1, 99999999) for _ in range(len(prompts) - len(seeds))]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, (prompt, seed) in enumerate(zip(prompts, seeds)):\n",
    "        print(f\"ìƒì„± {i+1}/{len(prompts)} (ì‹œë“œ: {seed})\")\n",
    "\n",
    "        save_path = None\n",
    "        if save_folder is not None:\n",
    "            save_path = f\"{save_folder}/image_{i+1:03d}_seed_{seed}.png\"\n",
    "\n",
    "        image = enhanced_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=prompt,\n",
    "            negative_prompt=base_negative,\n",
    "            seed=seed,\n",
    "            save_path=save_path,\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if image:\n",
    "            results.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"seed\": seed,\n",
    "                \"image\": image,\n",
    "                \"path\": save_path\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UehYd9h0XRi"
   },
   "source": [
    "# ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ ì‚¬ìš© ë°©ë²•\n",
    "\n",
    "## 1. ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± (íˆìŠ¤í† ë¦¬ ìë™ ì €ì¥)\n",
    "```python\n",
    "# ê¸°ë³¸ ìƒì„±\n",
    "image = enhanced_face_generation(\n",
    "    pipe=pipe,\n",
    "    prompt=\"young Asian woman, professional portrait, natural lighting\",\n",
    "    negative_prompt=\"blurry, low quality, bad anatomy\",\n",
    "    seed=12345,\n",
    "    save_path=\"test_portrait.png\"\n",
    ")\n",
    "```\n",
    "\n",
    "## 2. ë³¸ì¸ ì‚¬ì§„ ê¸°ë°˜ ìœ ì‚¬ ì´ë¯¸ì§€ ìë™ íƒìƒ‰\n",
    "```python\n",
    "# ì°¸ì¡° ì‚¬ì§„ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ ì‚¬ì§„)\n",
    "reference_photo = \"my_reference_photo.jpg\"\n",
    "\n",
    "# ìë™ íƒìƒ‰ ì‹¤í–‰\n",
    "similar_faces = find_similar_faces_auto(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=reference_photo,\n",
    "    target_score=0.65,  # 65% ì´ìƒ ìœ ì‚¬\n",
    "    max_attempts=50,    # ìµœëŒ€ 50ë²ˆ ì‹œë„\n",
    "    target_count=3      # 3ê°œ ì°¾ìœ¼ë©´ ì¢…ë£Œ\n",
    ")\n",
    "```\n",
    "\n",
    "## 3. íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
    "```python\n",
    "# íˆìŠ¤í† ë¦¬ ë³´ê¸°\n",
    "gen_manager.show_history(limit=5)\n",
    "\n",
    "# ê²€ìƒ‰\n",
    "results = gen_manager.search_generations(keyword=\"portrait\")\n",
    "seed_results = gen_manager.search_generations(seed=12345)\n",
    "\n",
    "# ì¬ìƒì„±\n",
    "regenerated = gen_manager.regenerate_by_id(generation_id=3, pipe=pipe)\n",
    "```\n",
    "\n",
    "## 4. ë°°ì¹˜ ìƒì„±\n",
    "```python\n",
    "prompts = [\n",
    "    \"professional headshot, business attire\",\n",
    "    \"casual portrait, outdoor lighting\",\n",
    "    \"artistic portrait, dramatic lighting\"\n",
    "]\n",
    "\n",
    "batch_results = batch_generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts=prompts,\n",
    "    base_negative=\"blurry, low quality, bad anatomy\",\n",
    "    save_folder=\"batch_portraits\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1757069488484,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "4-oKvAGS0XRi"
   },
   "outputs": [],
   "source": [
    "# # í…ŒìŠ¤íŠ¸: ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±\n",
    "# test_prompt = \"young Asian woman, professional portrait, natural lighting, high quality\"\n",
    "# test_negative = \"blurry, low quality, bad anatomy, deformed, cartoon, anime\"\n",
    "\n",
    "# test_image = enhanced_face_generation(\n",
    "#     pipe=pipe,\n",
    "#     prompt=test_prompt,\n",
    "#     negative_prompt=test_negative,\n",
    "#     seed=42,\n",
    "#     save_path=\"test_generation.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559,
     "referenced_widgets": [
      "fd2c322f12a14b368ed84092547f681f",
      "ff1d0668e9684b85ab16b24dcd3703bf",
      "b104756fe989454f88239e65e1a3a28c",
      "ece2eff5bc114c91ac0d89c13e248ddd",
      "48a00a2e7ac8415cba5d9570d2d1f51e",
      "b2f72d9d1f91471693f452f15334f547",
      "479ddc7377384e8885372d04ba5dfa73",
      "a3875881d459467a8ff80f2cee976635",
      "59bca1f7eb5046d1b735b5087ef0708d",
      "b63a628733394f5ab2e4453923a8cff6",
      "b96275ce2c8348058d5ae81f400fbc82"
     ]
    },
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1757069606180,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "KWXROcOA2cpP",
    "outputId": "5aec2f24-e2fb-4205-9515-b4b55cc4866c"
   },
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ ì‹¤í–‰ (í†µí•© í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "if helper.is_colab:\n",
    "    reference_photo = \"/content/drive/MyDrive/homepage/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜/ìŠ¤í”„ë¦°íŠ¸ë¯¸ì…˜_ì‘ì—…ì¤‘/test.png\"\n",
    "else:\n",
    "    reference_photo = \"test.png\"\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "if not os.path.exists(reference_photo):\n",
    "    print(f\"âŒ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_photo}\")\n",
    "    print(\"í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ ëª©ë¡:\")\n",
    "    for file in os.listdir('.'):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  - {file}\")\n",
    "else:\n",
    "    print(f\"âœ… ì°¸ì¡° ì´ë¯¸ì§€ í™•ì¸: {reference_photo}\")\n",
    "\n",
    "    # í†µí•© ìë™ íƒìƒ‰ ì‹¤í–‰ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "    try:\n",
    "        similar_faces = find_similar_faces_auto_enhanced(\n",
    "            pipe=pipe,\n",
    "            reference_image_path=reference_photo,\n",
    "            target_score=0.6,\n",
    "            max_attempts=30,\n",
    "            target_count=2,\n",
    "            age_group=\"30ëŒ€\",\n",
    "            gender=\"ë‚¨ì„±\",\n",
    "            ethnicity=\"ë°±ì¸\",\n",
    "            use_opencv_fallback=True  # ìë™ ë°±ì—… í™œì„±í™”\n",
    "        )\n",
    "\n",
    "        if similar_faces:\n",
    "            print(f\"\\nğŸ‰ {len(similar_faces)}ê°œì˜ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "        # ê¸°ë³¸ ìƒì„± í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)\n",
    "        print(\"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸...\")\n",
    "        test_image = enhanced_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=\"professional portrait, high quality, realistic\",\n",
    "            seed=42\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310_recommand_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0322d0ac3c50446594dd6754e4068241": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a1fbfb73b124332873f36584d894da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bd0dfd9b7804e61be99e2e43a8e4f21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e83df493cab467abe97477dd4b765cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c3bec2af7a492f9e659cb644fe6e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1221f3d8061943e395f0517c2bb0ba3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "144506bedbdd4755a5a94a0257100323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "146f96d250c3474f89d5497506dadc1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "152011fa31a344e985e8b4ebe6c0070b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1892b885c9f3473ba320f52e687ed4b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d00dd16c0c424e779d55f932a522de1d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1221f3d8061943e395f0517c2bb0ba3b",
      "value": "100%"
     }
    },
    "2cde21101bff44979b3ed02110617631": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e901af9a07345c8b8307a5f2c06c2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a79a6bb4574aa58aa478c99641fce9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40b8af3da4e84acf8ae9db69c8b7e34f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "479ddc7377384e8885372d04ba5dfa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48a00a2e7ac8415cba5d9570d2d1f51e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b06d29e4e94b8da5beb45c6056dac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5738ff9c88d04c79a193a5e63a89927d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b44ec25194b54084b90283695fa10a5f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fb1ebbd7fec24bed86805105f33babc1",
      "value": "â€‡20/20â€‡[00:02&lt;00:00,â€‡â€‡9.00it/s]"
     }
    },
    "59bca1f7eb5046d1b735b5087ef0708d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b9024b085ef47a69cf529c626a6c356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1892b885c9f3473ba320f52e687ed4b9",
       "IPY_MODEL_a8ce3f62c420440091a27a5793643b84",
       "IPY_MODEL_a32142681ece4dac8a9614442a929ac4"
      ],
      "layout": "IPY_MODEL_31a79a6bb4574aa58aa478c99641fce9"
     }
    },
    "69a0b86664244c4f9ec1b8ba1c66dd2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5728f8f34f24fd683a347068191f787",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd074d0a8cbd44d3ba698ff83f6d8dea",
      "value": "â€‡6/6â€‡[00:00&lt;00:00,â€‡â€‡7.90it/s]"
     }
    },
    "6f63fcd64d9b42e9b9db0ab247ea3652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e901af9a07345c8b8307a5f2c06c2bb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_144506bedbdd4755a5a94a0257100323",
      "value": "Loadingâ€‡pipelineâ€‡components...:â€‡100%"
     }
    },
    "795836e6dff14890aa75c7c6db2d8318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9258181299a348bd9a1fe7ca0687a0ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92b416e643294aa9835e8b841ea42cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_152011fa31a344e985e8b4ebe6c0070b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_795836e6dff14890aa75c7c6db2d8318",
      "value": "100%"
     }
    },
    "96359f7dabaf47f5aa5ea6391db64133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bd0dfd9b7804e61be99e2e43a8e4f21",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb25a9991f59443e87dd0dbfcfac06e2",
      "value": 6
     }
    },
    "99752028c0cf497d9540c51a55852cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb071adc9054464b951716ff6b68fd44",
       "IPY_MODEL_96359f7dabaf47f5aa5ea6391db64133",
       "IPY_MODEL_69a0b86664244c4f9ec1b8ba1c66dd2a"
      ],
      "layout": "IPY_MODEL_9258181299a348bd9a1fe7ca0687a0ab"
     }
    },
    "99b724cf124e4a739106bf0f5d2ac665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9cd78b5bebc442cea7600d375204bc9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32142681ece4dac8a9614442a929ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cde21101bff44979b3ed02110617631",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_146f96d250c3474f89d5497506dadc1c",
      "value": "â€‡30/30â€‡[00:01&lt;00:00,â€‡15.84it/s]"
     }
    },
    "a3875881d459467a8ff80f2cee976635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4a2fd815d034542a243a342823da200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8ce3f62c420440091a27a5793643b84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0f5643c47c342dd897008e86771c9cb",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4a2fd815d034542a243a342823da200",
      "value": 30
     }
    },
    "ac3f515f265e4880b1772c3274695e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd761716247648c0aa57cf756c6b0f7b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0e83df493cab467abe97477dd4b765cb",
      "value": "â€‡7/7â€‡[00:00&lt;00:00,â€‡â€‡7.23it/s]"
     }
    },
    "ad9c37d16de04dab8ced57639bf4c58f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55b06d29e4e94b8da5beb45c6056dac8",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99b724cf124e4a739106bf0f5d2ac665",
      "value": 20
     }
    },
    "b0f5643c47c342dd897008e86771c9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b104756fe989454f88239e65e1a3a28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3875881d459467a8ff80f2cee976635",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59bca1f7eb5046d1b735b5087ef0708d",
      "value": 30
     }
    },
    "b1d5c8d9fd5644bba6363bbd87d313fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2f72d9d1f91471693f452f15334f547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44ec25194b54084b90283695fa10a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63a628733394f5ab2e4453923a8cff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b96275ce2c8348058d5ae81f400fbc82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb071adc9054464b951716ff6b68fd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40b8af3da4e84acf8ae9db69c8b7e34f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0a1fbfb73b124332873f36584d894da6",
      "value": "Loadingâ€‡pipelineâ€‡components...:â€‡100%"
     }
    },
    "bb25a9991f59443e87dd0dbfcfac06e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bdbb6d528d4949159dcd3fd07f0e0075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f63fcd64d9b42e9b9db0ab247ea3652",
       "IPY_MODEL_f8ed5f9bb8004cea83322ae7519c721e",
       "IPY_MODEL_ac3f515f265e4880b1772c3274695e75"
      ],
      "layout": "IPY_MODEL_9cd78b5bebc442cea7600d375204bc9a"
     }
    },
    "cd074d0a8cbd44d3ba698ff83f6d8dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cee7cecaeb5248779aeb5bbae068d605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92b416e643294aa9835e8b841ea42cfd",
       "IPY_MODEL_ad9c37d16de04dab8ced57639bf4c58f",
       "IPY_MODEL_5738ff9c88d04c79a193a5e63a89927d"
      ],
      "layout": "IPY_MODEL_11c3bec2af7a492f9e659cb644fe6e4e"
     }
    },
    "d00dd16c0c424e779d55f932a522de1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5728f8f34f24fd683a347068191f787": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ece2eff5bc114c91ac0d89c13e248ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b63a628733394f5ab2e4453923a8cff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b96275ce2c8348058d5ae81f400fbc82",
      "value": "â€‡30/30â€‡[00:01&lt;00:00,â€‡15.55it/s]"
     }
    },
    "f8ed5f9bb8004cea83322ae7519c721e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0322d0ac3c50446594dd6754e4068241",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1d5c8d9fd5644bba6363bbd87d313fe",
      "value": 7
     }
    },
    "fb1ebbd7fec24bed86805105f33babc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd2c322f12a14b368ed84092547f681f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff1d0668e9684b85ab16b24dcd3703bf",
       "IPY_MODEL_b104756fe989454f88239e65e1a3a28c",
       "IPY_MODEL_ece2eff5bc114c91ac0d89c13e248ddd"
      ],
      "layout": "IPY_MODEL_48a00a2e7ac8415cba5d9570d2d1f51e"
     }
    },
    "fd761716247648c0aa57cf756c6b0f7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff1d0668e9684b85ab16b24dcd3703bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2f72d9d1f91471693f452f15334f547",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_479ddc7377384e8885372d04ba5dfa73",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
