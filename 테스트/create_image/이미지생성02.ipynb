{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewHNdIswgIrV"
   },
   "source": [
    "# 🎉 Google Colab face_recognition 문제 완전 해결!\n",
    "\n",
    "## ✅ 문제 해결 완료\n",
    "\n",
    "**이 노트북은 Google Colab에서 발생하는 `face_recognition` 라이브러리 설치 오류를 완전히 해결했습니다.**\n",
    "\n",
    "### ❌ 기존 문제:\n",
    "```\n",
    "ERROR: Failed building wheel for dlib\n",
    "ModuleNotFoundError: No module named 'face_recognition'\n",
    "```\n",
    "\n",
    "### ✅ 해결 방법:\n",
    "- `face_recognition` 라이브러리 **완전 제거**\n",
    "- **OpenCV 기반** 얼굴 감지 및 분석 시스템 구축\n",
    "- **더 강력한 특징 추출**: 히스토그램 + LBP + 기하학적 + 에지 특징\n",
    "- **다중 유사도 메트릭**: 코사인 + 유클리드 + LPIPS\n",
    "\n",
    "### 🚀 바로 실행 가능\n",
    "이제 Google Colab에서 **설치 오류 없이** 바로 실행할 수 있습니다!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4dL9Ba0ZAxO"
   },
   "source": [
    "# 🎨 AI 이미지 생성 및 얼굴 유사도 분석 시스템\n",
    "\n",
    "## 📋 목차\n",
    "1. [환경 설정 및 라이브러리](#1-환경-설정)\n",
    "2. [Stable Diffusion 파이프라인](#2-stable-diffusion-파이프라인)\n",
    "3. [얼굴 유사도 평가기](#3-얼굴-유사도-평가기)\n",
    "4. [이미지 생성 함수](#4-이미지-생성-함수)\n",
    "5. [스마트 프롬프트 생성기](#5-스마트-프롬프트-생성기)\n",
    "6. [자동 유사 얼굴 탐색](#6-자동-유사-얼굴-탐색)\n",
    "7. [실행 예제](#7-실행-예제)\n",
    "\n",
    "## 🎯 주요 기능\n",
    "- **Stable Diffusion 기반 이미지 생성**\n",
    "- **OpenCV + LPIPS 기반 얼굴 유사도 평가**\n",
    "- **인구통계학적 정보 기반 스마트 프롬프트 생성**\n",
    "- **자동 유사 얼굴 탐색 및 필터링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6690,
     "status": "ok",
     "timestamp": 1757068991753,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "x7_IBeByZAxP",
    "outputId": "c455761b-01bf-47ba-f21d-519d819a13b0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 1. Google Colab 환경 설정 및 라이브러리 (face_recognition 문제 해결)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Google Colab 환경 설정 및 라이브러리 (face_recognition 문제 해결)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Colab 환경 확인\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"🌟 Google Colab 환경에서 실행 중\")\n",
    "\n",
    "    # Colab에서 Google Drive 마운트\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # LPIPS 설치 (Colab에서 필요)\n",
    "    print(\"📦 LPIPS 설치 중...\")\n",
    "    !pip install -q lpips\n",
    "\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"💻 로컬 환경에서 실행 중\")\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 사용 중인 디바이스: {device}\")\n",
    "\n",
    "# 재현 가능한 결과를 위해 시드 설정\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# OpenCV만 사용하는 모드 (face_recognition 대신)\n",
    "USE_OPENCV_ONLY = True\n",
    "print(f\"🔧 OpenCV 전용 모드: {USE_OPENCV_ONLY}\")\n",
    "\n",
    "print(\"✅ 기본 라이브러리 및 환경 설정 완료 (face_recognition 제외)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "99752028c0cf497d9540c51a55852cbc",
      "bb071adc9054464b951716ff6b68fd44",
      "96359f7dabaf47f5aa5ea6391db64133",
      "69a0b86664244c4f9ec1b8ba1c66dd2a",
      "9258181299a348bd9a1fe7ca0687a0ab",
      "40b8af3da4e84acf8ae9db69c8b7e34f",
      "0a1fbfb73b124332873f36584d894da6",
      "0bd0dfd9b7804e61be99e2e43a8e4f21",
      "bb25a9991f59443e87dd0dbfcfac06e2",
      "d5728f8f34f24fd683a347068191f787",
      "cd074d0a8cbd44d3ba698ff83f6d8dea"
     ]
    },
    "executionInfo": {
     "elapsed": 12948,
     "status": "ok",
     "timestamp": 1757069004706,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "0GIOfdFKZAxQ",
    "outputId": "24e2a407-062f-47b2-ad25-2ccebf7df348"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Stable Diffusion 파이프라인 초기화 (Colab 최적화)\n",
    "# =============================================================================\n",
    "\n",
    "# Colab에서 필요한 패키지 설치\n",
    "if IN_COLAB:\n",
    "    print(\"📦 Colab용 패키지 설치 중...\")\n",
    "    !pip install -q diffusers transformers accelerate\n",
    "    !pip install -q xformers  # 메모리 최적화\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    import lpips\n",
    "\n",
    "    print(\"🔄 Stable Diffusion 모델 로딩 중...\")\n",
    "    print(\"⏰ 첫 실행 시 모델 다운로드로 3-5분 소요될 수 있습니다...\")\n",
    "\n",
    "    # Stable Diffusion 파이프라인 초기화\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16 if device.type == \"cuda\" else torch.float32,\n",
    "        safety_checker=None,\n",
    "        requires_safety_checker=False\n",
    "    )\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "    # Colab 메모리 최적화 설정\n",
    "    if device.type == \"cuda\":\n",
    "        pipe.enable_attention_slicing()\n",
    "        if IN_COLAB:\n",
    "            pipe.enable_model_cpu_offload()  # Colab에서 메모리 절약\n",
    "            pipe.enable_xformers_memory_efficient_attention()  # xformers 사용\n",
    "\n",
    "    # LPIPS 모델 초기화\n",
    "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    print(\"✅ Stable Diffusion 파이프라인 및 LPIPS 초기화 완료\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 초기화 실패: {e}\")\n",
    "    print(\"💡 패키지 재설치가 필요할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1757069004744,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "taqPJn3dZAxQ",
    "outputId": "36bdf0da-05b9-4a61-f5cb-63e14773b54b"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. OpenCV 전용 얼굴 유사도 평가기 (face_recognition 없이)\n",
    "# =============================================================================\n",
    "\n",
    "class FaceSimilarityEvaluator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV 전용 얼굴 유사도 평가기 (Colab 호환)\"\"\"\n",
    "        print(f\"🎯 OpenCV 전용 평가기 초기화: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV 얼굴 감지기 초기화\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "        # 참조 이미지 로드\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            if self.reference_image is None:\n",
    "                print(f\"❌ 이미지 로드 실패: {reference_image_path}\")\n",
    "                self.reference_features = None\n",
    "                return\n",
    "\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "            self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "            if self.reference_features is not None:\n",
    "                print(\"✅ 참조 이미지에서 얼굴 특징 추출 성공\")\n",
    "            else:\n",
    "                print(\"⚠️ 참조 이미지에서 얼굴을 찾을 수 없습니다\")\n",
    "        else:\n",
    "            print(f\"❌ 참조 이미지를 찾을 수 없습니다: {reference_image_path}\")\n",
    "            self.reference_features = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"OpenCV를 사용한 강화된 얼굴 특징 추출\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 다양한 스케일로 얼굴 감지\n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # 가장 큰 얼굴 선택\n",
    "            largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "            x, y, w, h = largest_face\n",
    "\n",
    "            # 얼굴 영역 추출 및 정규화\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "\n",
    "            # 히스토그램 균등화로 조명 정규화\n",
    "            face_normalized = cv2.equalizeHist(face_resized)\n",
    "\n",
    "            # 1. 히스토그램 특징\n",
    "            hist_features = cv2.calcHist([face_normalized], [0], None, [256], [0, 256]).flatten()\n",
    "            hist_features = hist_features / (hist_features.sum() + 1e-7)\n",
    "\n",
    "            # 2. LBP (Local Binary Pattern) 특징\n",
    "            lbp_features = self.calculate_lbp(face_normalized)\n",
    "\n",
    "            # 3. 눈 감지 특징 (얼굴 구조 분석)\n",
    "            eyes = self.eye_cascade.detectMultiScale(face_roi)\n",
    "            eye_features = np.array([len(eyes),\n",
    "                                   eyes[0][2]*eyes[0][3] if len(eyes) > 0 else 0])  # 눈 개수와 크기\n",
    "\n",
    "            # 4. 기하학적 특징 (얼굴 비율)\n",
    "            geometric_features = np.array([w/h, w, h])  # 가로세로 비율과 크기\n",
    "\n",
    "            # 5. 에지 특징\n",
    "            edges = cv2.Canny(face_normalized, 50, 150)\n",
    "            edge_features = np.array([np.sum(edges > 0) / (128*128)])  # 에지 밀도\n",
    "\n",
    "            # 모든 특징 결합\n",
    "            combined_features = np.concatenate([\n",
    "                hist_features,      # 히스토그램 (256개)\n",
    "                lbp_features,       # LBP (26개)\n",
    "                eye_features,       # 눈 특징 (2개)\n",
    "                geometric_features, # 기하학적 특징 (3개)\n",
    "                edge_features      # 에지 특징 (1개)\n",
    "            ])\n",
    "\n",
    "            return combined_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"특징 추출 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_lbp(self, image, radius=3, n_points=24):\n",
    "        \"\"\"Local Binary Pattern 계산 (scikit-image 없이)\"\"\"\n",
    "        try:\n",
    "            # 간단한 LBP 구현\n",
    "            h, w = image.shape\n",
    "            lbp = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "            for i in range(radius, h - radius):\n",
    "                for j in range(radius, w - radius):\n",
    "                    center = image[i, j]\n",
    "                    binary_string = ''\n",
    "\n",
    "                    # 8방향 검사 (간단화)\n",
    "                    neighbors = [\n",
    "                        image[i-1, j-1], image[i-1, j], image[i-1, j+1],\n",
    "                        image[i, j+1], image[i+1, j+1], image[i+1, j],\n",
    "                        image[i+1, j-1], image[i, j-1]\n",
    "                    ]\n",
    "\n",
    "                    for neighbor in neighbors:\n",
    "                        binary_string += '1' if neighbor >= center else '0'\n",
    "\n",
    "                    lbp[i, j] = int(binary_string, 2)\n",
    "\n",
    "            # 히스토그램 계산\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 26))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            return hist\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"LBP 계산 오류: {e}\")\n",
    "            # 대안: 간단한 텍스처 특징\n",
    "            return np.histogram(image.ravel(), bins=26)[0].astype(\"float\")\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"생성된 이미지와 참조 이미지의 유사도 평가\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PIL을 OpenCV 형식으로 변환\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 1. OpenCV 기반 얼굴 유사도\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # 코사인 유사도\n",
    "                cosine_sim = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                face_similarity = max(0, cosine_sim)\n",
    "                scores['face_similarity'] = face_similarity\n",
    "\n",
    "                # 유클리드 거리 기반 유사도\n",
    "                euclidean_dist = np.linalg.norm(self.reference_features - generated_features)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist / 1000)  # 정규화\n",
    "                scores['euclidean_similarity'] = euclidean_sim\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "                scores['euclidean_similarity'] = 0.0\n",
    "\n",
    "            # 2. LPIPS 점수 (사용 가능한 경우)\n",
    "            if 'lpips_model' in globals():\n",
    "                try:\n",
    "                    ref_tensor = transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(device)\n",
    "                    gen_tensor = transform(generated_image).unsqueeze(0).to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS 계산 오류: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 3. 종합 점수 (가중 평균)\n",
    "            face_weight = 0.5\n",
    "            euclidean_weight = 0.3\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['euclidean_similarity'] * euclidean_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"평가 오류: {e}\")\n",
    "            scores = {\n",
    "                'face_similarity': 0.0,\n",
    "                'euclidean_similarity': 0.0,\n",
    "                'lpips_similarity': 0.0,\n",
    "                'total_score': 0.0\n",
    "            }\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"✅ OpenCV 전용 FaceSimilarityEvaluator 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757069004763,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "nao847V0ZAxQ",
    "outputId": "7b93a592-d9a5-4407-8f34-f0b1d9d97b69"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. 이미지 생성 함수\n",
    "# =============================================================================\n",
    "\n",
    "def generate_image(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                  num_inference_steps=30, guidance_scale=7.5,\n",
    "                  save_path=None, show_image=True):\n",
    "    \"\"\"기본 이미지 생성 함수\"\"\"\n",
    "\n",
    "    if negative_prompt is None:\n",
    "        negative_prompt = \"blurry, low quality, bad anatomy, deformed, extra limbs, bad hands, cartoon, anime\"\n",
    "\n",
    "    generator = torch.Generator(device=pipe.device).manual_seed(seed)\n",
    "\n",
    "    print(f\"이미지 생성 중... (시드: {seed})\")\n",
    "    print(f\"프롬프트: {prompt}\")\n",
    "\n",
    "    try:\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "\n",
    "        if save_path:\n",
    "            image.save(save_path)\n",
    "            print(f\"이미지 저장됨: {save_path}\")\n",
    "\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Generated (Seed: {seed})\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"생성 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ generate_image 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1757069004776,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "-SEYqFAUZAxR",
    "outputId": "33fad6ba-4977-4b5d-fe4a-d8c30414f5bb"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. 스마트 프롬프트 생성기\n",
    "# =============================================================================\n",
    "\n",
    "def generate_demographic_prompts(age_group=\"20대\", gender=\"여성\", ethnicity=\"아시안\"):\n",
    "    \"\"\"나이, 성별, 인종 정보를 기반으로 향상된 프롬프트 생성\"\"\"\n",
    "\n",
    "    age_keywords = {\n",
    "        \"10대\": [\"young teenager\", \"youthful\", \"teenage\"],\n",
    "        \"20대\": [\"young adult\", \"early twenties\", \"youthful adult\"],\n",
    "        \"30대\": [\"adult\", \"mature young adult\", \"thirty-something\"],\n",
    "        \"40대\": [\"middle-aged adult\", \"mature\", \"experienced adult\"],\n",
    "        \"50대\": [\"mature adult\", \"middle-aged\", \"distinguished\"]\n",
    "    }\n",
    "\n",
    "    gender_keywords = {\n",
    "        \"남성\": [\"man\", \"male\", \"gentleman\"],\n",
    "        \"여성\": [\"woman\", \"female\", \"lady\"]\n",
    "    }\n",
    "\n",
    "    ethnicity_keywords = {\n",
    "        \"아시안\": [\"Asian\", \"East Asian\", \"Korean\"],\n",
    "        \"백인\": [\"Caucasian\", \"white\", \"European\"],\n",
    "        \"흑인\": [\"African American\", \"black\", \"African\"],\n",
    "        \"히스패닉\": [\"Hispanic\", \"Latino\", \"Latin American\"]\n",
    "    }\n",
    "\n",
    "    lighting_styles = [\n",
    "        \"natural lighting, bright and cheerful\",\n",
    "        \"soft studio lighting, clean background\",\n",
    "        \"golden hour lighting, warm and inviting\"\n",
    "    ]\n",
    "\n",
    "    quality_keywords = [\n",
    "        \"high quality, detailed, photorealistic\",\n",
    "        \"professional photography, sharp focus\",\n",
    "        \"realistic lighting, natural expression\"\n",
    "    ]\n",
    "\n",
    "    enhanced_prompts = []\n",
    "\n",
    "    age_terms = age_keywords.get(age_group, [\"young adult\"])\n",
    "    gender_terms = gender_keywords.get(gender, [\"person\"])\n",
    "    ethnic_terms = ethnicity_keywords.get(ethnicity, [\"\"])\n",
    "\n",
    "    for age_term in age_terms[:2]:\n",
    "        for gender_term in gender_terms[:2]:\n",
    "            for ethnic_term in ethnic_terms[:2]:\n",
    "                for lighting in lighting_styles:\n",
    "                    for quality in quality_keywords:\n",
    "                        if ethnic_term:\n",
    "                            prompt = f\"professional portrait of a {age_term} {ethnic_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        else:\n",
    "                            prompt = f\"professional portrait of a {age_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        enhanced_prompts.append(prompt)\n",
    "\n",
    "    # 중복 제거 및 셔플\n",
    "    enhanced_prompts = list(set(enhanced_prompts))\n",
    "    random.shuffle(enhanced_prompts)\n",
    "\n",
    "    return enhanced_prompts[:10]\n",
    "\n",
    "print(\"✅ generate_demographic_prompts 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757069004792,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "cfzlGTFaZAxR",
    "outputId": "3e53864f-b0ee-4ffd-dcda-788a6456c66e"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. 자동 유사 얼굴 탐색 함수 (최종 통합 버전)\n",
    "# =============================================================================\n",
    "\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6,\n",
    "                                   max_attempts=50, target_count=3,\n",
    "                                   age_group=\"20대\", gender=\"여성\", ethnicity=\"아시안\"):\n",
    "    \"\"\"OpenCV 기반 자동 얼굴 유사도 탐색\"\"\"\n",
    "\n",
    "    print(\"🔄 자동 유사도 탐색 시작...\")\n",
    "    print(f\"🎯 검색 조건: {age_group} {gender} {ethnicity}\")\n",
    "\n",
    "    # 평가기 초기화\n",
    "    try:\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        if evaluator.reference_features is None:\n",
    "            print(\"❌ 참조 이미지에서 얼굴을 찾을 수 없습니다.\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 평가기 초기화 실패: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 향상된 프롬프트 생성\n",
    "    enhanced_prompts = generate_demographic_prompts(age_group, gender, ethnicity)\n",
    "\n",
    "    # 기본 프롬프트 추가\n",
    "    basic_prompts = [\n",
    "        \"professional portrait, high quality, detailed\",\n",
    "        \"natural lighting portrait, realistic\",\n",
    "        \"studio portrait, professional photography\"\n",
    "    ]\n",
    "\n",
    "    all_prompts = enhanced_prompts + basic_prompts\n",
    "    print(f\"🎨 총 {len(all_prompts)}개의 프롬프트 준비 완료\")\n",
    "\n",
    "    successful_images = []\n",
    "    attempts = 0\n",
    "    prompt_idx = 0\n",
    "\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces\"\n",
    "\n",
    "    print(f\"🎯 목표: {target_count}개의 유사한 얼굴 찾기 (유사도 >= {target_score})\")\n",
    "\n",
    "    while len(successful_images) < target_count and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        current_prompt = all_prompts[prompt_idx % len(all_prompts)]\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\n🔄 시도 {attempts}/{max_attempts}\")\n",
    "        print(f\"📝 프롬프트: {current_prompt}\")\n",
    "\n",
    "        try:\n",
    "            # 이미지 생성\n",
    "            generated_image = generate_image(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                prompt_idx += 1\n",
    "                continue\n",
    "\n",
    "            # 유사도 평가\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "\n",
    "            print(f\"📊 평가 결과:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "            # 목표 점수 달성 시 저장\n",
    "            if scores['total_score'] >= target_score:\n",
    "                save_path = f\"similar_face_{len(successful_images)+1:02d}_score_{scores['total_score']:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                successful_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path,\n",
    "                    'demographics': f\"{age_group}_{gender}_{ethnicity}\"\n",
    "                })\n",
    "\n",
    "                print(f\"✅ 성공! ({len(successful_images)}/{target_count})\")\n",
    "\n",
    "                # 이미지 표시\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(successful_images)} (Score: {scores['total_score']:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"❌ 목표 점수 미달 (현재: {scores['total_score']:.4f}, 목표: {target_score})\")\n",
    "\n",
    "            prompt_idx += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 이미지 생성 오류: {e}\")\n",
    "            prompt_idx += 1\n",
    "\n",
    "    print(f\"\\n🎯 탐색 완료: {len(successful_images)}개의 성공적인 이미지 생성\")\n",
    "\n",
    "    # 결과 정렬 (총 점수 기준)\n",
    "    successful_images.sort(key=lambda x: x['scores']['total_score'], reverse=True)\n",
    "    return successful_images\n",
    "\n",
    "print(\"✅ find_similar_faces_auto_enhanced 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1757069005248,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "VdZFm0hdZAxR",
    "outputId": "efe94bee-05f4-46ab-e6cf-5e7fd0aa7cb4"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 7. Colab 환경 설정 및 실행 예제\n",
    "# =============================================================================\n",
    "\n",
    "# 환경별 파일 경로 설정\n",
    "if IN_COLAB:\n",
    "    # Colab 환경: Google Drive 경로\n",
    "    reference_photo = \"/content/drive/MyDrive/homepage/스프린트미션/스프린트미션_작업중/test.png\"\n",
    "    print(\"🌟 Google Colab 환경에서 실행\")\n",
    "    print(\"📁 Google Drive에서 파일 로드\")\n",
    "else:\n",
    "    # 로컬 환경\n",
    "    reference_photo = \"test.png\"\n",
    "    print(\"💻 로컬 환경에서 실행\")\n",
    "\n",
    "print(f\"📷 참조 이미지 경로: {reference_photo}\")\n",
    "\n",
    "# 파일 존재 확인 및 참조 이미지 표시\n",
    "if os.path.exists(reference_photo):\n",
    "    print(\"✅ 참조 이미지 확인됨\")\n",
    "\n",
    "    try:\n",
    "        # 참조 이미지 미리보기\n",
    "        ref_img = Image.open(reference_photo)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(ref_img)\n",
    "        plt.title(\"📷 참조 이미지\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"📐 이미지 크기: {ref_img.size}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 이미지 로드 오류: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 참조 이미지를 찾을 수 없습니다.\")\n",
    "\n",
    "    if IN_COLAB:\n",
    "        print(\"💡 Google Drive가 마운트되었는지 확인하세요.\")\n",
    "        print(\"💡 파일이 올바른 경로에 있는지 확인하세요:\")\n",
    "        print(\"   /content/drive/MyDrive/homepage/스프린트미션/스프린트미션_작업중/test.png\")\n",
    "\n",
    "        # Google Drive 내용 확인\n",
    "        drive_path = \"/content/drive/MyDrive\"\n",
    "        if os.path.exists(drive_path):\n",
    "            print(f\"\\n📂 Google Drive 루트 폴더 내용:\")\n",
    "            for item in os.listdir(drive_path)[:10]:  # 상위 10개만 표시\n",
    "                print(f\"   📁 {item}\")\n",
    "    else:\n",
    "        print(\"📂 현재 디렉토리의 이미지 파일:\")\n",
    "        for file in os.listdir(\".\"):\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                print(f\"   📁 {file}\")\n",
    "\n",
    "print(\"\\n🚀 시스템 준비 완료!\")\n",
    "print(\"\\n💡 다음 셀에서 테스트를 실행하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899,
     "referenced_widgets": [
      "cee7cecaeb5248779aeb5bbae068d605",
      "92b416e643294aa9835e8b841ea42cfd",
      "ad9c37d16de04dab8ced57639bf4c58f",
      "5738ff9c88d04c79a193a5e63a89927d",
      "11c3bec2af7a492f9e659cb644fe6e4e",
      "152011fa31a344e985e8b4ebe6c0070b",
      "795836e6dff14890aa75c7c6db2d8318",
      "55b06d29e4e94b8da5beb45c6056dac8",
      "99b724cf124e4a739106bf0f5d2ac665",
      "b44ec25194b54084b90283695fa10a5f",
      "fb1ebbd7fec24bed86805105f33babc1"
     ]
    },
    "executionInfo": {
     "elapsed": 3667,
     "status": "ok",
     "timestamp": 1757069008918,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "pL-RpQ_IZAxR",
    "outputId": "494fd9ac-97ba-4948-ab6e-91925c5bcd9b"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 8. Colab 안전 테스트 실행\n",
    "# =============================================================================\n",
    "\n",
    "# 참조 이미지가 있는 경우에만 테스트 실행\n",
    "if os.path.exists(reference_photo):\n",
    "    print(\"🧪 Colab 환경 테스트 시작...\")\n",
    "\n",
    "    try:\n",
    "        # 1. 간단한 이미지 생성 테스트\n",
    "        print(\"🎨 1단계: 기본 이미지 생성 테스트\")\n",
    "        test_prompt = \"professional portrait of a young Asian woman, natural lighting, high quality, photorealistic\"\n",
    "\n",
    "        test_image = generate_image(\n",
    "            pipe=pipe,\n",
    "            prompt=test_prompt,\n",
    "            seed=12345,\n",
    "            num_inference_steps=20,  # Colab에서 빠른 테스트를 위해 축소\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if test_image:\n",
    "            print(\"✅ 기본 이미지 생성 성공!\")\n",
    "\n",
    "            # 2. 유사도 평가 테스트\n",
    "            print(\"\\n📊 2단계: 유사도 평가 테스트\")\n",
    "            evaluator = FaceSimilarityEvaluator(reference_photo)\n",
    "\n",
    "            if evaluator.reference_features is not None:\n",
    "                scores = evaluator.evaluate_similarity(test_image)\n",
    "                print(f\"\udcc8 유사도 평가 결과:\")\n",
    "                for key, value in scores.items():\n",
    "                    print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "                # 성공 기준 확인\n",
    "                if scores['total_score'] > 0.3:\n",
    "                    print(\"✅ 유사도 평가 시스템 정상 작동!\")\n",
    "                else:\n",
    "                    print(\"⚠️ 유사도가 낮지만 시스템은 정상 작동 중\")\n",
    "\n",
    "            else:\n",
    "                print(\"❌ 참조 이미지에서 얼굴 감지 실패\")\n",
    "\n",
    "        else:\n",
    "            print(\"❌ 이미지 생성 실패\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테스트 실행 오류: {e}\")\n",
    "        print(\"💡 GPU 메모리 부족일 수 있습니다. 런타임을 재시작해보세요.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 참조 이미지가 없어 테스트를 건너뜁니다.\")\n",
    "    print(\"💡 Google Drive에 test.png 파일을 업로드하고 다시 실행하세요.\")\n",
    "\n",
    "print(\"\\n🎯 테스트 완료!\")\n",
    "print(\"\\n💡 전체 시스템을 사용하려면 다음 셀의 find_similar_faces_auto_enhanced() 함수를 사용하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IKYMDw4ZAxS"
   },
   "source": [
    "## 📚 Google Colab 사용 가이드\n",
    "\n",
    "### \udf1f Colab 환경 최적화\n",
    "\n",
    "**이 노트북은 Google Colab에서 `face_recognition` 라이브러리 문제를 해결하기 위해 OpenCV 전용으로 설계되었습니다.**\n",
    "\n",
    "### 🎯 주요 변경사항\n",
    "\n",
    "1. **face_recognition 라이브러리 제거**: dlib 컴파일 오류 해결\n",
    "2. **OpenCV 전용 얼굴 감지**: Haar Cascade + 강화된 특징 추출\n",
    "3. **Colab 메모리 최적화**: CPU offload + attention slicing\n",
    "4. **자동 환경 감지**: Colab과 로컬 환경 자동 구분\n",
    "\n",
    "### 🚀 실행 순서\n",
    "\n",
    "1. **셀 1**: 환경 설정 및 라이브러리 로드\n",
    "2. **셀 2**: Stable Diffusion 파이프라인 초기화 (첫 실행 시 3-5분 소요)\n",
    "3. **셀 3**: OpenCV 기반 얼굴 유사도 평가기\n",
    "4. **셀 4-6**: 유틸리티 함수들\n",
    "5. **셀 7**: 참조 이미지 확인\n",
    "6. **셀 8**: 테스트 실행\n",
    "\n",
    "### 📁 파일 경로 설정\n",
    "\n",
    "```python\n",
    "# Google Drive에 파일 업로드 경로:\n",
    "# /content/drive/MyDrive/homepage/스프린트미션/스프린트미션_작업중/test.png\n",
    "\n",
    "# 또는 Colab에 직접 업로드:\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # test.png 업로드\n",
    "reference_photo = \"test.png\"\n",
    "```\n",
    "\n",
    "### ⚙️ 매개변수 권장값 (Colab 최적화)\n",
    "\n",
    "- **`num_inference_steps`**: 20-30 (빠른 생성)\n",
    "- **`target_score`**: 0.4-0.6 (OpenCV 특성상 낮게 설정)\n",
    "- **`max_attempts`**: 20-30 (Colab 시간 제한)\n",
    "- **`target_count`**: 3-5개\n",
    "\n",
    "### 🔧 메모리 최적화 팁\n",
    "\n",
    "```python\n",
    "# GPU 메모리 부족 시:\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# 메모리 정리\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 파이프라인 재초기화\n",
    "pipe.enable_model_cpu_offload()\n",
    "```\n",
    "\n",
    "### 🚨 Colab 주의사항\n",
    "\n",
    "1. **런타임 연결 끊김**: 장시간 실행 시 연결이 끊길 수 있음\n",
    "2. **GPU 사용량 제한**: 무료 계정은 GPU 사용량 제한 있음\n",
    "3. **파일 저장**: 생성된 이미지는 Google Drive에 자동 저장\n",
    "4. **메모리 제한**: 복잡한 작업 시 메모리 부족 발생 가능\n",
    "\n",
    "### 💡 문제 해결\n",
    "\n",
    "**\"CUDA out of memory\" 오류 시:**\n",
    "```python\n",
    "# 1. 런타임 재시작: 런타임 > 런타임 재시작\n",
    "# 2. 메모리 정리 후 재실행\n",
    "# 3. inference_steps 줄이기 (20으로 설정)\n",
    "```\n",
    "\n",
    "**참조 이미지를 찾을 수 없을 때:**\n",
    "```python\n",
    "# Google Drive 마운트 확인\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 파일 경로 확인\n",
    "import os\n",
    "print(os.listdir('/content/drive/MyDrive'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1757069008962,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "8--M503d9RjR",
    "outputId": "f9eb7418-1b99-4ae4-9e0c-9e66c9330569"
   },
   "outputs": [],
   "source": [
    "# 시스템 테스트 및 참조 이미지 확인\n",
    "test_image_path = \"test.png\"\n",
    "\n",
    "print(\"🧪 OpenCV 기반 시스템 테스트...\")\n",
    "\n",
    "# 참조 이미지 존재 확인\n",
    "if os.path.exists(test_image_path):\n",
    "    print(f\"✅ 참조 이미지 발견: {test_image_path}\")\n",
    "\n",
    "    # OpenCV 기반 평가기 테스트\n",
    "    try:\n",
    "        evaluator = FaceSimilarityEvaluator(test_image_path)\n",
    "        print(\"✅ OpenCV 기반 얼굴 평가기 초기화 성공!\")\n",
    "\n",
    "        # 자기 자신과의 유사도 테스트\n",
    "        if evaluator.reference_features is not None:\n",
    "            test_image = Image.open(test_image_path)\n",
    "            scores = evaluator.evaluate_similarity(test_image)\n",
    "            print(f\"🔍 자기 참조 테스트 결과:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(\"⚠️ 참조 이미지에서 얼굴을 감지하지 못했습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 평가기 초기화 실패: {e}\")\n",
    "\n",
    "else:\n",
    "    print(f\"⚠️ 참조 이미지가 없습니다: {test_image_path}\")\n",
    "    print(\"현재 디렉토리의 파일들:\")\n",
    "    for file in os.listdir(\".\"):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  📁 {file}\")\n",
    "\n",
    "print(\"🔧 시스템이 face_recognition 없이 정상 작동합니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1757069008981,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "AUnSsXwV9RjR",
    "outputId": "2341c853-81f5-4124-c9ad-89b9b8415c54"
   },
   "outputs": [],
   "source": [
    "# face_recognition 없이 작동하는 SmartPromptGenerator\n",
    "class SmartPromptGenerator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV 기반 스마트 프롬프트 생성기\"\"\"\n",
    "        print(f\"🎨 OpenCV 기반 프롬프트 생성기 초기화: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image_path = reference_image_path\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "            self.features = self.analyze_features()\n",
    "        else:\n",
    "            print(f\"❌ 참조 이미지를 찾을 수 없습니다: {reference_image_path}\")\n",
    "            self.features = {}\n",
    "\n",
    "    def analyze_features(self):\n",
    "        \"\"\"OpenCV를 사용한 기본적인 얼굴 특징 분석\"\"\"\n",
    "        features = {}\n",
    "\n",
    "        try:\n",
    "            # 얼굴 감지\n",
    "            gray = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                # 가장 큰 얼굴 선택\n",
    "                x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "\n",
    "                # 기본 특징들\n",
    "                features.update({\n",
    "                    'face_detected': True,\n",
    "                    'face_size': 'large' if w * h > 10000 else 'medium' if w * h > 5000 else 'small',\n",
    "                    'face_ratio': w / h,\n",
    "                })\n",
    "\n",
    "                # 이미지 밝기 분석\n",
    "                brightness = np.mean(gray[y:y+h, x:x+w])\n",
    "                features['brightness'] = 'bright' if brightness > 150 else 'dark' if brightness < 100 else 'normal'\n",
    "\n",
    "                # 색상 분석 (간단한 버전)\n",
    "                face_roi = self.reference_image_rgb[y:y+h, x:x+w]\n",
    "                avg_color = np.mean(face_roi, axis=(0, 1))\n",
    "                features['skin_tone'] = 'warm' if avg_color[0] > avg_color[2] else 'cool'\n",
    "\n",
    "            else:\n",
    "                features['face_detected'] = False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"특징 분석 오류: {e}\")\n",
    "            features['face_detected'] = False\n",
    "\n",
    "        return features\n",
    "\n",
    "    def generate_smart_prompts(self, count=10):\n",
    "        \"\"\"분석된 특징을 바탕으로 스마트 프롬프트 생성\"\"\"\n",
    "\n",
    "        base_prompts = [\n",
    "            \"a professional portrait photo of a person\",\n",
    "            \"a high-quality headshot of a person\",\n",
    "            \"a realistic portrait of a person\",\n",
    "            \"a detailed face portrait of a person\",\n",
    "            \"a studio portrait of a person\",\n",
    "            \"a professional photograph of a person\",\n",
    "            \"a clear portrait photo of a person\",\n",
    "            \"a high-resolution portrait of a person\",\n",
    "            \"a realistic headshot of a person\",\n",
    "            \"a professional studio portrait of a person\"\n",
    "        ]\n",
    "\n",
    "        # 특징 기반 수정자들\n",
    "        modifiers = []\n",
    "\n",
    "        if self.features.get('face_detected', False):\n",
    "            if self.features.get('brightness') == 'bright':\n",
    "                modifiers.append(\"well-lit\")\n",
    "            elif self.features.get('brightness') == 'dark':\n",
    "                modifiers.append(\"dramatic lighting\")\n",
    "\n",
    "            if self.features.get('skin_tone') == 'warm':\n",
    "                modifiers.append(\"warm tones\")\n",
    "            elif self.features.get('skin_tone') == 'cool':\n",
    "                modifiers.append(\"cool tones\")\n",
    "\n",
    "        # 품질 향상 키워드\n",
    "        quality_keywords = [\n",
    "            \"high quality\", \"detailed\", \"sharp focus\", \"professional\",\n",
    "            \"photorealistic\", \"8k resolution\", \"studio lighting\"\n",
    "        ]\n",
    "\n",
    "        smart_prompts = []\n",
    "        for i, base in enumerate(base_prompts[:count]):\n",
    "            prompt = base\n",
    "\n",
    "            # 수정자 추가\n",
    "            if modifiers and i % 3 == 0:\n",
    "                prompt += f\", {', '.join(modifiers[:2])}\"\n",
    "\n",
    "            # 품질 키워드 추가\n",
    "            if i % 2 == 0:\n",
    "                prompt += f\", {quality_keywords[i % len(quality_keywords)]}\"\n",
    "\n",
    "            smart_prompts.append(prompt)\n",
    "\n",
    "        return smart_prompts, self.features\n",
    "\n",
    "print(\"✅ OpenCV 기반 SmartPromptGenerator 클래스 로드 완료\")\n",
    "\n",
    "# 테스트\n",
    "try:\n",
    "    prompt_gen = SmartPromptGenerator(\"test.png\")\n",
    "    smart_prompts, features = prompt_gen.generate_smart_prompts(5)\n",
    "    print(\"🎨 생성된 스마트 프롬프트:\")\n",
    "    for i, prompt in enumerate(smart_prompts, 1):\n",
    "        print(f\"  {i}. {prompt}\")\n",
    "    print(f\"📊 분석된 특징: {features}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 프롬프트 생성기 테스트 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757069008994,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "-YB3-DK89RjR",
    "outputId": "c47c3f12-44b8-4a31-e71c-d1758e0d76f6"
   },
   "outputs": [],
   "source": [
    "# 개선된 find_similar_faces_auto_enhanced 함수 (나이, 성별, 인종 정보 추가)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6, max_attempts=50, target_count=3,\n",
    "                                   age_group=\"20대\", gender=\"여성\", ethnicity=\"아시안\"):\n",
    "    \"\"\"OpenCV 기반 자동 얼굴 유사도 탐색 (개인정보 기반 프롬프트 개선)\"\"\"\n",
    "\n",
    "    print(\"🔄 개선된 OpenCV 기반 자동 유사도 탐색 시작...\")\n",
    "    print(f\"🎯 검색 조건: {age_group} {gender} {ethnicity}\")\n",
    "\n",
    "    # OpenCV 기반 평가기 초기화\n",
    "    try:\n",
    "        print(\"🎯 OpenCV 기반 평가기 초기화...\")\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "        print(\"✅ OpenCV 기반 시스템 초기화 성공\")\n",
    "\n",
    "        # 기본 스마트 프롬프트 생성\n",
    "        smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "        print(f\"🎨 기본 {len(smart_prompts)}개의 스마트 프롬프트 생성 완료\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ OpenCV 기반 평가기 초기화 실패: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 개인정보 기반 향상된 프롬프트 생성\n",
    "    enhanced_prompts = generate_demographic_prompts(age_group, gender, ethnicity)\n",
    "\n",
    "    # 기본 프롬프트와 개인정보 기반 프롬프트 결합\n",
    "    all_prompts = enhanced_prompts + smart_prompts[:5]  # 기본 프롬프트도 일부 포함\n",
    "\n",
    "    print(f\"🎨 총 {len(all_prompts)}개의 향상된 프롬프트 준비 완료\")\n",
    "\n",
    "    successful_images = []\n",
    "    attempts = 0\n",
    "    prompt_idx = 0\n",
    "\n",
    "    print(f\"🎯 목표: {target_count}개의 유사한 얼굴 찾기 (유사도 >= {target_score})\")\n",
    "    print(f\"📊 분석된 특징: {features}\")\n",
    "\n",
    "    while len(successful_images) < target_count and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        current_prompt = all_prompts[prompt_idx % len(all_prompts)]\n",
    "\n",
    "        print(f\"\\n🔄 시도 {attempts}/{max_attempts}\")\n",
    "        print(f\"📝 프롬프트: {current_prompt}\")\n",
    "\n",
    "        try:\n",
    "            # 이미지 생성\n",
    "            with torch.no_grad():\n",
    "                result = pipe(\n",
    "                    current_prompt,\n",
    "                    num_inference_steps=20,\n",
    "                    guidance_scale=7.5,\n",
    "                    width=512,\n",
    "                    height=512\n",
    "                )\n",
    "\n",
    "            generated_image = result.images[0]\n",
    "\n",
    "            # 유사도 평가\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "\n",
    "            print(f\"📊 평가 결과:\")\n",
    "            for key, value in scores.items():\n",
    "                print(f\"   {key}: {value:.4f}\")\n",
    "\n",
    "            # 목표 점수 달성 시 저장\n",
    "            if scores['total_score'] >= target_score:\n",
    "                successful_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'attempt': attempts,\n",
    "                    'demographics': f\"{age_group}_{gender}_{ethnicity}\"\n",
    "                })\n",
    "                print(f\"✅ 성공! ({len(successful_images)}/{target_count})\")\n",
    "\n",
    "                # 이미지 표시\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(successful_images)} (Score: {scores['total_score']:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                print(f\"❌ 목표 점수 미달 (현재: {scores['total_score']:.4f}, 목표: {target_score})\")\n",
    "\n",
    "            prompt_idx += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 이미지 생성 오류: {e}\")\n",
    "            prompt_idx += 1\n",
    "\n",
    "    print(f\"\\n🎯 탐색 완료: {len(successful_images)}개의 성공적인 이미지 생성\")\n",
    "\n",
    "    # 결과 정렬 (총 점수 기준)\n",
    "    successful_images.sort(key=lambda x: x['scores']['total_score'], reverse=True)\n",
    "\n",
    "    return successful_images\n",
    "\n",
    "\n",
    "def generate_demographic_prompts(age_group, gender, ethnicity):\n",
    "    \"\"\"나이, 성별, 인종 정보를 기반으로 향상된 프롬프트 생성\"\"\"\n",
    "\n",
    "    # 나이 그룹별 키워드\n",
    "    age_keywords = {\n",
    "        \"10대\": [\"young teenager\", \"youthful\", \"teenage\", \"adolescent\"],\n",
    "        \"20대\": [\"young adult\", \"early twenties\", \"youthful adult\", \"young person\"],\n",
    "        \"30대\": [\"adult\", \"mature young adult\", \"thirty-something\", \"professional adult\"],\n",
    "        \"40대\": [\"middle-aged adult\", \"mature\", \"experienced adult\", \"forty-something\"],\n",
    "        \"50대\": [\"mature adult\", \"middle-aged\", \"distinguished\", \"experienced person\"]\n",
    "    }\n",
    "\n",
    "    # 성별 키워드\n",
    "    gender_keywords = {\n",
    "        \"남성\": [\"man\", \"male\", \"gentleman\", \"guy\"],\n",
    "        \"여성\": [\"woman\", \"female\", \"lady\", \"girl\"]\n",
    "    }\n",
    "\n",
    "    # 인종 키워드\n",
    "    ethnicity_keywords = {\n",
    "        \"아시안\": [\"Asian\", \"East Asian\", \"Korean\", \"Japanese\", \"Chinese\"],\n",
    "        \"백인\": [\"Caucasian\", \"white\", \"European\", \"Western\"],\n",
    "        \"흑인\": [\"African American\", \"black\", \"African\", \"dark-skinned\"],\n",
    "        \"히스패닉\": [\"Hispanic\", \"Latino\", \"Latin American\", \"Mediterranean\"],\n",
    "        \"중동\": [\"Middle Eastern\", \"Arabic\", \"Persian\", \"Turkish\"]\n",
    "    }\n",
    "\n",
    "    # 기본 스타일 (밝고 자연스러운 톤)\n",
    "    lighting_styles = [\n",
    "        \"natural lighting, bright and cheerful\",\n",
    "        \"soft natural daylight, warm atmosphere\",\n",
    "        \"bright studio lighting, clean background\",\n",
    "        \"outdoor natural light, fresh and bright\",\n",
    "        \"golden hour lighting, warm and inviting\",\n",
    "        \"soft window light, natural and bright\"\n",
    "    ]\n",
    "\n",
    "    # 품질 향상 키워드\n",
    "    quality_keywords = [\n",
    "        \"high quality, detailed, photorealistic\",\n",
    "        \"professional photography, sharp focus, 8k resolution\",\n",
    "        \"natural skin tone, realistic features, detailed\",\n",
    "        \"clear facial features, professional portrait\",\n",
    "        \"realistic lighting, natural expression, high detail\"\n",
    "    ]\n",
    "\n",
    "    enhanced_prompts = []\n",
    "\n",
    "    # 각 조합으로 프롬프트 생성\n",
    "    age_terms = age_keywords.get(age_group, [\"young adult\"])\n",
    "    gender_terms = gender_keywords.get(gender, [\"person\"])\n",
    "    ethnic_terms = ethnicity_keywords.get(ethnicity, [\"\"])\n",
    "\n",
    "    for age_term in age_terms[:2]:  # 상위 2개 나이 키워드\n",
    "        for gender_term in gender_terms[:2]:  # 상위 2개 성별 키워드\n",
    "            for ethnic_term in ethnic_terms[:2]:  # 상위 2개 인종 키워드\n",
    "                for lighting in lighting_styles[:3]:  # 상위 3개 조명 스타일\n",
    "                    for quality in quality_keywords[:2]:  # 상위 2개 품질 키워드\n",
    "\n",
    "                        # 프롬프트 조합\n",
    "                        if ethnic_term:\n",
    "                            prompt = f\"professional portrait of a {age_term} {ethnic_term} {gender_term}, {lighting}, {quality}\"\n",
    "                        else:\n",
    "                            prompt = f\"professional portrait of a {age_term} {gender_term}, {lighting}, {quality}\"\n",
    "\n",
    "                        enhanced_prompts.append(prompt)\n",
    "\n",
    "    # 중복 제거 및 셔플\n",
    "    enhanced_prompts = list(set(enhanced_prompts))\n",
    "    random.shuffle(enhanced_prompts)\n",
    "\n",
    "    print(f\"🎨 {age_group} {gender} {ethnicity} 기반 {len(enhanced_prompts)}개 프롬프트 생성\")\n",
    "\n",
    "    return enhanced_prompts[:15]  # 상위 15개만 반환\n",
    "\n",
    "\n",
    "print(\"✅ 개선된 find_similar_faces_auto_enhanced 함수 로드 완료\")\n",
    "print(\"🚀 이제 나이, 성별, 인종 정보로 더 정확한 검색이 가능합니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1757069009050,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "wMQlEv_KWgWb",
    "outputId": "d6aac505-c8d4-4945-9f70-e9035828dd92"
   },
   "outputs": [],
   "source": [
    "# 개선된 함수 사용 예제\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 개선된 find_similar_faces_auto_enhanced 사용 예제\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 사용 가능한 옵션들\n",
    "print(\"📋 사용 가능한 옵션들:\")\n",
    "print(\"나이 그룹: 10대, 20대, 30대, 40대, 50대\")\n",
    "print(\"성별: 남성, 여성\")\n",
    "print(\"인종: 아시안, 백인, 흑인, 히스패닉, 중동\")\n",
    "print()\n",
    "\n",
    "# 예제 프롬프트 생성 테스트\n",
    "print(\"🧪 예제 프롬프트 생성 테스트:\")\n",
    "test_prompts = generate_demographic_prompts(\"20대\", \"여성\", \"아시안\")\n",
    "print(\"생성된 프롬프트 예시 (상위 5개):\")\n",
    "for i, prompt in enumerate(test_prompts[:5], 1):\n",
    "    print(f\"  {i}. {prompt}\")\n",
    "\n",
    "print(\"\\n💡 사용법:\")\n",
    "print(\"\"\"\n",
    "# 기본 사용 (20대 여성 아시안)\n",
    "similar_faces = find_similar_faces_auto_enhanced(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=\"test.png\",\n",
    "    target_score=0.6,\n",
    "    max_attempts=30,\n",
    "    target_count=3\n",
    ")\n",
    "\n",
    "# 커스텀 설정 (30대 남성 백인)\n",
    "similar_faces = find_similar_faces_auto_enhanced(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=\"test.png\",\n",
    "    target_score=0.65,\n",
    "    max_attempts=50,\n",
    "    target_count=5,\n",
    "    age_group=\"30대\",\n",
    "    gender=\"남성\",\n",
    "    ethnicity=\"백인\"\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35339,
     "status": "ok",
     "timestamp": 1757069044390,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "stxgBgRDQidf",
    "outputId": "780a9d8a-d1dd-4bc1-f795-d7fcb1b86b33"
   },
   "outputs": [],
   "source": [
    "# !pip install -q \"numpy<2\"\n",
    "# !pip install -q kaggle\n",
    "# !pip install -q kagglehub\n",
    "# !pip install -q albumentations\n",
    "# !pip install -q ultralytics\n",
    "# !pip install -q --user opencv-python\n",
    "# !pip install -q torchvision\n",
    "# !pip install -q torch\n",
    "# !pip install -q pycocotools\n",
    "#!pip install --upgrade torchvision\n",
    "#!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "\n",
    "!pip install -q lpips\n",
    "print(f\"lpips 설치 완료\")\n",
    "!pip install -q pytorch-fid\n",
    "print(f\"pytorch-fid 설치 완료\")\n",
    "!pip install -q torch-fidelity\n",
    "print(f\"torch-fidelity 설치 완료\")\n",
    "!pip install -q scipy\n",
    "print(f\"scipy 설치 완료\")\n",
    "!pip install -q face_recognition\n",
    "print(f\"face_recognition 설치 완료\")\n",
    "!pip install -q diffusers\n",
    "print(f\"diffusers 설치 완료\")\n",
    "\n",
    "print(f\"라이브러리 설치 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1757069044411,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "y-PxX7m45GtI",
    "outputId": "47d651d3-dce5-4659-da47-e6c31a81c64a"
   },
   "outputs": [],
   "source": [
    "# 대안 방법: OpenCV 기반 얼굴 유사도 평가기\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import lpips\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class OpenCVFaceSimilarityEvaluator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"OpenCV 기반 얼굴 유사도 평가기\"\"\"\n",
    "        print(f\"OpenCV 기반 평가기 초기화 중: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV 얼굴 감지기 초기화\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # 참조 이미지 로드\n",
    "        if os.path.exists(reference_image_path):\n",
    "            self.reference_image = cv2.imread(reference_image_path)\n",
    "            self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 참조 얼굴 특징 추출\n",
    "            self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "            if self.reference_features is not None:\n",
    "                print(\"✅ 참조 얼굴 특징 추출 완료\")\n",
    "            else:\n",
    "                print(\"⚠️ 참조 이미지에서 얼굴을 찾을 수 없습니다\")\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"참조 이미지를 찾을 수 없습니다: {reference_image_path}\")\n",
    "\n",
    "        # LPIPS 초기화\n",
    "        try:\n",
    "            self.lpips_model = lpips.LPIPS(net='alex').to(__device)\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((512, 512)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "            ])\n",
    "            print(\"✅ LPIPS 모델 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ LPIPS 초기화 실패: {e}\")\n",
    "            self.lpips_model = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"얼굴 특징 추출 (OpenCV 기반)\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # 가장 큰 얼굴 선택\n",
    "            largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "            x, y, w, h = largest_face\n",
    "\n",
    "            # 얼굴 영역 추출\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "\n",
    "            # 히스토그램 기반 특징\n",
    "            hist_features = cv2.calcHist([face_resized], [0], None, [256], [0, 256]).flatten()\n",
    "\n",
    "            # LBP (Local Binary Pattern) 특징\n",
    "            lbp_features = self.calculate_lbp(face_resized)\n",
    "\n",
    "            # 특징 결합\n",
    "            combined_features = np.concatenate([hist_features, lbp_features])\n",
    "\n",
    "            return combined_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"특징 추출 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_lbp(self, image, radius=3, n_points=24):\n",
    "        \"\"\"Local Binary Pattern 계산\"\"\"\n",
    "        try:\n",
    "            from skimage.feature import local_binary_pattern\n",
    "            lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "            (hist, _) = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            return hist\n",
    "        except:\n",
    "            # skimage가 없으면 간단한 대안 사용\n",
    "            return np.histogram(image.ravel(), bins=50)[0].astype(\"float\")\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"생성된 이미지와 참조 이미지의 유사도 평가\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PIL을 OpenCV 형식으로 변환\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 1. OpenCV 기반 얼굴 유사도\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # 코사인 유사도 계산\n",
    "                similarity = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                face_similarity = max(0, similarity)  # 음수 방지\n",
    "                scores['face_similarity'] = face_similarity\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "\n",
    "            # 2. LPIPS 점수 (가능한 경우)\n",
    "            if self.lpips_model is not None:\n",
    "                try:\n",
    "                    ref_tensor = self.transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(__device)\n",
    "                    gen_tensor = self.transform(generated_image).unsqueeze(0).to(__device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = self.lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS 계산 오류: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 3. 종합 점수\n",
    "            face_weight = 0.8  # OpenCV 기반이므로 가중치 조정\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"평가 오류: {e}\")\n",
    "            scores = {'face_similarity': 0.0, 'lpips_similarity': 0.0, 'total_score': 0.0}\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"OpenCV 기반 얼굴 평가기 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1757069044436,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "Ktzm_aa25GtJ",
    "outputId": "34482451-7c44-4ada-fabf-6423602cc0f5"
   },
   "outputs": [],
   "source": [
    "# 기존 find_similar_faces_auto 함수를 OpenCV 기반으로 업그레이드\n",
    "def find_similar_faces_auto_enhanced(pipe, reference_image_path, target_score=0.6, max_attempts=50, target_count=3, use_opencv_fallback=True):\n",
    "    \"\"\"향상된 자동 얼굴 유사도 탐색 (face_recognition + OpenCV 백업)\"\"\"\n",
    "\n",
    "    print(\"🔄 자동 유사도 탐색 시작...\")\n",
    "\n",
    "    # 먼저 face_recognition 시도\n",
    "    evaluator = None\n",
    "    prompt_gen = None\n",
    "\n",
    "    try:\n",
    "        print(\"🎯 face_recognition 기반 평가기 시도...\")\n",
    "        evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "        prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "        print(\"✅ face_recognition 기반 시스템 초기화 성공\")\n",
    "\n",
    "        # 스마트 프롬프트 생성\n",
    "        smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "        print(f\"감지된 얼굴 특징: {features}\")\n",
    "\n",
    "    except Exception as face_rec_error:\n",
    "        print(f\"❌ face_recognition 초기화 실패: {face_rec_error}\")\n",
    "\n",
    "        if use_opencv_fallback:\n",
    "            print(\"🔄 OpenCV 기반 백업 시스템으로 전환...\")\n",
    "            try:\n",
    "                evaluator = OpenCVFaceSimilarityEvaluator(reference_image_path)\n",
    "                print(\"✅ OpenCV 기반 평가기 초기화 성공\")\n",
    "\n",
    "                # 기본 프롬프트 사용\n",
    "                smart_prompts = [\n",
    "                    \"professional portrait, high quality, detailed, sharp focus\",\n",
    "                    \"natural lighting portrait, realistic, professional photography\",\n",
    "                    \"soft studio lighting, headshot, detailed face\",\n",
    "                    \"outdoor natural portrait, clear lighting, high resolution\",\n",
    "                    \"casual portrait, friendly expression, detailed features\",\n",
    "                    \"business portrait, professional attire, studio lighting\"\n",
    "                ]\n",
    "                features = {\"system\": \"opencv_fallback\"}\n",
    "\n",
    "            except Exception as opencv_error:\n",
    "                print(f\"❌ OpenCV 백업 시스템도 실패: {opencv_error}\")\n",
    "                return []\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    if not evaluator:\n",
    "        print(\"❌ 평가 시스템을 초기화할 수 없습니다.\")\n",
    "        return []\n",
    "\n",
    "    # 공통 탐색 로직\n",
    "    found_images = []\n",
    "    attempt_count = 0\n",
    "\n",
    "    # 네거티브 프롬프트\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces, bad hands, distorted face\"\n",
    "\n",
    "    print(f\"🎯 목표: {target_count}개 이미지 (점수 {target_score} 이상)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while len(found_images) < target_count and attempt_count < max_attempts:\n",
    "        attempt_count += 1\n",
    "\n",
    "        # 프롬프트 선택 (순환)\n",
    "        prompt_idx = (attempt_count - 1) % len(smart_prompts)\n",
    "        current_prompt = smart_prompts[prompt_idx]\n",
    "\n",
    "        # 랜덤 시드\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\n🔍 시도 {attempt_count}/{max_attempts}\")\n",
    "        print(f\"📝 프롬프트: {current_prompt}\")\n",
    "        print(f\"🎲 시드: {seed}\")\n",
    "\n",
    "        try:\n",
    "            # 이미지 생성 (기존 함수 재사용)\n",
    "            generated_image = alternative_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False  # 배치 처리시 화면 출력 끄기\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                print(\"❌ 이미지 생성 실패\")\n",
    "                continue\n",
    "\n",
    "            # 유사도 평가\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "            total_score = scores['total_score']\n",
    "\n",
    "            print(f\"📊 점수: {total_score:.3f} (얼굴: {scores['face_similarity']:.3f}, LPIPS: {scores['lpips_similarity']:.3f})\")\n",
    "\n",
    "            # 목표 점수 달성시 저장\n",
    "            if total_score >= target_score:\n",
    "                print(f\"✅ 목표 달성! (점수: {total_score:.3f})\")\n",
    "\n",
    "                # 이미지 저장\n",
    "                save_path = f\"similar_face_{len(found_images)+1:02d}_score_{total_score:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                found_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path\n",
    "                })\n",
    "\n",
    "                # 이미지 표시\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(found_images)} (Score: {total_score:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 시도 {attempt_count} 오류: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"🏁 탐색 완료!\")\n",
    "    print(f\"🔢 시도 횟수: {attempt_count}\")\n",
    "    print(f\"🖼️ 발견된 이미지: {len(found_images)}개\")\n",
    "\n",
    "    if found_images:\n",
    "        print(\"\\n📋 발견된 이미지 정보:\")\n",
    "        for i, result in enumerate(found_images):\n",
    "            print(f\"  {i+1}. 점수: {result['scores']['total_score']:.3f}, 경로: {result['path']}\")\n",
    "\n",
    "    return found_images\n",
    "\n",
    "print(\"✅ 통합 자동 탐색 함수 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643,
     "referenced_widgets": [
      "5b9024b085ef47a69cf529c626a6c356",
      "1892b885c9f3473ba320f52e687ed4b9",
      "a8ce3f62c420440091a27a5793643b84",
      "a32142681ece4dac8a9614442a929ac4",
      "31a79a6bb4574aa58aa478c99641fce9",
      "d00dd16c0c424e779d55f932a522de1d",
      "1221f3d8061943e395f0517c2bb0ba3b",
      "b0f5643c47c342dd897008e86771c9cb",
      "a4a2fd815d034542a243a342823da200",
      "2cde21101bff44979b3ed02110617631",
      "146f96d250c3474f89d5497506dadc1c"
     ]
    },
    "executionInfo": {
     "elapsed": 2388,
     "status": "ok",
     "timestamp": 1757069759993,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "gtKLPc9l5GtJ",
    "outputId": "8ff4d89f-b698-46d1-9b32-c2411bff52f6"
   },
   "outputs": [],
   "source": [
    "# 🚀 통합 테스트 실행 (기존 함수 재사용)\n",
    "print(\"🔧 환경 감지 및 설정...\")\n",
    "\n",
    "# 경로 설정 (helper 함수 재사용)\n",
    "import os\n",
    "\n",
    "# 코랩 여부 확인 (helper 모듈 사용)\n",
    "try:\n",
    "    is_colab = helper.is_colab\n",
    "except:\n",
    "    # helper가 없으면 직접 확인\n",
    "    is_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if is_colab:\n",
    "    colab_path = \"/content/drive/MyDrive/homepage/스프린트미션/스프린트미션_작업중/test.png\"\n",
    "    reference_photo = colab_path\n",
    "    print(f\"✅ 코랩 환경 - 경로: {reference_photo}\")\n",
    "else:\n",
    "    local_path = \"test.png\"\n",
    "    reference_photo = local_path\n",
    "    print(f\"✅ 로컬 환경 - 경로: {reference_photo}\")\n",
    "\n",
    "# 파일 존재 확인\n",
    "if not os.path.exists(reference_photo):\n",
    "    print(\"❌ 참조 이미지를 찾을 수 없습니다\")\n",
    "    print(\"현재 디렉토리:\", os.getcwd())\n",
    "    print(\"이미지 파일 목록:\")\n",
    "    for file in os.listdir('.'):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  - {file}\")\n",
    "    reference_photo = None\n",
    "\n",
    "if reference_photo:\n",
    "    print(f\"\\n🎯 통합 자동 탐색 실행...\")\n",
    "\n",
    "    try:\n",
    "        # 기존 함수 재사용 (enhanced 버전)\n",
    "        similar_faces = find_similar_faces_auto_enhanced(\n",
    "            pipe=pipe,\n",
    "            reference_image_path=reference_photo,\n",
    "            target_score=0.5,        # 관대한 점수\n",
    "            max_attempts=20,         # 테스트용 적은 시도\n",
    "            target_count=2,          # 2개만 찾기\n",
    "            age_group=\"30대\",\n",
    "            gender=\"남성\",\n",
    "            ethnicity=\"백인\",\n",
    "            use_opencv_fallback=True # OpenCV 백업 활성화\n",
    "        )\n",
    "\n",
    "        if similar_faces:\n",
    "            print(f\"\\n🎉 성공! {len(similar_faces)}개의 유사한 이미지를 찾았습니다!\")\n",
    "\n",
    "            # 히스토리 관리자 사용 (기존 gen_manager 재사용)\n",
    "            print(\"\\n📚 생성 히스토리 저장 중...\")\n",
    "            for result in similar_faces:\n",
    "                metadata = {\n",
    "                    \"prompt\": result['prompt'],\n",
    "                    \"seed\": result['seed'],\n",
    "                    \"scores\": result['scores'],\n",
    "                    \"method\": \"auto_search\",\n",
    "                    \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "                }\n",
    "                gen_id = gen_manager.save_generation(metadata, result['path'])\n",
    "                print(f\"  히스토리 ID {gen_id}: {result['path']}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n😢 조건에 맞는 이미지를 찾지 못했습니다.\")\n",
    "            print(\"💡 점수를 더 낮추거나 시도 횟수를 늘려보세요.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 통합 탐색 실패: {e}\")\n",
    "\n",
    "        print(\"\\n🔄 기본 이미지 생성 테스트 (기존 함수 재사용)...\")\n",
    "        try:\n",
    "            # enhanced_face_generation 함수 재사용\n",
    "            test_image = enhanced_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=\"professional portrait, high quality, realistic, detailed face\",\n",
    "                negative_prompt=\"blurry, low quality, bad anatomy, deformed\",\n",
    "                seed=42,\n",
    "                save_path=\"fallback_test.png\"\n",
    "            )\n",
    "\n",
    "            if test_image:\n",
    "                print(\"✅ 기본 이미지 생성 성공! 시스템이 정상 작동합니다.\")\n",
    "        except Exception as fallback_e:\n",
    "            print(f\"❌ 기본 생성도 실패: {fallback_e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 참조 이미지가 없어 테스트를 실행할 수 없습니다.\")\n",
    "    print(\"💡 test.png 파일을 현재 디렉토리에 업로드해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3323,
     "status": "ok",
     "timestamp": 1757069062961,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "riCoM4kZdb_T",
    "outputId": "2359d41c-1418-47db-d239-63cc4ee65c15"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import importlib\n",
    "import helper_c0z0c_dev as helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1757069062989,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "TXoYK8FtMfKM",
    "outputId": "871ced58-855d-40a9-9584-24289cb99366"
   },
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "\n",
    "# --- Scikit-learn: 데이터 전처리, 모델, 평가 ---\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import (\n",
    "    fetch_california_housing, load_iris, make_moons, make_circles,\n",
    "    load_breast_cancer, load_wine\n",
    ")\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# --- 기타 라이브러리 ---\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from PIL import ImageDraw\n",
    "import albumentations as A\n",
    "import IPython.display\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- PyTorch: 딥러닝 관련 ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from collections import OrderedDict\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as coco_mask\n",
    "\n",
    "# --- 기타 ---\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timezone, timedelta\n",
    "import pytz\n",
    "__kst = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# GPU 설정\n",
    "__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "__device_cpu = torch.device('cpu')\n",
    "\n",
    "  # 재현 가능한 결과를 위해\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if __device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(f\"라이브러리 로드 완료 사용장치:{__device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "bdbb6d528d4949159dcd3fd07f0e0075",
      "6f63fcd64d9b42e9b9db0ab247ea3652",
      "f8ed5f9bb8004cea83322ae7519c721e",
      "ac3f515f265e4880b1772c3274695e75",
      "9cd78b5bebc442cea7600d375204bc9a",
      "2e901af9a07345c8b8307a5f2c06c2bb",
      "144506bedbdd4755a5a94a0257100323",
      "0322d0ac3c50446594dd6754e4068241",
      "b1d5c8d9fd5644bba6363bbd87d313fe",
      "fd761716247648c0aa57cf756c6b0f7b",
      "0e83df493cab467abe97477dd4b765cb"
     ]
    },
    "executionInfo": {
     "elapsed": 7435,
     "status": "ok",
     "timestamp": 1757069070425,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "Es-QZcrGYKSg",
    "outputId": "117fdf0f-df2a-4d8d-d010-1100e6f84b1c"
   },
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision matplotlib pillow requests\n",
    "import requests\n",
    "import io\n",
    "from diffusers import StableDiffusionPipeline\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUH9352r0XRf"
   },
   "outputs": [],
   "source": [
    "def alternative_face_generation(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                              num_inference_steps=30, guidance_scale=7.5,\n",
    "                              save_path=None, show_image=True):\n",
    "    \"\"\"확장된 Stable Diffusion 이미지 생성 함수\"\"\"\n",
    "\n",
    "    try:\n",
    "        # 기본 negative prompt 설정\n",
    "        if negative_prompt is None:\n",
    "            negative_prompt = \"blurry, low quality, bad anatomy, deformed, extra limbs, bad hands, bad face, bad eyes, extra fingers, cartoon, anime, nsfw, inappropriate\"\n",
    "\n",
    "        # 랜덤 시드 고정\n",
    "        generator = torch.Generator(device=pipe.device).manual_seed(seed)\n",
    "\n",
    "        print(f\"이미지 생성 중... (시드: {seed})\")\n",
    "        print(f\"프롬프트: {prompt}\")\n",
    "        if negative_prompt:\n",
    "            print(f\"네거티브: {negative_prompt}\")\n",
    "\n",
    "        # 이미지 생성\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "\n",
    "        # 이미지 저장\n",
    "        if save_path:\n",
    "            image.save(save_path)\n",
    "            print(f\"이미지 저장됨: {save_path}\")\n",
    "\n",
    "            # 메타데이터 저장\n",
    "            metadata = {\n",
    "                \"prompt\": prompt,\n",
    "                \"negative_prompt\": negative_prompt,\n",
    "                \"seed\": seed,\n",
    "                \"steps\": num_inference_steps,\n",
    "                \"guidance_scale\": guidance_scale\n",
    "            }\n",
    "\n",
    "            import json\n",
    "            metadata_path = save_path.replace('.png', '_metadata.json')\n",
    "            with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        # 이미지 표시\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Generated (Seed: {seed})\", fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        print(\"이미지 생성 완료!\")\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"생성 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1757069488412,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "6WCIVPBn0XRf",
    "outputId": "e89aa312-e9e7-47c9-a2c5-93d451b9a087"
   },
   "outputs": [],
   "source": [
    "# 🎯 OpenCV 기반 얼굴 유사도 평가기 (face_recognition 완전 대체)\n",
    "print(\"🔄 OpenCV 전용 얼굴 분석 시스템 초기화...\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import lpips\n",
    "    LPIPS_AVAILABLE = True\n",
    "    print(\"✅ LPIPS 사용 가능\")\n",
    "except ImportError:\n",
    "    LPIPS_AVAILABLE = False\n",
    "    print(\"⚠️ LPIPS 없음 - 기본 특징만 사용\")\n",
    "\n",
    "class OpenCVFaceEvaluator:\n",
    "    \"\"\"face_recognition 없이 OpenCV만으로 얼굴 유사도 평가\"\"\"\n",
    "\n",
    "    def __init__(self, reference_image_path):\n",
    "        print(f\"🎯 OpenCV 얼굴 평가기 초기화: {reference_image_path}\")\n",
    "\n",
    "        # OpenCV 얼굴 감지기들 초기화\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "        # 참조 이미지 로드 및 특징 추출\n",
    "        if not os.path.exists(reference_image_path):\n",
    "            raise FileNotFoundError(f\"참조 이미지를 찾을 수 없습니다: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image = cv2.imread(reference_image_path)\n",
    "        if self.reference_image is None:\n",
    "            raise ValueError(f\"이미지 로드 실패: {reference_image_path}\")\n",
    "\n",
    "        self.reference_image_rgb = cv2.cvtColor(self.reference_image, cv2.COLOR_BGR2RGB)\n",
    "        self.reference_features = self.extract_face_features(self.reference_image)\n",
    "\n",
    "        if self.reference_features is None:\n",
    "            raise ValueError(\"참조 이미지에서 얼굴을 찾을 수 없습니다\")\n",
    "\n",
    "        print(\"✅ 참조 이미지 특징 추출 완료\")\n",
    "\n",
    "        # LPIPS 초기화 (사용 가능한 경우)\n",
    "        if LPIPS_AVAILABLE:\n",
    "            try:\n",
    "                self.lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.Resize((256, 256)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                ])\n",
    "                print(\"✅ LPIPS 모델 초기화 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ LPIPS 초기화 실패: {e}\")\n",
    "                self.lpips_model = None\n",
    "        else:\n",
    "            self.lpips_model = None\n",
    "\n",
    "    def extract_face_features(self, image):\n",
    "        \"\"\"OpenCV 기반 종합 얼굴 특징 추출\"\"\"\n",
    "        try:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 다중 스케일 얼굴 감지\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(50, 50))\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "\n",
    "            # 가장 큰 얼굴 선택\n",
    "            x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_roi, (128, 128))\n",
    "            face_normalized = cv2.equalizeHist(face_resized)\n",
    "\n",
    "            # 1. 히스토그램 특징\n",
    "            hist_features = cv2.calcHist([face_normalized], [0], None, [64], [0, 256]).flatten()\n",
    "            hist_features = hist_features / (hist_features.sum() + 1e-7)\n",
    "\n",
    "            # 2. LBP 특징 (간단한 구현)\n",
    "            lbp_features = self.calculate_simple_lbp(face_normalized)\n",
    "\n",
    "            # 3. 기하학적 특징\n",
    "            geometric_features = np.array([\n",
    "                w / h,  # 얼굴 비율\n",
    "                w, h,   # 크기\n",
    "                len(self.eye_cascade.detectMultiScale(face_roi)),  # 눈 개수\n",
    "                np.std(face_normalized),  # 텍스처 변화도\n",
    "                np.mean(face_normalized)  # 평균 밝기\n",
    "            ])\n",
    "\n",
    "            # 4. 에지 특징\n",
    "            edges = cv2.Canny(face_normalized, 50, 150)\n",
    "            edge_features = np.array([\n",
    "                np.sum(edges > 0) / (128 * 128),  # 에지 밀도\n",
    "                np.mean(edges),\n",
    "                np.std(edges)\n",
    "            ])\n",
    "\n",
    "            # 모든 특징 결합\n",
    "            all_features = np.concatenate([\n",
    "                hist_features,      # 64개\n",
    "                lbp_features,       # 26개\n",
    "                geometric_features, # 6개\n",
    "                edge_features      # 3개\n",
    "            ])\n",
    "\n",
    "            return all_features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"특징 추출 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_simple_lbp(self, image):\n",
    "        \"\"\"간단한 LBP 계산\"\"\"\n",
    "        h, w = image.shape\n",
    "        lbp = np.zeros((h-2, w-2), dtype=np.uint8)\n",
    "\n",
    "        for i in range(1, h-1):\n",
    "            for j in range(1, w-1):\n",
    "                center = image[i, j]\n",
    "                binary_val = 0\n",
    "\n",
    "                # 8방향 이웃 검사\n",
    "                neighbors = [\n",
    "                    image[i-1, j-1], image[i-1, j], image[i-1, j+1],\n",
    "                    image[i, j+1], image[i+1, j+1], image[i+1, j],\n",
    "                    image[i+1, j-1], image[i, j-1]\n",
    "                ]\n",
    "\n",
    "                for k, neighbor in enumerate(neighbors):\n",
    "                    if neighbor >= center:\n",
    "                        binary_val += 2**k\n",
    "\n",
    "                lbp[i-1, j-1] = binary_val\n",
    "\n",
    "        # 히스토그램 계산\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 256))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        return hist\n",
    "\n",
    "    def evaluate_similarity(self, generated_image):\n",
    "        \"\"\"생성된 이미지와의 유사도 평가\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        try:\n",
    "            # PIL을 OpenCV 형식으로 변환\n",
    "            generated_array = np.array(generated_image)\n",
    "            generated_cv = cv2.cvtColor(generated_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 얼굴 특징 추출\n",
    "            generated_features = self.extract_face_features(generated_cv)\n",
    "\n",
    "            if generated_features is not None and self.reference_features is not None:\n",
    "                # 1. 코사인 유사도\n",
    "                cosine_sim = cosine_similarity([self.reference_features], [generated_features])[0][0]\n",
    "                scores['face_similarity'] = max(0, cosine_sim)\n",
    "\n",
    "                # 2. 유클리드 거리 기반 유사도\n",
    "                euclidean_dist = np.linalg.norm(self.reference_features - generated_features)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist / 100)\n",
    "                scores['euclidean_similarity'] = euclidean_sim\n",
    "            else:\n",
    "                scores['face_similarity'] = 0.0\n",
    "                scores['euclidean_similarity'] = 0.0\n",
    "\n",
    "            # 3. LPIPS (사용 가능한 경우)\n",
    "            if self.lpips_model is not None:\n",
    "                try:\n",
    "                    ref_tensor = self.transform(Image.fromarray(self.reference_image_rgb)).unsqueeze(0).to(device)\n",
    "                    gen_tensor = self.transform(generated_image).unsqueeze(0).to(device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        lpips_distance = self.lpips_model(ref_tensor, gen_tensor).item()\n",
    "                        lpips_similarity = max(0, 1 - lpips_distance)\n",
    "                        scores['lpips_similarity'] = lpips_similarity\n",
    "                except Exception as lpips_e:\n",
    "                    print(f\"LPIPS 계산 오류: {lpips_e}\")\n",
    "                    scores['lpips_similarity'] = 0.0\n",
    "            else:\n",
    "                scores['lpips_similarity'] = 0.0\n",
    "\n",
    "            # 4. 종합 점수\n",
    "            face_weight = 0.5\n",
    "            euclidean_weight = 0.3\n",
    "            lpips_weight = 0.2\n",
    "\n",
    "            total_score = (scores['face_similarity'] * face_weight +\n",
    "                          scores['euclidean_similarity'] * euclidean_weight +\n",
    "                          scores['lpips_similarity'] * lpips_weight)\n",
    "            scores['total_score'] = total_score\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"평가 오류: {e}\")\n",
    "            scores = {\n",
    "                'face_similarity': 0.0,\n",
    "                'euclidean_similarity': 0.0,\n",
    "                'lpips_similarity': 0.0,\n",
    "                'total_score': 0.0\n",
    "            }\n",
    "\n",
    "        return scores\n",
    "\n",
    "print(\"✅ OpenCV 기반 얼굴 평가기 클래스 정의 완료!\")\n",
    "print(\"🎯 이제 face_recognition 없이도 완전한 얼굴 유사도 분석이 가능합니다.\")\n",
    "\n",
    "# 사용 예제\n",
    "print(\"\\n💡 사용 예제:\")\n",
    "print(\"evaluator = OpenCVFaceEvaluator('your_reference_image.png')\")\n",
    "print(\"scores = evaluator.evaluate_similarity(generated_image)\")\n",
    "print(\"print(f'유사도: {scores[\\\"total_score\\\"]:.4f}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1757069488415,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "cm9ZJBRg0XRg"
   },
   "outputs": [],
   "source": [
    "class SmartPromptGenerator:\n",
    "    def __init__(self, reference_image_path):\n",
    "        \"\"\"참조 이미지에서 특징 추출하여 프롬프트 생성\"\"\"\n",
    "        print(f\"프롬프트 생성기 초기화 중: {reference_image_path}\")\n",
    "\n",
    "        # 이미지가 존재하는지 확인\n",
    "        if not os.path.exists(reference_image_path):\n",
    "            raise FileNotFoundError(f\"참조 이미지를 찾을 수 없습니다: {reference_image_path}\")\n",
    "\n",
    "        try:\n",
    "            self.reference_image = face_recognition.load_image_file(reference_image_path)\n",
    "            print(\"얼굴 랜드마크 감지 중...\")\n",
    "            self.face_landmarks = face_recognition.face_landmarks(self.reference_image)\n",
    "\n",
    "            if self.face_landmarks:\n",
    "                print(f\"얼굴 랜드마크 감지 완료 ({len(self.face_landmarks)}개 얼굴)\")\n",
    "            else:\n",
    "                print(\"얼굴 랜드마크를 찾을 수 없습니다. 기본 프롬프트를 사용합니다.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"프롬프트 생성기 초기화 오류: {e}\")\n",
    "            self.reference_image = None\n",
    "            self.face_landmarks = []\n",
    "\n",
    "    def analyze_face_features(self):\n",
    "        \"\"\"얼굴 특징 분석\"\"\"\n",
    "        if not self.face_landmarks:\n",
    "            print(\"얼굴 랜드마크가 없어 기본 특징을 반환합니다.\")\n",
    "            return {\n",
    "                'eye_size': 'normal eyes',\n",
    "                'nose_type': 'straight nose',\n",
    "                'face_shape': 'balanced face'\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            landmarks = self.face_landmarks[0]\n",
    "            features = {}\n",
    "\n",
    "            # 눈 분석\n",
    "            left_eye = landmarks.get('left_eye', [])\n",
    "            right_eye = landmarks.get('right_eye', [])\n",
    "\n",
    "            if left_eye and len(left_eye) >= 4:\n",
    "                eye_width = abs(left_eye[3][0] - left_eye[0][0])\n",
    "                features['eye_size'] = 'large eyes' if eye_width > 30 else 'normal eyes'\n",
    "            else:\n",
    "                features['eye_size'] = 'normal eyes'\n",
    "\n",
    "            # 코 분석\n",
    "            nose_bridge = landmarks.get('nose_bridge', [])\n",
    "            features['nose_type'] = 'straight nose' if len(nose_bridge) > 3 else 'small nose'\n",
    "\n",
    "            # 얼굴형 분석 (간단한 버전)\n",
    "            chin = landmarks.get('chin', [])\n",
    "            nose_bridge = landmarks.get('nose_bridge', [])\n",
    "\n",
    "            if chin and len(chin) >= 9 and nose_bridge and len(nose_bridge) >= 1:\n",
    "                face_width = abs(chin[0][0] - chin[-1][0])\n",
    "                face_height = abs(chin[8][1] - nose_bridge[0][1])\n",
    "\n",
    "                if face_height > face_width * 1.3:\n",
    "                    features['face_shape'] = 'oval face'\n",
    "                elif face_width > face_height * 1.1:\n",
    "                    features['face_shape'] = 'round face'\n",
    "                else:\n",
    "                    features['face_shape'] = 'balanced face'\n",
    "            else:\n",
    "                features['face_shape'] = 'balanced face'\n",
    "\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"얼굴 특징 분석 오류: {e}\")\n",
    "            return {\n",
    "                'eye_size': 'normal eyes',\n",
    "                'nose_type': 'straight nose',\n",
    "                'face_shape': 'balanced face'\n",
    "            }\n",
    "\n",
    "    def generate_smart_prompts(self, base_descriptions=None):\n",
    "        \"\"\"분석된 특징을 바탕으로 스마트 프롬프트 생성\"\"\"\n",
    "        features = self.analyze_face_features()\n",
    "\n",
    "        if base_descriptions is None:\n",
    "            base_descriptions = [\n",
    "                \"professional portrait\",\n",
    "                \"natural lighting portrait\",\n",
    "                \"soft studio lighting\",\n",
    "                \"outdoor natural portrait\",\n",
    "                \"casual portrait\",\n",
    "                \"headshot photography\"\n",
    "            ]\n",
    "\n",
    "        # 특징 기반 수식어 추가\n",
    "        feature_terms = []\n",
    "        for feature_type, feature_value in features.items():\n",
    "            feature_terms.append(feature_value)\n",
    "\n",
    "        # 기본 품질 향상 키워드\n",
    "        quality_terms = [\n",
    "            \"high quality\", \"detailed\", \"sharp focus\",\n",
    "            \"professional photography\", \"realistic\", \"8k resolution\"\n",
    "        ]\n",
    "\n",
    "        prompts = []\n",
    "        for base_desc in base_descriptions:\n",
    "            # 특징 + 기본 설명 + 품질 키워드 조합\n",
    "            feature_str = \", \".join(feature_terms[:2])  # 너무 많으면 과적합\n",
    "            quality_str = \", \".join(quality_terms[:3])\n",
    "\n",
    "            prompt = f\"{base_desc}, {feature_str}, {quality_str}\"\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        print(f\"생성된 프롬프트 수: {len(prompts)}\")\n",
    "        return prompts, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1757069488458,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "g29IwWA70XRg"
   },
   "outputs": [],
   "source": [
    "class ImageGenerationManager:\n",
    "    def __init__(self, history_file=\"generation_history.json\"):\n",
    "        \"\"\"이미지 생성 히스토리 관리자\"\"\"\n",
    "        self.history_file = history_file\n",
    "        self.load_history()\n",
    "\n",
    "    def load_history(self):\n",
    "        \"\"\"기존 히스토리 로드\"\"\"\n",
    "        if os.path.exists(self.history_file):\n",
    "            with open(self.history_file, 'r', encoding='utf-8') as f:\n",
    "                self.history = json.load(f)\n",
    "        else:\n",
    "            self.history = {\"generations\": []}\n",
    "\n",
    "    def save_generation(self, metadata, image_path=None):\n",
    "        \"\"\"생성 정보 저장\"\"\"\n",
    "        generation_data = {\n",
    "            **metadata,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"image_path\": image_path,\n",
    "            \"generation_id\": len(self.history[\"generations\"]) + 1\n",
    "        }\n",
    "\n",
    "        self.history[\"generations\"].append(generation_data)\n",
    "\n",
    "        # 히스토리 파일 저장\n",
    "        with open(self.history_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.history, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return generation_data[\"generation_id\"]\n",
    "\n",
    "    def regenerate_by_id(self, generation_id, pipe, save_new=True):\n",
    "        \"\"\"ID로 이미지 재생성\"\"\"\n",
    "        generation = self.find_generation_by_id(generation_id)\n",
    "        if not generation:\n",
    "            print(f\"ID {generation_id}를 찾을 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "        return self.regenerate_from_metadata(generation, pipe, save_new)\n",
    "\n",
    "    def regenerate_from_metadata(self, metadata, pipe, save_new=True):\n",
    "        \"\"\"메타데이터로부터 이미지 재생성\"\"\"\n",
    "        print(f\"재생성 시작...\")\n",
    "        print(f\"원본 시드: {metadata.get('seed', 'Unknown')}\")\n",
    "        print(f\"원본 프롬프트: {metadata.get('prompt', 'Unknown')}\")\n",
    "\n",
    "        # 새 파일명 생성 (재생성용)\n",
    "        save_path = None\n",
    "        if save_new:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            save_path = f\"regenerated_{timestamp}_seed_{metadata.get('seed', 'unknown')}.png\"\n",
    "\n",
    "        # 이미지 재생성\n",
    "        regenerated_image = alternative_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=metadata.get('prompt', ''),\n",
    "            negative_prompt=metadata.get('negative_prompt', ''),\n",
    "            seed=metadata.get('seed', 42),\n",
    "            num_inference_steps=metadata.get('steps', 30),\n",
    "            guidance_scale=metadata.get('guidance_scale', 7.5),\n",
    "            save_path=save_path,\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if regenerated_image and save_new:\n",
    "            # 재생성 정보도 히스토리에 추가\n",
    "            regen_metadata = {\n",
    "                **metadata,\n",
    "                \"is_regeneration\": True,\n",
    "                \"original_generation_id\": metadata.get('generation_id'),\n",
    "                \"regenerated_from\": metadata.get('image_path', 'Unknown')\n",
    "            }\n",
    "            self.save_generation(regen_metadata, save_path)\n",
    "\n",
    "        return regenerated_image\n",
    "\n",
    "    def find_generation_by_id(self, generation_id):\n",
    "        \"\"\"ID로 생성 정보 찾기\"\"\"\n",
    "        for gen in self.history[\"generations\"]:\n",
    "            if gen.get(\"generation_id\") == generation_id:\n",
    "                return gen\n",
    "        return None\n",
    "\n",
    "    def search_generations(self, keyword=None, seed=None, limit=10):\n",
    "        \"\"\"생성 히스토리 검색\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for gen in self.history[\"generations\"]:\n",
    "            match = True\n",
    "\n",
    "            if keyword and keyword.lower() not in gen.get(\"prompt\", \"\").lower():\n",
    "                match = False\n",
    "\n",
    "            if seed and gen.get(\"seed\") != seed:\n",
    "                match = False\n",
    "\n",
    "            if match:\n",
    "                results.append(gen)\n",
    "\n",
    "        return results[-limit:]  # 최근 항목부터\n",
    "\n",
    "    def show_history(self, limit=10):\n",
    "        \"\"\"히스토리 출력\"\"\"\n",
    "        recent = self.history[\"generations\"][-limit:]\n",
    "\n",
    "        print(f\"최근 {len(recent)}개 생성 기록:\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for gen in reversed(recent):  # 최신순\n",
    "            print(f\"ID: {gen.get('generation_id', 'Unknown')}\")\n",
    "            print(f\"시드: {gen.get('seed', 'Unknown')}\")\n",
    "            print(f\"시간: {gen.get('timestamp', 'Unknown')}\")\n",
    "            print(f\"프롬프트: {gen.get('prompt', 'Unknown')[:60]}...\")\n",
    "            if gen.get('image_path'):\n",
    "                print(f\"파일: {gen.get('image_path')}\")\n",
    "            print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757069488465,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "kzk0UUpl0XRh",
    "outputId": "e13a763a-d217-4a5e-9fe4-62ad8e5196e4"
   },
   "outputs": [],
   "source": [
    "# 전역 매니저 인스턴스\n",
    "gen_manager = ImageGenerationManager()\n",
    "\n",
    "# 기존 함수 개선 (메타데이터 자동 저장)\n",
    "def enhanced_face_generation(pipe, prompt, negative_prompt=None, seed=42,\n",
    "                           num_inference_steps=30, guidance_scale=7.5,\n",
    "                           save_path=None, show_image=True, auto_save_history=True):\n",
    "    \"\"\"히스토리 저장 기능이 추가된 이미지 생성\"\"\"\n",
    "\n",
    "    # 기존 생성 함수 호출\n",
    "    image = alternative_face_generation(\n",
    "        pipe=pipe,\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        seed=seed,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        save_path=save_path,\n",
    "        show_image=show_image\n",
    "    )\n",
    "\n",
    "    # 히스토리 자동 저장\n",
    "    if image and auto_save_history:\n",
    "        metadata = {\n",
    "            \"prompt\": prompt,\n",
    "            \"negative_prompt\": negative_prompt,\n",
    "            \"seed\": seed,\n",
    "            \"steps\": num_inference_steps,\n",
    "            \"guidance_scale\": guidance_scale,\n",
    "            \"model\": \"runwayml/stable-diffusion-v1-5\"\n",
    "        }\n",
    "\n",
    "        generation_id = gen_manager.save_generation(metadata, save_path)\n",
    "        print(f\"히스토리 저장됨 (ID: {generation_id})\")\n",
    "\n",
    "    return image\n",
    "\n",
    "def find_similar_faces_auto(pipe, reference_image_path, target_score=0.7, max_attempts=100, target_count=3):\n",
    "    \"\"\"자동으로 유사한 얼굴 이미지 찾기\"\"\"\n",
    "\n",
    "    # 평가기와 프롬프트 생성기 초기화\n",
    "    evaluator = FaceSimilarityEvaluator(reference_image_path)\n",
    "    prompt_gen = SmartPromptGenerator(reference_image_path)\n",
    "\n",
    "    # 스마트 프롬프트 생성\n",
    "    smart_prompts, features = prompt_gen.generate_smart_prompts()\n",
    "    print(f\"감지된 얼굴 특징: {features}\")\n",
    "    print(f\"생성된 스마트 프롬프트 수: {len(smart_prompts)}\")\n",
    "\n",
    "    found_images = []\n",
    "    attempt_count = 0\n",
    "\n",
    "    # 네거티브 프롬프트\n",
    "    negative_prompt = \"blurry, low quality, bad anatomy, deformed, cartoon, anime, multiple faces, bad hands\"\n",
    "\n",
    "    print(f\"목표: {target_count}개 이미지 (점수 {target_score} 이상)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while len(found_images) < target_count and attempt_count < max_attempts:\n",
    "        attempt_count += 1\n",
    "\n",
    "        # 프롬프트 선택 (순환 또는 랜덤)\n",
    "        prompt_idx = (attempt_count - 1) % len(smart_prompts)\n",
    "        current_prompt = smart_prompts[prompt_idx]\n",
    "\n",
    "        # 랜덤 시드\n",
    "        seed = random.randint(1, 99999999)\n",
    "\n",
    "        print(f\"\\n시도 {attempt_count}/{max_attempts}\")\n",
    "        print(f\"프롬프트: {current_prompt}\")\n",
    "        print(f\"시드: {seed}\")\n",
    "\n",
    "        try:\n",
    "            # 이미지 생성\n",
    "            generated_image = alternative_face_generation(\n",
    "                pipe=pipe,\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                seed=seed,\n",
    "                show_image=False  # 배치 처리시 화면 출력 끄기\n",
    "            )\n",
    "\n",
    "            if generated_image is None:\n",
    "                continue\n",
    "\n",
    "            # 유사도 평가\n",
    "            scores = evaluator.evaluate_similarity(generated_image)\n",
    "            total_score = scores['total_score']\n",
    "\n",
    "            print(f\"점수: {total_score:.3f} (얼굴: {scores['face_similarity']:.3f}, LPIPS: {scores['lpips_similarity']:.3f})\")\n",
    "\n",
    "            # 목표 점수 달성시 저장\n",
    "            if total_score >= target_score:\n",
    "                print(f\"✅ 목표 달성! (점수: {total_score:.3f})\")\n",
    "\n",
    "                # 이미지 저장\n",
    "                save_path = f\"similar_face_{len(found_images)+1:02d}_score_{total_score:.3f}_seed_{seed}.png\"\n",
    "                generated_image.save(save_path)\n",
    "\n",
    "                found_images.append({\n",
    "                    'image': generated_image,\n",
    "                    'scores': scores,\n",
    "                    'prompt': current_prompt,\n",
    "                    'seed': seed,\n",
    "                    'path': save_path\n",
    "                })\n",
    "\n",
    "                # 이미지 표시\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(generated_image)\n",
    "                plt.title(f\"Found #{len(found_images)} (Score: {total_score:.3f})\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"탐색 완료!\")\n",
    "    print(f\"시도 횟수: {attempt_count}\")\n",
    "    print(f\"발견된 이미지: {len(found_images)}개\")\n",
    "\n",
    "    if found_images:\n",
    "        print(\"\\n발견된 이미지 정보:\")\n",
    "        for i, result in enumerate(found_images):\n",
    "            print(f\"{i+1}. 점수: {result['scores']['total_score']:.3f}, 경로: {result['path']}\")\n",
    "\n",
    "    return found_images\n",
    "\n",
    "print(\"이미지 생성 관리자 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1757069488467,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "6254H8xj0XRh"
   },
   "outputs": [],
   "source": [
    "# 대량 재생성 함수\n",
    "def regenerate_favorites(pipe, generation_ids):\n",
    "    \"\"\"즐겨찾기 이미지들 재생성\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for gen_id in generation_ids:\n",
    "        print(f\"\\n재생성 중: ID {gen_id}\")\n",
    "        image = gen_manager.regenerate_by_id(gen_id, pipe, save_new=True)\n",
    "        if image:\n",
    "            results.append({\"id\": gen_id, \"image\": image})\n",
    "\n",
    "    return results\n",
    "\n",
    "# 배치 생성 함수\n",
    "def batch_generate_images(pipe, prompts, base_negative=None, seeds=None, save_folder=None):\n",
    "    \"\"\"여러 프롬프트로 배치 생성\"\"\"\n",
    "\n",
    "    if save_folder is not None:\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    if isinstance(prompts, str):\n",
    "        prompts = [prompts]\n",
    "\n",
    "    if seeds is None:\n",
    "        seeds = [random.randint(1, 99999999) for _ in prompts]\n",
    "    elif len(seeds) < len(prompts):\n",
    "        seeds = seeds + [random.randint(1, 99999999) for _ in range(len(prompts) - len(seeds))]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, (prompt, seed) in enumerate(zip(prompts, seeds)):\n",
    "        print(f\"생성 {i+1}/{len(prompts)} (시드: {seed})\")\n",
    "\n",
    "        save_path = None\n",
    "        if save_folder is not None:\n",
    "            save_path = f\"{save_folder}/image_{i+1:03d}_seed_{seed}.png\"\n",
    "\n",
    "        image = enhanced_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=prompt,\n",
    "            negative_prompt=base_negative,\n",
    "            seed=seed,\n",
    "            save_path=save_path,\n",
    "            show_image=True\n",
    "        )\n",
    "\n",
    "        if image:\n",
    "            results.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"seed\": seed,\n",
    "                \"image\": image,\n",
    "                \"path\": save_path\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UehYd9h0XRi"
   },
   "source": [
    "# 이미지 생성 시스템 사용 방법\n",
    "\n",
    "## 1. 기본 이미지 생성 (히스토리 자동 저장)\n",
    "```python\n",
    "# 기본 생성\n",
    "image = enhanced_face_generation(\n",
    "    pipe=pipe,\n",
    "    prompt=\"young Asian woman, professional portrait, natural lighting\",\n",
    "    negative_prompt=\"blurry, low quality, bad anatomy\",\n",
    "    seed=12345,\n",
    "    save_path=\"test_portrait.png\"\n",
    ")\n",
    "```\n",
    "\n",
    "## 2. 본인 사진 기반 유사 이미지 자동 탐색\n",
    "```python\n",
    "# 참조 사진 경로 설정 (본인 사진)\n",
    "reference_photo = \"my_reference_photo.jpg\"\n",
    "\n",
    "# 자동 탐색 실행\n",
    "similar_faces = find_similar_faces_auto(\n",
    "    pipe=pipe,\n",
    "    reference_image_path=reference_photo,\n",
    "    target_score=0.65,  # 65% 이상 유사\n",
    "    max_attempts=50,    # 최대 50번 시도\n",
    "    target_count=3      # 3개 찾으면 종료\n",
    ")\n",
    "```\n",
    "\n",
    "## 3. 히스토리 관리\n",
    "```python\n",
    "# 히스토리 보기\n",
    "gen_manager.show_history(limit=5)\n",
    "\n",
    "# 검색\n",
    "results = gen_manager.search_generations(keyword=\"portrait\")\n",
    "seed_results = gen_manager.search_generations(seed=12345)\n",
    "\n",
    "# 재생성\n",
    "regenerated = gen_manager.regenerate_by_id(generation_id=3, pipe=pipe)\n",
    "```\n",
    "\n",
    "## 4. 배치 생성\n",
    "```python\n",
    "prompts = [\n",
    "    \"professional headshot, business attire\",\n",
    "    \"casual portrait, outdoor lighting\",\n",
    "    \"artistic portrait, dramatic lighting\"\n",
    "]\n",
    "\n",
    "batch_results = batch_generate_images(\n",
    "    pipe=pipe,\n",
    "    prompts=prompts,\n",
    "    base_negative=\"blurry, low quality, bad anatomy\",\n",
    "    save_folder=\"batch_portraits\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1757069488484,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "4-oKvAGS0XRi"
   },
   "outputs": [],
   "source": [
    "# # 테스트: 기본 이미지 생성\n",
    "# test_prompt = \"young Asian woman, professional portrait, natural lighting, high quality\"\n",
    "# test_negative = \"blurry, low quality, bad anatomy, deformed, cartoon, anime\"\n",
    "\n",
    "# test_image = enhanced_face_generation(\n",
    "#     pipe=pipe,\n",
    "#     prompt=test_prompt,\n",
    "#     negative_prompt=test_negative,\n",
    "#     seed=42,\n",
    "#     save_path=\"test_generation.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559,
     "referenced_widgets": [
      "fd2c322f12a14b368ed84092547f681f",
      "ff1d0668e9684b85ab16b24dcd3703bf",
      "b104756fe989454f88239e65e1a3a28c",
      "ece2eff5bc114c91ac0d89c13e248ddd",
      "48a00a2e7ac8415cba5d9570d2d1f51e",
      "b2f72d9d1f91471693f452f15334f547",
      "479ddc7377384e8885372d04ba5dfa73",
      "a3875881d459467a8ff80f2cee976635",
      "59bca1f7eb5046d1b735b5087ef0708d",
      "b63a628733394f5ab2e4453923a8cff6",
      "b96275ce2c8348058d5ae81f400fbc82"
     ]
    },
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1757069606180,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "KWXROcOA2cpP",
    "outputId": "5aec2f24-e2fb-4205-9515-b4b55cc4866c"
   },
   "outputs": [],
   "source": [
    "# 간단한 실행 (통합 함수 재사용)\n",
    "if helper.is_colab:\n",
    "    reference_photo = \"/content/drive/MyDrive/homepage/스프린트미션/스프린트미션_작업중/test.png\"\n",
    "else:\n",
    "    reference_photo = \"test.png\"\n",
    "\n",
    "# 파일 존재 확인\n",
    "if not os.path.exists(reference_photo):\n",
    "    print(f\"❌ 참조 이미지를 찾을 수 없습니다: {reference_photo}\")\n",
    "    print(\"현재 디렉토리 파일 목록:\")\n",
    "    for file in os.listdir('.'):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            print(f\"  - {file}\")\n",
    "else:\n",
    "    print(f\"✅ 참조 이미지 확인: {reference_photo}\")\n",
    "\n",
    "    # 통합 자동 탐색 실행 (기존 함수 재사용)\n",
    "    try:\n",
    "        similar_faces = find_similar_faces_auto_enhanced(\n",
    "            pipe=pipe,\n",
    "            reference_image_path=reference_photo,\n",
    "            target_score=0.6,\n",
    "            max_attempts=30,\n",
    "            target_count=2,\n",
    "            age_group=\"30대\",\n",
    "            gender=\"남성\",\n",
    "            ethnicity=\"백인\",\n",
    "            use_opencv_fallback=True  # 자동 백업 활성화\n",
    "        )\n",
    "\n",
    "        if similar_faces:\n",
    "            print(f\"\\n🎉 {len(similar_faces)}개의 유사한 이미지를 성공적으로 찾았습니다!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 탐색 중 오류 발생: {e}\")\n",
    "\n",
    "        # 기본 생성 테스트 (기존 함수 재사용)\n",
    "        print(\"기본 이미지 생성 테스트...\")\n",
    "        test_image = enhanced_face_generation(\n",
    "            pipe=pipe,\n",
    "            prompt=\"professional portrait, high quality, realistic\",\n",
    "            seed=42\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310_recommand_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0322d0ac3c50446594dd6754e4068241": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a1fbfb73b124332873f36584d894da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bd0dfd9b7804e61be99e2e43a8e4f21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e83df493cab467abe97477dd4b765cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c3bec2af7a492f9e659cb644fe6e4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1221f3d8061943e395f0517c2bb0ba3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "144506bedbdd4755a5a94a0257100323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "146f96d250c3474f89d5497506dadc1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "152011fa31a344e985e8b4ebe6c0070b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1892b885c9f3473ba320f52e687ed4b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d00dd16c0c424e779d55f932a522de1d",
      "placeholder": "​",
      "style": "IPY_MODEL_1221f3d8061943e395f0517c2bb0ba3b",
      "value": "100%"
     }
    },
    "2cde21101bff44979b3ed02110617631": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e901af9a07345c8b8307a5f2c06c2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a79a6bb4574aa58aa478c99641fce9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40b8af3da4e84acf8ae9db69c8b7e34f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "479ddc7377384e8885372d04ba5dfa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48a00a2e7ac8415cba5d9570d2d1f51e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b06d29e4e94b8da5beb45c6056dac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5738ff9c88d04c79a193a5e63a89927d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b44ec25194b54084b90283695fa10a5f",
      "placeholder": "​",
      "style": "IPY_MODEL_fb1ebbd7fec24bed86805105f33babc1",
      "value": " 20/20 [00:02&lt;00:00,  9.00it/s]"
     }
    },
    "59bca1f7eb5046d1b735b5087ef0708d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b9024b085ef47a69cf529c626a6c356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1892b885c9f3473ba320f52e687ed4b9",
       "IPY_MODEL_a8ce3f62c420440091a27a5793643b84",
       "IPY_MODEL_a32142681ece4dac8a9614442a929ac4"
      ],
      "layout": "IPY_MODEL_31a79a6bb4574aa58aa478c99641fce9"
     }
    },
    "69a0b86664244c4f9ec1b8ba1c66dd2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5728f8f34f24fd683a347068191f787",
      "placeholder": "​",
      "style": "IPY_MODEL_cd074d0a8cbd44d3ba698ff83f6d8dea",
      "value": " 6/6 [00:00&lt;00:00,  7.90it/s]"
     }
    },
    "6f63fcd64d9b42e9b9db0ab247ea3652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e901af9a07345c8b8307a5f2c06c2bb",
      "placeholder": "​",
      "style": "IPY_MODEL_144506bedbdd4755a5a94a0257100323",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "795836e6dff14890aa75c7c6db2d8318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9258181299a348bd9a1fe7ca0687a0ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92b416e643294aa9835e8b841ea42cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_152011fa31a344e985e8b4ebe6c0070b",
      "placeholder": "​",
      "style": "IPY_MODEL_795836e6dff14890aa75c7c6db2d8318",
      "value": "100%"
     }
    },
    "96359f7dabaf47f5aa5ea6391db64133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bd0dfd9b7804e61be99e2e43a8e4f21",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb25a9991f59443e87dd0dbfcfac06e2",
      "value": 6
     }
    },
    "99752028c0cf497d9540c51a55852cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb071adc9054464b951716ff6b68fd44",
       "IPY_MODEL_96359f7dabaf47f5aa5ea6391db64133",
       "IPY_MODEL_69a0b86664244c4f9ec1b8ba1c66dd2a"
      ],
      "layout": "IPY_MODEL_9258181299a348bd9a1fe7ca0687a0ab"
     }
    },
    "99b724cf124e4a739106bf0f5d2ac665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9cd78b5bebc442cea7600d375204bc9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32142681ece4dac8a9614442a929ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cde21101bff44979b3ed02110617631",
      "placeholder": "​",
      "style": "IPY_MODEL_146f96d250c3474f89d5497506dadc1c",
      "value": " 30/30 [00:01&lt;00:00, 15.84it/s]"
     }
    },
    "a3875881d459467a8ff80f2cee976635": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4a2fd815d034542a243a342823da200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8ce3f62c420440091a27a5793643b84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0f5643c47c342dd897008e86771c9cb",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4a2fd815d034542a243a342823da200",
      "value": 30
     }
    },
    "ac3f515f265e4880b1772c3274695e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd761716247648c0aa57cf756c6b0f7b",
      "placeholder": "​",
      "style": "IPY_MODEL_0e83df493cab467abe97477dd4b765cb",
      "value": " 7/7 [00:00&lt;00:00,  7.23it/s]"
     }
    },
    "ad9c37d16de04dab8ced57639bf4c58f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55b06d29e4e94b8da5beb45c6056dac8",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99b724cf124e4a739106bf0f5d2ac665",
      "value": 20
     }
    },
    "b0f5643c47c342dd897008e86771c9cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b104756fe989454f88239e65e1a3a28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3875881d459467a8ff80f2cee976635",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59bca1f7eb5046d1b735b5087ef0708d",
      "value": 30
     }
    },
    "b1d5c8d9fd5644bba6363bbd87d313fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2f72d9d1f91471693f452f15334f547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44ec25194b54084b90283695fa10a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63a628733394f5ab2e4453923a8cff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b96275ce2c8348058d5ae81f400fbc82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb071adc9054464b951716ff6b68fd44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40b8af3da4e84acf8ae9db69c8b7e34f",
      "placeholder": "​",
      "style": "IPY_MODEL_0a1fbfb73b124332873f36584d894da6",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "bb25a9991f59443e87dd0dbfcfac06e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bdbb6d528d4949159dcd3fd07f0e0075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f63fcd64d9b42e9b9db0ab247ea3652",
       "IPY_MODEL_f8ed5f9bb8004cea83322ae7519c721e",
       "IPY_MODEL_ac3f515f265e4880b1772c3274695e75"
      ],
      "layout": "IPY_MODEL_9cd78b5bebc442cea7600d375204bc9a"
     }
    },
    "cd074d0a8cbd44d3ba698ff83f6d8dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cee7cecaeb5248779aeb5bbae068d605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92b416e643294aa9835e8b841ea42cfd",
       "IPY_MODEL_ad9c37d16de04dab8ced57639bf4c58f",
       "IPY_MODEL_5738ff9c88d04c79a193a5e63a89927d"
      ],
      "layout": "IPY_MODEL_11c3bec2af7a492f9e659cb644fe6e4e"
     }
    },
    "d00dd16c0c424e779d55f932a522de1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5728f8f34f24fd683a347068191f787": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ece2eff5bc114c91ac0d89c13e248ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b63a628733394f5ab2e4453923a8cff6",
      "placeholder": "​",
      "style": "IPY_MODEL_b96275ce2c8348058d5ae81f400fbc82",
      "value": " 30/30 [00:01&lt;00:00, 15.55it/s]"
     }
    },
    "f8ed5f9bb8004cea83322ae7519c721e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0322d0ac3c50446594dd6754e4068241",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b1d5c8d9fd5644bba6363bbd87d313fe",
      "value": 7
     }
    },
    "fb1ebbd7fec24bed86805105f33babc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd2c322f12a14b368ed84092547f681f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff1d0668e9684b85ab16b24dcd3703bf",
       "IPY_MODEL_b104756fe989454f88239e65e1a3a28c",
       "IPY_MODEL_ece2eff5bc114c91ac0d89c13e248ddd"
      ],
      "layout": "IPY_MODEL_48a00a2e7ac8415cba5d9570d2d1f51e"
     }
    },
    "fd761716247648c0aa57cf756c6b0f7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff1d0668e9684b85ab16b24dcd3703bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2f72d9d1f91471693f452f15334f547",
      "placeholder": "​",
      "style": "IPY_MODEL_479ddc7377384e8885372d04ba5dfa73",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
