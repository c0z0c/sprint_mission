MLP
CNN -> 이미지 데이터를 다루는 컴퓨터 비전
RNN -> 시계열 데이터

이유?
이미지는 주변 픽셀에 영향을 받기 때문에 convolution
시열은 시간적으로 연속적인 이전 데이터에 영향을 받기 때문에 RNN
=사람의 생각, 느낌, 직관
=inductive bias (귀납적 편향)
=데이터의 특성을 보니까 대략 "이런 방법으로 인식하면 효과적일 것 같은 느낌"
=inductive bias 가 매우 강하다
=모델에 작용된 편견이 강하고
=보통 이게 강할수록, 모델의 complexity(복잡도)가 낮아져요.
=모델의 복잡도는 모델의 크기와는 약간 다른 개념
=데이터를 처리하는 layer에 같은 hidden dimension 크기 기준으로 얼마나 많은 파라미터가 필요한지
모델 복잡도 비교
MLP >>>>>>> CNN >>>> RNN
MLP
layer1 = nn.Linear(128, 128)
layer2 = nn.Linear(128, 128)
layer3 = nn.Linear(128, 128)
CNN
layer1 = nn.Conv2d(kernel=(3, 3), input_channel=64, output_channel=128)
layer2 = nn.Conv2d(kernel=(3, 3), input_channel=128, output_channel=256)
layer3 = nn.Conv2d(kernel=(3, 3), input_channel=256, output_channel=512)
RNN
layer = nn.LSTM(128, 3)

우리가 할 일: 사진 데이터보고, 개-고양이 판별
입력 x 이미지: shape: 500*500*3 (가로픽셀수*세로픽셀수*RGB)
이걸 MLP로 하면?
처음부터 이미지를 flatten: 3dimension 텐서를 일렬로 쭉 나열
입력차원: 75만
x = flatten(x) -> (500*500*3) -> (750,000*1) shape 변환
linear_layer = nn.Linear(750000, 256)
x = linear_layer(x) == (x = Wx+b) -> 256차원 벡터
이 linear_layer에는 W, b라는 학습할 파라미터 행렬, 벡터가 있는데
W에 들어가는 실제 숫자의 양은?
W: 750000* 256
b: 256
이러면 대략 1억 9천만개 숫자가 필요한데,
한 숫자가 float자료형이라서 32bit=4byte
W에만 768MB의 메모리가 필요함.
처음 입력단계부터 MLP로 이걸 넣으면 너무너무 메모리복잡도가 올라감

여기까지가 AI, 딥러닝하던 사람들의 고민

지금부터 주인공을 바꿔서, 컴퓨터그래픽 분야에서 이미지처리하던 사람들 before 2010년대
convolution을 어떻게 잘할 수 있을까?
convolution은 CNN이 나오기 이전부터 이미지 처리할 때 많이 쓰이던 개념
합성곱 (곱한다음에 더하기)

horizontal convoltion filter를 적용
입력 이미지에서 가로선이 두드러지는 부분은 값이 크게 계산되고, 아닌 부분은 작게 계산.
-> 이 horizontal convolution filter를 적용한 결과값은 이미지에서 “가로적인“ 특징만 추출

그러면 세로, 대각선, 마름도, 동그라미, 네모, 세모
등등 이런식으로 여러 단순 도형의 패턴을 추출할 수 있겠죠?

이미지 -> 가로필터 -> 세로필터 -> 십자패턴이 잡히겠죠?
단순도형필터를 여러 단계에 거쳐서 적용하면
더 복잡한 도형 필터를 적용하는 효과가 있겠죠?

이미지처리하던 연구자들은 뭘 고민했냐면
어떻게 해야 더 이미지의 특징을 잘 추출할 수 있는 convolution 필터를 만들고
이 필터들을 가지고 이미지가 어떤 순서로 처리되어야, 이미지의 특징을 잘 추출할 수 있을까?
-> 정보가 압축 (컨볼루션 적용할 때마다 가로 세로 픽셀 값들이 압축)
-> 이런식으로 저차원의 특징(벡터)으로 잘 만들면, 간단한 분류 모델들로 이미지 판별이 쉬워지지 않을까?
이건 경우의 수가 거의 수천만가지라서 정답을 찾는게 불가능

어느 순간 이 두 사람이 만나서 얘기를 하다가
convolution 필터를 사람이 왜 만들어?
그냥 얘도 행렬인데 학습시키면 되는거 아니야?
-> Convolutional Neural Network
그냥 MLP 학습하듯이, 처음엔 convolution 필터를 무작위로 생성한 다음에
할튼 얘가 가로든 세로든 그건 중요한게 아니고, 입력에 어떤 파라미터를 곱해서
정답에 가까워지는 방향으로 업데이트하다보면 이미지 특징 추출도 알아서 잘하지 않을까?

cnn_layer = nn.Conv2d(kernel=(3, 3), input_channel=3, output_channel=128)

x: 500*500*3

cnn_layer(x) -> 498*498*128
이걸 cnn, pooling을 반복하다보면
498*498*128 -> 31*31*512 -> 49만
여기서 flatten하고 MLP로 보내요
linear_layer = nn.Linear(49만, 256) -> 1억2천

모델에 필요한 파라미터 수는 40% 감소, 성능은 올라감
이미지에 대한 inductive bias
=이미로부터 어떤 지엽적이고 단순한 패턴들을 모아모아서 추출하다보면
=어느샌가 전역(global)적이고 복잡한 패턴까지 잘 추출할 수 있다

GPT에 있는 핵심 모델 = Transformer는 자연어 입력에 대한 inductive bias

왜 시계열은 RNN인가?

모든 시간의 속성을 가지는 흐름은 사람이 인식할 때 어떻게 받아들여지냐면
오늘의 상태 + (이전의 상태)*망각율(decay rate)
현재 시점에서 입력된 데이터 + f(과거시점에서 이미 들어온 데이터)
x = x_1, ..., x_t (1번 시점부터 t번 시점까지의 시계열)
f: 현재데이터를 인식하는 함수 = layer = 행렬
f(x) = Wx+b
g: 과거 데이터를 인식하는 함수 = layer = 행렬
g(x) = Vx+c

y_t = f(x_t) + g(f(x_t-1)) 

이러다보면
현재 시점에서 먼 과거일 수록 g함수(이전 hidden state에 뭔가를 곱하고 확률적으로 forget시키는 것) 점점 희미해짐
인간이 시간의 흐름에서 데이터를 인식하는 것과 매우 유사한 방법
시계열 데이터를 가지고 미래를 예측 / 시계열 자체를 판별 등 여러 작업을 할 때
당연히 현재시점에 가까운 데이터일 수록 더 중요하게 보게 됨
= 환자의 시계열 활력징후 데이터를 통해서 앞으로 사망/심정지가 발생할지 예측
= 주식데이터 예측, 내일 주가 예측하는데, 어제오늘 주가가 4년전 주가보다는 내일 주가와 더 연관성이 크겠죠?

RNN은 한 행렬가지고 모들 시계열을 전부 공유해서 사용하기 때문에 (shared parameter)
MLP 비해 model complexity가 매우매우 낮음

요즘은 Transformer가 다 하고있음
why? Transformer의 모델 복잡도 >>>>>>> MLP
모델 복잡도가 높을 수록 뭐가 좋냐면
학습데이터 규모가 커질수록 성능 향상이 뚜렷해짐
2020년 전에는 학습데이터의 양이 백만단위
요즘은 데이터 양이 억, 조단위
scaling law 시대에 살고 있음 = 데이터많이 때려박고, 모델 크기 키울수록 성능 좋아짐

Transformer: 원래는 자연어를 위해서 개발되었는데, 연구하다보니 데이터가 엄청 많은 조건에서는 CNN, RNN보다 이미지도 더 잘하고, 시계열도 더 잘한다

입력된 데이터의 각 요소 별로 서로의 연관성(=attention)을 학습하게끔 하는 게 핵심

LLM을 개발하는 회사
LLM을 활용해서 Agentic AI 서비스를 개발하는 회사
LLM이 아닌 AI모델을 개발하는 회사
