객채인식
이미지 분류

그냥 학습하는 방법, 모델 구조는 거의 다 똑같고
딱 하나 차이
"정답을 뭘로 두고 학습하느냐"
딥러닝의 학습 
= "모델의 출력이 정답에 가까워지는 방향으로 가도록 모델의 내부 가중치(=파라미터)를 업데이트 하는 것"

분류
정답: one-hot vector (5개 클래스 중에 하나 맞추기)
정답 y: [0 0 0 1 0]
모델f
이미지x
f(x) = [0.2, 0.1, 0.0, 0.4 0.3]

f(x)랑 y랑 차이(=손실함수)가 최소화 되도록 f 안에 있는 가중치를 업데이트

객체인식
f, x 거의 그대로
y를 뭘로 둬야할까?
목표: 이미지 안에서 네모 하나 그리는 것
001000000
000011100
000110100
011000010
-> 이건 segmentation에 가까움 (더 어려움)

픽셀 -> 좌표평면 상의 직사각형 정보를 알려면
좌표 몇개를 알아야할까?

(x1, y1), (x2, y2) (x1<x2, y1<y2)
이 좌표에 들어가는 숫자 4개를 맞추면 되지 않을까?
-> 다변량회귀 (multivariate regression)
-> 여러 숫자를 맞추는 것
f(x) 마지막에 출력할 때
nn.Linear(dim, 4) -> 출력하면 될 것 같은데?
-문제: 학습이 불안정해집니다
-왜? 딥러닝은 Gradient Descent로 학습됨
새로운w = 이전w-미분값*학습률
학습률 = 0.001 이렇게 작은데
왜 작게 할까요?
너무 크게 하면 학습이 불안정 = 발산하거나, 수렴이안됨

좌표의 값 = 정수 (129, 90) , (398, 430)
이런식으로 큰 정수를 정답으로 두면
DL 레이어에 x가 들어올 때 큰 값을 곱하고 더해야겠죠?
이런식으로 수의 스케일이 커지면 학습이 매우 어려워짐
두번째 문제, (x1<x2, y1<y2) 이 제약 조건 거는것도 너무 학습에 비효율적 이걸 위한 손실함수도 따로 구해서 더해야함

yolo v1
입력을 -> 그리드로 나눔 (그리드=픽셀의 집합)
정답도 그리드로 설정
꼭 픽셀단위까지 정확하진 않아도 되니까
정답 그리드를 맞추면 되는데,

정답을 어떻게 세팅했냐가 포인트 
(가로기준 중점의 상대위치, 세로기준 중점의 상대위치,
폭, 높이)
이미지 사이즈: (500*500)
정답 네모: (129, 90) , (398, 430)
(0.656, 0.520, 0.538, 0.680)
-> 이걸 맞추게 하자!
장점: 맞출 정답 숫자가 전부 0~1사이
->모델 마지막에 sigmoid씌워서 출력하면 학습도 안정적으로 잘됨

이래도 어려웠음.
네비게이션: 도착지
출발지가 매번 달라짐(그래서 어쩔때는 학습이 잘되고, 어쩔때는 잘안되고)

yolo v2
-앵커(anchor) 개념 도입
-출발지를 고정 (대전)
-목적지는 이미지마다 다르니까 
-출발지에서 얼만큼 이동해야 목적지로 갈 수 있는지 맞추게 하는게 목적
-v1에서는 그냥 너가 어디서 출발하든, 목적지 좌표만 맞춰! (2016)
-v2에서는 여기서 출발에서 목적지 좌표로 얼만큼 이동하면 될지 맞춰 (2018)
-현재 출발지 (0.5, 0.5, 0.2, 0.2)
(0.656, 0.520, 0.538, 0.680) -> 이걸 맞추는게 아니라

(0.656, 0.520, 0.538, 0.680) - (0.5, 0.5, 0.2, 0.2)
이렇게 구하진 않고 지수함수같은 것을 활용해서
정답이 음수가 안되게 장치를 걸어둠

여러 object를 맞추려면? (4개)
후보 anchor를 10개 둔다음에
4개 object 별로 겹치는 영역(IoU)이 가장 큰 앵커 4개 선정해서 예측

object detction은 너무 쉽고, segmentation더 가치가 있기 때문에, 일반적인 거대 AI에선 안쓰이고
완전 하드웨어 사양이 낮은 공장, 로봇, 자동차 등
Physical AI 영역에서는 가벼운 모델들이 잘 쓰임
여기서 중요한건 실시간 반응속도
자율주행, 센서 등의 환경에서 유용

transfer learning
이미 학습된 모델(pretrain)을 (같은형태, 다른형태)로 추가 학습
추가학습=fine tuning (tuning, post-train)

ChatGPT학습 과정
Pretrain단계
-다음 단어 계속 맞추게 학습
-데이터: 책, 코드, 위키, 웹사이트, 등등 모든 자연어 문서
-> 언어를 가르침
Post train(fine tuing)단계
-이것도 다음단어 학습
-데이터: 사람의 지시 -> 지시에 따른 결과물
-Supervised Fine Tuning (SFT)
-강화학습
-데이터: 사람의 피드백
-사람의 지시 -> 결과물 -> 사람이 평가한 점수
->이 점수(=보상)가 최대화 되도록 강화학습

CNN같은 것들도 pretrained 모델 다운받아서
(우리한테 없는 이미지 데이터로 많이 학습한 모델)
=어느정도 이미지에 대한 감각, 인식성능이 있는 모델
내 지금 이미지 관련 작업에 쓰는 것이
그냥 처음부터 학습하는 것보다 수렴도 빠르고 성능도 좋음.

파인튜닝 할 때
모델 전체 튜닝
일부만 튜닝(parameter efficient fine tuning, PEFT)
LoRA, classifier만 튜닝하기 등등

코드잇 스터디
알아서 복습하는 단계

2025년 기준 AI업계에서 가장 떠오르는 기술역량
=Context engineering
이걸 잘하면 Agentic AI 서비스를 개발하는 기업에 취업할 가능성이 상승

AI 산업동향
지금은 나무심는 법 배우고 있음
숲은 어떻게 생겼나? 가끔 보는 것도 좋음
우리나라, 국내기업들이 AI시대에 공통적으로 느끼는 문제들이 뭐고, 이걸 해결하기위해서 뭘 하려고하고
어디에 돈을 쓰려고하고, 사람을 쓰려고 하는지
이런 큰 흐름에 대한 고민들을 해보시는 것을 추천.




